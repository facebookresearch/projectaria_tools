"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[2326],{6367:(e,i,s)=>{s.r(i),s.d(i,{assets:()=>c,contentTitle:()=>d,default:()=>u,frontMatter:()=>t,metadata:()=>n,toc:()=>h});const n=JSON.parse('{"id":"projectariatools/tools/pythonviz","title":"Visualization Tools (Python)","description":"This page covers the Python-based visualization tools available in Project Aria Tools. These tools provide powerful ways to visualize and analyze Aria data using the Rerun visualization framework.","source":"@site/docs-research-tools/projectariatools/tools/pythonviz.mdx","sourceDirName":"projectariatools/tools","slug":"/projectariatools/tools/pythonviz","permalink":"/projectaria_tools/gen2/research-tools/projectariatools/tools/pythonviz","draft":false,"unlisted":false,"editUrl":"https://www.internalfb.com/code/fbsource/arvr/projects/ariane/aria_research_kit/projectaria_tools/website/docs-research-tools/projectariatools/tools/pythonviz.mdx","tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0,"title":"Visualization Tools (Python)"},"sidebar":"researchToolsSidebar","previous":{"title":"Installation","permalink":"/projectaria_tools/gen2/research-tools/projectariatools/installation"},"next":{"title":"Visualization Tools (C++)","permalink":"/projectaria_tools/gen2/research-tools/projectariatools/tools/cppviz"}}');var a=s(74848),r=s(28453),l=s(67581),o=s(98180);const t={sidebar_position:0,title:"Visualization Tools (Python)"},d="Python Visualization Tools",c={},h=[{value:"aria_rerun_viewer",id:"aria_rerun_viewer",level:2},{value:"Basic Usage",id:"basic-usage",level:3},{value:"Command Line Options",id:"command-line-options",level:3},{value:"Examples",id:"examples",level:3},{value:"Basic Visualization",id:"basic-visualization",level:4},{value:"Visualize Only RGB Camera and Eye Gaze",id:"visualize-only-rgb-camera-and-eye-gaze",level:4},{value:"Skip Beginning and End of Recording",id:"skip-beginning-and-end-of-recording",level:4},{value:"Apply Custom Subsampling",id:"apply-custom-subsampling",level:4},{value:"Complex Example with Multiple Options",id:"complex-example-with-multiple-options",level:4},{value:"What You&#39;ll See",id:"what-youll-see",level:3},{value:"Important Notes",id:"important-notes",level:3},{value:"viewer_mps",id:"viewer_mps",level:2},{value:"Basic Usage",id:"basic-usage-1",level:3},{value:"Command Line Options",id:"command-line-options-1",level:3},{value:"Input Files",id:"input-files",level:4},{value:"Visualization Options",id:"visualization-options",level:4},{value:"Examples",id:"examples-1",level:3},{value:"Auto-detect MPS Data",id:"auto-detect-mps-data",level:4},{value:"Specify Individual MPS Files",id:"specify-individual-mps-files",level:4},{value:"Web Browser Mode",id:"web-browser-mode",level:4},{value:"Multiple Trajectories and Point Clouds",id:"multiple-trajectories-and-point-clouds",level:4},{value:"What You&#39;ll See",id:"what-youll-see-1",level:3}];function p(e){const i={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(i.header,{children:(0,a.jsx)(i.h1,{id:"python-visualization-tools",children:"Python Visualization Tools"})}),"\n",(0,a.jsx)(i.p,{children:"This page covers the Python-based visualization tools available in Project Aria Tools. These tools provide powerful ways to visualize and analyze Aria data using the Rerun visualization framework."}),"\n",(0,a.jsx)(i.h2,{id:"aria_rerun_viewer",children:"aria_rerun_viewer"}),"\n",(0,a.jsxs)(i.p,{children:["The ",(0,a.jsx)(i.code,{children:"aria_rerun_viewer"})," is a Python tool that visualizes Aria VRS (Video Recording and Sensor) files using the Rerun visualization framework. It supports both Aria Gen1 and Gen2 devices and can display multiple sensor streams including cameras, IMU, audio, eye gaze, hand tracking, and more."]}),"\n",(0,a.jsx)(l.A,{alt:"Docusaurus themed image",sources:{light:(0,o.default)("/img/docs-research-tools/projectariatools/aria_rerun_viewer.png"),dark:(0,o.default)("/img/docs-research-tools/projectariatools/aria_rerun_viewer.png")}}),"\n",(0,a.jsx)(i.h3,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-bash",children:"aria_rerun_viewer --vrs path/to/your/file.vrs\n"})}),"\n",(0,a.jsx)(i.h3,{id:"command-line-options",children:"Command Line Options"}),"\n",(0,a.jsxs)(i.table,{children:[(0,a.jsx)(i.thead,{children:(0,a.jsxs)(i.tr,{children:[(0,a.jsx)(i.th,{children:"Parameter"}),(0,a.jsx)(i.th,{children:"Type"}),(0,a.jsx)(i.th,{children:"Required"}),(0,a.jsx)(i.th,{children:"Description"})]})}),(0,a.jsxs)(i.tbody,{children:[(0,a.jsxs)(i.tr,{children:[(0,a.jsx)(i.td,{children:(0,a.jsx)(i.code,{children:"--vrs"})}),(0,a.jsx)(i.td,{children:"string"}),(0,a.jsx)(i.td,{children:"Yes"}),(0,a.jsx)(i.td,{children:"Path to the VRS file you want to visualize"})]}),(0,a.jsxs)(i.tr,{children:[(0,a.jsx)(i.td,{children:(0,a.jsx)(i.code,{children:"--skip-begin-sec"})}),(0,a.jsx)(i.td,{children:"float"}),(0,a.jsx)(i.td,{children:"No"}),(0,a.jsx)(i.td,{children:"Number of seconds to skip at the beginning of the VRS file"})]}),(0,a.jsxs)(i.tr,{children:[(0,a.jsx)(i.td,{children:(0,a.jsx)(i.code,{children:"--skip-end-sec"})}),(0,a.jsx)(i.td,{children:"float"}),(0,a.jsx)(i.td,{children:"No"}),(0,a.jsx)(i.td,{children:"Number of seconds to skip at the end of the VRS file"})]}),(0,a.jsxs)(i.tr,{children:[(0,a.jsx)(i.td,{children:(0,a.jsx)(i.code,{children:"--enabled-streams"})}),(0,a.jsx)(i.td,{children:"string list"}),(0,a.jsx)(i.td,{children:"No"}),(0,a.jsxs)(i.td,{children:["Enable specific streams by their labels (space-separated). Available streams include: ",(0,a.jsx)(i.code,{children:"camera-rgb"}),", ",(0,a.jsx)(i.code,{children:"slam-front-left"}),", ",(0,a.jsx)(i.code,{children:"slam-front-right"}),", ",(0,a.jsx)(i.code,{children:"slam-side-left"}),", ",(0,a.jsx)(i.code,{children:"slam-side-right"}),", ",(0,a.jsx)(i.code,{children:"camera-et-left"}),", ",(0,a.jsx)(i.code,{children:"camera-et-right"}),", ",(0,a.jsx)(i.code,{children:"imu-left"}),", ",(0,a.jsx)(i.code,{children:"imu-right"}),", ",(0,a.jsx)(i.code,{children:"mic"}),", ",(0,a.jsx)(i.code,{children:"baro0"}),", ",(0,a.jsx)(i.code,{children:"mag0"}),", ",(0,a.jsx)(i.code,{children:"gps"}),", ",(0,a.jsx)(i.code,{children:"handtracking"}),", ",(0,a.jsx)(i.code,{children:"eyegaze"}),", ",(0,a.jsx)(i.code,{children:"vio"}),", ",(0,a.jsx)(i.code,{children:"vio_high_frequency"}),". Default: all available streams"]})]}),(0,a.jsxs)(i.tr,{children:[(0,a.jsx)(i.td,{children:(0,a.jsx)(i.code,{children:"--subsample-rates"})}),(0,a.jsx)(i.td,{children:"string list"}),(0,a.jsx)(i.td,{children:"No"}),(0,a.jsxs)(i.td,{children:["Specify subsampling rates for streams in the format ",(0,a.jsx)(i.code,{children:"stream=rate"})," (space-separated pairs). Example: ",(0,a.jsx)(i.code,{children:"camera-rgb=2 eyegaze=5"}),". Default: ",(0,a.jsx)(i.code,{children:"vio_high_frequency=10"})]})]})]})]}),"\n",(0,a.jsx)(i.h3,{id:"examples",children:"Examples"}),"\n",(0,a.jsx)(i.h4,{id:"basic-visualization",children:"Basic Visualization"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-bash",children:"aria_rerun_viewer --vrs recording.vrs\n"})}),"\n",(0,a.jsx)(i.h4,{id:"visualize-only-rgb-camera-and-eye-gaze",children:"Visualize Only RGB Camera and Eye Gaze"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-bash",children:"aria_rerun_viewer \\\n  --vrs recording.vrs \\\n  --enabled-streams camera-rgb eyegaze\n"})}),"\n",(0,a.jsx)(i.h4,{id:"skip-beginning-and-end-of-recording",children:"Skip Beginning and End of Recording"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-bash",children:"aria_rerun_viewer \\\n  --vrs recording.vrs \\\n  --skip-begin-sec 10 \\\n  --skip-end-sec 5\n"})}),"\n",(0,a.jsx)(i.h4,{id:"apply-custom-subsampling",children:"Apply Custom Subsampling"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-bash",children:"aria_rerun_viewer \\\n  --vrs recording.vrs \\\n  --subsample-rates camera-rgb=3 vio_high_frequency=20\n"})}),"\n",(0,a.jsx)(i.h4,{id:"complex-example-with-multiple-options",children:"Complex Example with Multiple Options"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-bash",children:"aria_rerun_viewer \\\n  --vrs recording.vrs \\\n  --enabled-streams camera-rgb slam-front-left slam-front-right eyegaze handtracking \\\n  --subsample-rates camera-rgb=2 handtracking=5 \\\n  --skip-begin-sec 30 \\\n  --skip-end-sec 10\n"})}),"\n",(0,a.jsx)(i.h3,{id:"what-youll-see",children:"What You'll See"}),"\n",(0,a.jsx)(i.p,{children:"The viewer displays data in an interactive 3D environment using Rerun:"}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"RGB & SLAM Camera stream"}),": RGB and SLAM camera images, with overlaid eye gaze and hand tracking results."]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"1D Sensor Data"}),": IMU, audio, magnetometer, and barometer data plotted as 1D time series."]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"3D World View"}),": 3D visualization of the VIO trajectory, eye gaze, and hand tracking results."]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"Device calibration"}),": 3D representation of the sensor locations on Aria device."]}),"\n"]}),"\n",(0,a.jsx)(i.h3,{id:"important-notes",children:"Important Notes"}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsxs)(i.li,{children:["\n",(0,a.jsxs)(i.p,{children:[(0,a.jsx)(i.strong,{children:"VIO High Frequency Subsampling"}),": The ",(0,a.jsx)(i.code,{children:"vio_high_frequency"})," stream runs at 800Hz by default, which is automatically subsampled to 80Hz (subsample rate of 10) to improve visualization performance. You can adjust this using ",(0,a.jsx)(i.code,{children:"--subsample-rates vio_high_frequency=<rate>"}),"."]}),"\n"]}),"\n",(0,a.jsxs)(i.li,{children:["\n",(0,a.jsxs)(i.p,{children:[(0,a.jsx)(i.strong,{children:"Image Decoding Performance"}),": Image decoding is currently performed on CPU on Linux, so plotting speed might be slow depending on CPU load. To see smooth visualization, wait until Rerun caches some data then click play again, or use subsample options like ",(0,a.jsx)(i.code,{children:"--subsample-rates camera-rgb=2"})," to reduce the frame rate."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(i.h2,{id:"viewer_mps",children:"viewer_mps"}),"\n",(0,a.jsxs)(i.p,{children:["The ",(0,a.jsx)(i.code,{children:"viewer_mps"})," tool visualizes Aria data along with Machine Perception Services (MPS) outputs like SLAM trajectories, point clouds, eye gaze, and hand tracking results."]}),"\n",(0,a.jsx)(l.A,{alt:"Docusaurus themed image",sources:{light:(0,o.default)("/img/docs-research-tools/projectariatools/mps_viewer.png"),dark:(0,o.default)("/img/docs-research-tools/projectariatools/mps_viewer.png")}}),"\n",(0,a.jsx)(i.h3,{id:"basic-usage-1",children:"Basic Usage"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-bash",children:"viewer_mps --vrs path/to/recording.vrs\n"})}),"\n",(0,a.jsx)(i.h3,{id:"command-line-options-1",children:"Command Line Options"}),"\n",(0,a.jsx)(i.h4,{id:"input-files",children:"Input Files"}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.code,{children:"--vrs"}),": Path to VRS file"]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.code,{children:"--trajectory"}),": Path(s) to MPS trajectory files (supports multiple files)"]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.code,{children:"--points"}),": Path(s) to MPS global point cloud files (supports multiple files)"]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.code,{children:"--eyegaze"}),": Path to MPS eye gaze file"]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.code,{children:"--hands"}),": Path to MPS wrist and palm poses file"]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.code,{children:"--hands_all"}),": Path to MPS full hand tracking results file"]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.code,{children:"--mps_folder"}),": Path to MPS folder (overrides default ",(0,a.jsx)(i.code,{children:"<vrs_file>/mps"})," location)"]}),"\n"]}),"\n",(0,a.jsx)(i.h4,{id:"visualization-options",children:"Visualization Options"}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.code,{children:"--no_rectify_image"}),": Show raw fisheye RGB images without undistortion"]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.code,{children:"--web"}),": Run viewer in web browser instead of desktop app"]}),"\n"]}),"\n",(0,a.jsx)(i.h3,{id:"examples-1",children:"Examples"}),"\n",(0,a.jsx)(i.h4,{id:"auto-detect-mps-data",children:"Auto-detect MPS Data"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-bash",children:"# Automatically finds MPS data in <vrs_file>/mps folder\nviewer_mps --vrs recording.vrs\n"})}),"\n",(0,a.jsx)(i.h4,{id:"specify-individual-mps-files",children:"Specify Individual MPS Files"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-bash",children:"viewer_mps \\\n  --vrs recording.vrs \\\n  --trajectory trajectory/closed_loop_trajectory.csv \\\n  --points global_points/global_points.csv.gz \\\n  --eyegaze eye_gaze/general_eye_gaze.csv\n"})}),"\n",(0,a.jsx)(i.h4,{id:"web-browser-mode",children:"Web Browser Mode"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-bash",children:"viewer_mps \\\n  --vrs recording.vrs \\\n  --web\n"})}),"\n",(0,a.jsx)(i.h4,{id:"multiple-trajectories-and-point-clouds",children:"Multiple Trajectories and Point Clouds"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-bash",children:"viewer_mps \\\n  --trajectory trajectory1.csv trajectory2.csv \\\n  --points points1.csv points2.csv\n"})}),"\n",(0,a.jsx)(i.h3,{id:"what-youll-see-1",children:"What You'll See"}),"\n",(0,a.jsx)(i.p,{children:"The MPS viewer provides:"}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"3D Scene"}),": SLAM trajectory, point clouds, and device poses in 3D space"]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"Camera Views"}),": RGB camera feeds with overlaid eye gaze and hand tracking projections"]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"Hand Tracking"}),": 3D hand landmarks, skeleton connections, and wrist/palm poses"]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"Eye Gaze"}),": 3D gaze vectors and their projections onto camera images"]}),"\n"]}),"\n",(0,a.jsx)(i.p,{children:"This tool is particularly useful for validating MPS processing results and understanding the spatial relationships between different data modalities."})]})}function u(e={}){const{wrapper:i}={...(0,r.R)(),...e.components};return i?(0,a.jsx)(i,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}},28453:(e,i,s)=>{s.d(i,{R:()=>l,x:()=>o});var n=s(96540);const a={},r=n.createContext(a);function l(e){const i=n.useContext(r);return n.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:l(e.components),n.createElement(r.Provider,{value:i},e.children)}}}]);