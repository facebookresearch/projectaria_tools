"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[4520],{62058(e,n,r){r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"mps/benchmarks/performance","title":"Hand Tracking","description":"This page presents the performance evaluation of the MPS Hand Tracking algorithm for Aria Gen2 glasses.","source":"@site/docs-technical-specs/mps/benchmarks/performance.mdx","sourceDirName":"mps/benchmarks","slug":"/mps/benchmarks/performance","permalink":"/projectaria_tools/gen2/technical-specs/mps/benchmarks/performance","draft":false,"unlisted":false,"editUrl":"https://www.internalfb.com/code/fbsource/arvr/projects/ariane/aria_research_kit/projectaria_tools/website/docs-technical-specs/mps/benchmarks/performance.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Hand Tracking"},"sidebar":"technicalSpecsSidebar","previous":{"title":"Command Line Interface","permalink":"/projectaria_tools/gen2/technical-specs/mps/mps_cli_guide"},"next":{"title":"2D Image Coordinate System Conventions","permalink":"/projectaria_tools/gen2/technical-specs/coordinate/2d-coor"}}');var s=r(74848),i=r(28453);const a={sidebar_position:2,title:"Hand Tracking"},c="Hand Tracking Algorithm Benchmark",d={},o=[{value:"Benchmark Dataset",id:"benchmark-dataset",level:2},{value:"Dataset Specifications",id:"dataset-specifications",level:3},{value:"Participant Diversity",id:"participant-diversity",level:3},{value:"Recording Scenarios",id:"recording-scenarios",level:3},{value:"Ground Truth Annotations",id:"ground-truth-annotations",level:2},{value:"Evaluation Metrics",id:"evaluation-metrics",level:2},{value:"Results",id:"results",level:2}];function l(e){const n={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"hand-tracking-algorithm-benchmark",children:"Hand Tracking Algorithm Benchmark"})}),"\n",(0,s.jsx)(n.p,{children:"This page presents the performance evaluation of the MPS Hand Tracking algorithm for Aria Gen2 glasses."}),"\n",(0,s.jsx)(n.h2,{id:"benchmark-dataset",children:"Benchmark Dataset"}),"\n",(0,s.jsxs)(n.p,{children:["The MPS Hand Tracking algorithm is benchmarked on an internal dataset specifically designed for ",(0,s.jsx)(n.strong,{children:"hand-object interaction (HOI)"})," scenarios. These scenarios are particularly valuable for robotics applications and present significant challenges for hand tracking due to object-induced occlusions."]}),"\n",(0,s.jsx)(n.h3,{id:"dataset-specifications",children:"Dataset Specifications"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Property"}),(0,s.jsx)(n.th,{children:"Value"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Total Duration"}),(0,s.jsx)(n.td,{children:"1 hour"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Frame Rate"}),(0,s.jsx)(n.td,{children:"30 fps"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Cameras Used"}),(0,s.jsx)(n.td,{children:"All 4 CV cameras on Aria Gen2"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Number of Participants"}),(0,s.jsx)(n.td,{children:"7"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Number of Objects"}),(0,s.jsx)(n.td,{children:"20 everyday objects"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"participant-diversity",children:"Participant Diversity"}),"\n",(0,s.jsx)(n.p,{children:"Seven participants were recruited to ensure diversity across:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Ethnicity"}),"\n",(0,s.jsx)(n.li,{children:"Age"}),"\n",(0,s.jsx)(n.li,{children:"Gender"}),"\n",(0,s.jsx)(n.li,{children:"Hand size"}),"\n",(0,s.jsx)(n.li,{children:"Arm length"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"recording-scenarios",children:"Recording Scenarios"}),"\n",(0,s.jsx)(n.p,{children:"Each participant was asked to interact naturally with a pool of 20 everyday objects. The dataset captures:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Frequent hand occlusions"})," from objects or the other hand during natural interaction"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Out-of-field-of-view segments"})," where subjects' hands move outside the Aria Gen2 field of view"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"These challenging scenarios provide an end-to-end evaluation signal for Aria Gen2 hand tracking performance."}),"\n",(0,s.jsx)(n.h2,{id:"ground-truth-annotations",children:"Ground Truth Annotations"}),"\n",(0,s.jsxs)(n.p,{children:["Hand pose ground truth annotations follow the standard ",(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"https://github.com/facebookresearch/UmeTrack",children:"UmeTrack format"})})," and are generated using an internal marker-free reconstruction system with ",(0,s.jsx)(n.strong,{children:"millimeter-level keypoint accuracy"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"Thanks to the extensive field-of-view coverage of outside-in cameras in the reconstruction system, nearly all frames in the 1-hour VRS dataset have valid hand pose ground truth annotations."}),"\n",(0,s.jsx)(n.h2,{id:"evaluation-metrics",children:"Evaluation Metrics"}),"\n",(0,s.jsx)(n.p,{children:"We report the following metrics (lower is better for both):"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Metric"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.strong,{children:"MKPE"})," (Mean Keypoint Error)"]}),(0,s.jsx)(n.td,{children:"Average Euclidean distance between predicted and ground truth keypoints, measured in millimeters"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.strong,{children:"LTR"})," (Lose Track Ratio)"]}),(0,s.jsx)(n.td,{children:"Percentage of frames where tracking is lost"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"results",children:"Results"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Method"}),(0,s.jsx)(n.th,{children:"MKPE (mm) \u2193"}),(0,s.jsx)(n.th,{children:"LTR (%) \u2193"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"On-device HT"}),(0,s.jsx)(n.td,{children:"45.0"}),(0,s.jsx)(n.td,{children:"12.7"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"MPS HT (3.1.1)"}),(0,s.jsx)(n.td,{children:"20.1"}),(0,s.jsx)(n.td,{children:"8.6"})]})]})]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}},28453(e,n,r){r.d(n,{R:()=>a,x:()=>c});var t=r(96540);const s={},i=t.createContext(s);function a(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);