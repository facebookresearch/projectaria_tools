"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[4368],{28453:(e,t,r)=>{r.d(t,{R:()=>s,x:()=>c});var i=r(96540);const o={},n=i.createContext(o);function s(e){const t=i.useContext(n);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function c(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(n.Provider,{value:t},e.children)}},42718:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>a,contentTitle:()=>c,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"mps/data_formats/mps_trajectory","title":"Trajectory","description":"6DoF trajectory data is generated as part of SLAM Machine Perception Services (MPS) requests:","source":"@site/docs-technical-specs/mps/data_formats/mps_trajectory.mdx","sourceDirName":"mps/data_formats","slug":"/mps/data_formats/mps_trajectory","permalink":"/projectaria_tools/gen2/technical-specs/mps/data_formats/mps_trajectory","draft":false,"unlisted":false,"editUrl":"https://www.internalfb.com/code/fbsource/arvr/projects/ariane/aria_research_kit/projectaria_tools/website/docs-technical-specs/mps/data_formats/mps_trajectory.mdx","tags":[],"version":"current","sidebarPosition":20,"frontMatter":{"sidebar_position":20,"title":"Trajectory"},"sidebar":"technicalSpecsSidebar","previous":{"title":"Basics","permalink":"/projectaria_tools/gen2/technical-specs/mps/data_formats/basics"},"next":{"title":"Semi-Dense Point Cloud","permalink":"/projectaria_tools/gen2/technical-specs/mps/data_formats/mps_pointcloud"}}');var o=r(74848),n=r(28453);const s={sidebar_position:20,title:"Trajectory"},c="MPS output - Trajectory",a={},d=[{value:"Open loop trajectory",id:"open-loop-trajectory",level:2},{value:"Closed loop trajectory",id:"closed-loop-trajectory",level:2}];function l(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,n.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"mps-output---trajectory",children:"MPS output - Trajectory"})}),"\n",(0,o.jsx)(t.p,{children:"6DoF trajectory data is generated as part of SLAM Machine Perception Services (MPS) requests:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"open_loop_trajectory.csv"})," file"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"closed_loop_trajectory.csv"})," file"]}),"\n"]}),"\n",(0,o.jsxs)(t.p,{children:["This data can be visualized using the MPS Viewer in ",(0,o.jsx)(t.a,{href:"/research-tools/projectariatools/pythontutorials/mps",children:"Python"}),"."]}),"\n",(0,o.jsx)(t.h2,{id:"open-loop-trajectory",children:"Open loop trajectory"}),"\n",(0,o.jsx)(t.p,{children:"Open loop trajectory is the high frequency (IMU rate, which is 1kHz) odometry estimation output by the visual-inertial odometry (VIO), in an arbitrary odometry coordinate frame. The estimation includes pose and dynamics (translational and angular velocities)."}),"\n",(0,o.jsx)(t.p,{children:"The open loop trajectory has good \u201crelative\u201d and \u201clocal\u201d accuracy: the relative transformation between two poses is accurate when the time span between two frames is short (within a few minutes). However, the open loop trajectory has increased drift error accumulated over time spent and travel distance. Consider using closed loop trajectory if you are looking for trajectory without drift error."}),"\n",(0,o.jsxs)(t.p,{children:["For the utility function to load the open loop trajectory in Python, please check the ",(0,o.jsx)(t.a,{href:"/research-tools/projectariatools/pythontutorials/mps#loading-closed-loop-trajectory",children:"python notebook tutorial"})]}),"\n",(0,o.jsxs)(t.table,{children:[(0,o.jsx)(t.thead,{children:(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.th,{children:"Column"}),(0,o.jsx)(t.th,{children:"Type"}),(0,o.jsx)(t.th,{children:"Description"})]})}),(0,o.jsxs)(t.tbody,{children:[(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"tracking_timestamp_us"})}),(0,o.jsx)(t.td,{children:"int"}),(0,o.jsx)(t.td,{children:"Aria device timestamp in microseconds"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"utc_timestamp_ns"})}),(0,o.jsx)(t.td,{children:"int"}),(0,o.jsx)(t.td,{children:"Wall clock UTC time in nanoseconds. If not available, the value will be -1"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"session_uid"})}),(0,o.jsx)(t.td,{children:"string"}),(0,o.jsx)(t.td,{children:"Unique identifier of the odometry coordinate frame. When the session_uid is the same, poses and velocities are defined in the same coordinate frame"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"{tx,ty,tz,qx,qy,qz,qw}_odometry_device"})}),(0,o.jsx)(t.td,{children:"float"}),(0,o.jsx)(t.td,{children:"Pose of the device coordinate frame in odometry frame T_odometry_device, include translation (tx, ty, tz) in meters and rotation quaternion (qx, qy, qz, qw)"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"device_linear_velocity_{x,y,z}_odometry"})}),(0,o.jsx)(t.td,{children:"float"}),(0,o.jsx)(t.td,{children:"Velocity of device coordinate frame in odometry frame, (x, y, z) in meter/s"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"angular_velocity_{x,y,z}_device"})}),(0,o.jsx)(t.td,{children:"float"}),(0,o.jsx)(t.td,{children:"Angular velocity of device coordinate frame in device frame, (x, y, z) in rad/s"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"gravity_{x,y,z}_odometry"})}),(0,o.jsx)(t.td,{children:"float"}),(0,o.jsx)(t.td,{children:"Earth gravity vector in odometry frame, (x, y, z) in meter/s^2. This vector is pointing toward the ground, and includes gravitation and centrifugal forces from earth rotation"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"quality_score"})}),(0,o.jsx)(t.td,{children:"float"}),(0,o.jsx)(t.td,{children:"A quality score between 0.0 to 1.0. The larger the score is, the higher confidence the estimation has higher quality"})]})]})]}),"\n",(0,o.jsx)(t.h2,{id:"closed-loop-trajectory",children:"Closed loop trajectory"}),"\n",(0,o.jsx)(t.p,{children:"Closed loop trajectory is the high frequency (IMU rate, which is 1kHz) pose estimation output by our mapping process, in an arbitrary gravity aligned world coordinate frame. The estimation includes pose and dynamics (translational and angular velocities)."}),"\n",(0,o.jsx)(t.p,{children:"Closed loop trajectories are fully bundle adjusted with detected loop closures, reducing the VIO drift which is present in the open loop trajectories. However, due to the loop closure correction, the \u201crelative\u201d and \u201clocal\u201d trajectory accuracy within a short time span (i.e. seconds) might be worse compared to open loop trajectories."}),"\n",(0,o.jsx)(t.p,{children:"In some open datasets we also share and use this format for trajectory pose ground truth from simulation or Optitrack, and the files will be called in a different file name aria_gt_trajectory.csv."}),"\n",(0,o.jsxs)(t.p,{children:["For the utility function to load the closed loop trajectory in Python and C++, please check the ",(0,o.jsx)(t.a,{href:"/research-tools/projectariatools/pythontutorials/mps#loading-open-loop-trajectory",children:"code examples"})]}),"\n",(0,o.jsxs)(t.table,{children:[(0,o.jsx)(t.thead,{children:(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.th,{children:"Column"}),(0,o.jsx)(t.th,{children:"Type"}),(0,o.jsx)(t.th,{children:"Description"})]})}),(0,o.jsxs)(t.tbody,{children:[(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"graph_uid"})}),(0,o.jsx)(t.td,{children:"string"}),(0,o.jsx)(t.td,{children:"Unique identifier of the world coordinate frame"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"tracking_timestamp_us"})}),(0,o.jsx)(t.td,{children:"int"}),(0,o.jsx)(t.td,{children:"Aria device timestamp in microsecond"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"utc_timestamp_ns"})}),(0,o.jsx)(t.td,{children:"int"}),(0,o.jsx)(t.td,{children:"Wall clock UTC time in nanosecond. If not available, the value will be -1"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"{tx,ty,tz,qx,qy,qz,qw}_world_device"})}),(0,o.jsx)(t.td,{children:"float"}),(0,o.jsx)(t.td,{children:"Pose of the device coordinate frame in world frame T_world_device, translation (tx, ty, tz) in meters and rotation quaternion (qx, qy, qz, qw)"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"device_linear_velocity_{x,y,z}_device"})}),(0,o.jsx)(t.td,{children:"float"}),(0,o.jsx)(t.td,{children:"Velocity of device coordinate frame in device frame, (x, y, z) in meter/s"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"angular_velocity_{x,y,z}_device"})}),(0,o.jsx)(t.td,{children:"float"}),(0,o.jsx)(t.td,{children:"Angular velocity of device coordinate frame in device frame, (x, y, z) in rad/s"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"gravity_{x,y,z}_world"})}),(0,o.jsx)(t.td,{children:"float"}),(0,o.jsx)(t.td,{children:"Gravity vector (x, y, z) in the world frame, in meter/s^2. MPS output will all have fixed value` [0, 0, -9.81]\u2019, while other source (e.g. simulation or Optitrack ground truth) may give different values"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.code,{children:"quality_score"})}),(0,o.jsx)(t.td,{children:"float"}),(0,o.jsx)(t.td,{children:"A quality score between 0.0 to 1.0. The larger the score is, the higher confidence the estimation has higher quality`"})]})]})]})]})}function h(e={}){const{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}}}]);