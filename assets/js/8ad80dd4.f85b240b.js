"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[9838],{7456:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>c,default:()=>u,frontMatter:()=>d,metadata:()=>s,toc:()=>p});const s=JSON.parse('{"id":"open_datasets/open_datasets","title":"Open Datasets","description":"This section provides information about how to use Project Aria\'s open data.","source":"@site/docs/open_datasets/open_datasets.mdx","sourceDirName":"open_datasets","slug":"/open_datasets/","permalink":"/projectaria_tools/docs/open_datasets/","draft":false,"unlisted":false,"editUrl":"https://github.com/facebookresearch/projectaria_tools/tree/main/website/docs/open_datasets/open_datasets.mdx","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"sidebar_position":10,"title":"Open Datasets"},"sidebar":"tutorialSidebar","previous":{"title":"Fix USB Driver Issues in Linux","permalink":"/projectaria_tools/docs/ARK/troubleshooting/linux_usb_driver"},"next":{"title":"Dataset Download","permalink":"/projectaria_tools/docs/open_datasets/dataset_download"}}');var o=a(74848),i=a(28453),n=a(98180),r=a(67581);const d={sidebar_position:10,title:"Open Datasets"},c="Project Aria Open Datasets",l={},p=[];function h(e){const t={a:"a",h1:"h1",header:"header",li:"li",p:"p",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"project-aria-open-datasets",children:"Project Aria Open Datasets"})}),"\n",(0,o.jsx)(t.p,{children:"This section provides information about how to use Project Aria's open data."}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.a,{href:"/projectaria_tools/docs/open_datasets/dataset_explorer/",children:"Aria Dataset Explorer"})," - a centralized hub for Project Aria public datasets that helps users efficiently find, preview and download Aria data"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.a,{href:"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/",children:"Aria Everyday Activities Dataset"})," - multiple activity sequences where 1-2 users wearing Project Aria glasses participate in everyday activities to capture time synchronized data in a shared world location"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.a,{href:"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/",children:"Aria Digital Twin Dataset"})," - raw and synthesized sensor data from Project Aria glasses, combined with ground truth data generated using a motion capture system including depth images, device trajectories, object trajectories and bounding boxes, and human tracking"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.a,{href:"/projectaria_tools/docs/open_datasets/object_explorer",children:"DTC Object Explorer"})," - an interactive webtool that allows researchers to find, visualize, and download high-quality ",(0,o.jsx)(t.a,{href:"https://www.projectaria.com/datasets/dtc/",children:"Digital Twin"})," object models in the common GLB format."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.a,{href:"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/",children:"Aria Synthetic Environments Dataset"})," - a large scale dataset of 100K unique procedurally-generated scenes of interior layouts of apartments filled with 3D objects, and simulated with the sensor characteristics of Aria glasses"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.a,{href:"/projectaria_tools/docs/open_datasets/ego-exo4d/",children:"Ego-Exo4D Dataset"})," - more than 800 participants from 13 cities worldwide performed these activities in 131 different natural scene contexts, yielding long-form captures from 1 to 42 minutes each and 1,422 hours of video combined"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.a,{href:"/projectaria_tools/docs/open_datasets/hot3d",children:"HOT3D Dataset"})," - a new benchmark dataset for vision-based understanding of 3D hand-object interactions"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.a,{href:"/projectaria_tools/docs/open_datasets/ritw",children:"Reading in the Wild Dataset"})," - a new benchmark dataset designed to inform models that determine whether or not subjects are reading."]}),"\n"]}),"\n",(0,o.jsx)(r.A,{alt:"data collections",sources:{light:(0,n.default)("/img/open_datasets/data_collections.png"),dark:(0,n.default)("/img/open_datasets/data_collections_dark.png")}})]})}function u(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},28453:(e,t,a)=>{a.d(t,{R:()=>n,x:()=>r});var s=a(96540);const o={},i=s.createContext(o);function n(e){const t=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:n(e.components),s.createElement(i.Provider,{value:t},e.children)}}}]);