"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[1887],{3527:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"open_datasets/aria_synthetic_environments_dataset/ase_data_tools","title":"Data Tools and Visualization","description":"We provide different functions and code snippets in Python to load Aria Synthetic Environments (ASE) data from a sequence and associate/interpret them with each other. The contents of each scene/sequence are detailed in Data Format.","source":"@site/docs/open_datasets/aria_synthetic_environments_dataset/ase_data_tools.mdx","sourceDirName":"open_datasets/aria_synthetic_environments_dataset","slug":"/open_datasets/aria_synthetic_environments_dataset/ase_data_tools","permalink":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_data_tools","draft":false,"unlisted":false,"editUrl":"https://github.com/facebookresearch/projectaria_tools/tree/main/website/docs/open_datasets/aria_synthetic_environments_dataset/ase_data_tools.mdx","tags":[],"version":"current","sidebarPosition":40,"frontMatter":{"sidebar_position":40,"title":"Data Tools and Visualization"},"sidebar":"tutorialSidebar","previous":{"title":"Data Format","permalink":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_data_format"},"next":{"title":"ASE Challenges","permalink":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_challenges"}}');var i=n(74848),s=n(28453);const o={sidebar_position:40,title:"Data Tools and Visualization"},r="Synthetic Environments Data Tools and Visualization",l={},d=[{value:"Data Helper Tools",id:"data-helper-tools",level:2},{value:"Visualization",id:"visualization",level:2},{value:"Python sample",id:"python-sample",level:2},{value:"Python Notebook",id:"python-notebook",level:2},{value:"Part 1: 3D visualization of the scene",id:"part-1-3d-visualization-of-the-scene",level:3},{value:"Part 2: Loading and Plotting Images and Image Annotations",id:"part-2-loading-and-plotting-images-and-image-annotations",level:3},{value:"Part 3: Projecting Points into Images",id:"part-3-projecting-points-into-images",level:3}];function c(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"synthetic-environments-data-tools-and-visualization",children:"Synthetic Environments Data Tools and Visualization"})}),"\n",(0,i.jsxs)(t.p,{children:["We provide different functions and code snippets in Python to load Aria Synthetic Environments (ASE) data from a sequence and associate/interpret them with each other. The contents of each scene/sequence are detailed in ",(0,i.jsxs)(t.strong,{children:[(0,i.jsx)(t.a,{href:"ase_data_format",children:"Data Format"}),"."]})]}),"\n",(0,i.jsxs)(t.p,{children:["They provide a set of helper functions to use the data efficiently and also visualize them. All of these snippets are placed under  ",(0,i.jsx)(t.strong,{children:"projectaria_tools/tree/main/projects/AriaSyntheticEnvironment/tutorial/code_snippets/"})]}),"\n",(0,i.jsx)(t.h2,{id:"data-helper-tools",children:"Data Helper Tools"}),"\n",(0,i.jsx)(t.p,{children:"These helper functions are broadly categorized into the following types:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["Data interpreter: ",(0,i.jsx)(t.code,{children:"interpreter.py"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Provides an interpreter for the ASE Scene Language to convert them into a 3D model in the form of bounding boxes"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["Data readers: ",(0,i.jsx)(t.code,{children:"readers.py"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["Provide readers for the:","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.code,{children:"ASE Scene Language"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.code,{children:"Ground-truth trajectory"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.code,{children:"Semi-dense Map points"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["Data Plotters: ",(0,i.jsx)(t.code,{children:"plotters.py"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["Provide simple plotting functions for the:","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.code,{children:"3D scene from ASE Scene Language"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.code,{children:"Ground-truth trajectory"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.code,{children:"Semi Dense Map points"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"visualization",children:"Visualization"}),"\n",(0,i.jsx)(t.h2,{id:"python-sample",children:"Python sample"}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.code,{children:"Viewer_projects_ase"})," displays an interactive view of an ASE sequence with ",(0,i.jsx)(t.a,{href:"/docs/data_utilities/visualization/visualization_python#rerun",children:"Rerun"}),". It allows you to see all data in 3D context."]}),"\n",(0,i.jsxs)(t.p,{children:["You can call as the following (",(0,i.jsx)(t.code,{children:"frame_id"})," being optional):"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"viewer_projects_ase --dataset_path ase_data/7  --frame_id 745\n"})}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"ASE Viewer Screenshot",src:n(36778).A+"",width:"1999",height:"706"})}),"\n",(0,i.jsx)(t.admonition,{type:"tip",children:(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"The timeline enables you to switch before device_time and frame_id to know to which image frame_id a camera pose corresponds to"}),"\n",(0,i.jsx)(t.li,{children:"The 3D world view is clickable, you can quickly select an object and see its instance name"}),"\n"]})}),"\n",(0,i.jsx)(t.h2,{id:"python-notebook",children:"Python Notebook"}),"\n",(0,i.jsxs)(t.p,{children:["We also provide Jupyter notebooks to visualize the data for each sequence. To get started download ASE data following steps from ",(0,i.jsx)(t.a,{href:"ase_download_dataset",children:"Dataset Download"})]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"cd /path_to/projectaria_tools\n\njupyter notebook projects/AriaSyntheticEnvironment/tutorial/ase_tutorial_notebook.ipynb\n"})}),"\n",(0,i.jsx)(t.h3,{id:"part-1-3d-visualization-of-the-scene",children:"Part 1: 3D visualization of the scene"}),"\n",(0,i.jsx)(t.p,{children:"This section will introduce the dataset\u2019s 3D components as well as code snippets to help users get familiar with them."}),"\n",(0,i.jsx)(t.p,{children:"You will be taken through examples of how to load the 3D dataset annotations namely: the ground-truth trajectory, the ASE Scene Language, and the Semi-dense Map point cloud. In addition, we provide examples of how they can each be plotted."}),"\n",(0,i.jsx)(t.p,{children:"At the end of the section you should see 3D plots containing:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"The Semi-dense Map point cloud,"}),"\n",(0,i.jsx)(t.li,{children:"The layout annotations, visualized as 3D box wireframes,"}),"\n",(0,i.jsx)(t.li,{children:"The trajectory plotted as a dotted line in 3D."}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["Example scene visualization:\n",(0,i.jsx)(t.img,{alt:"Image: 3D visualization within a house",src:n(62808).A+"",width:"1716",height:"1310"})]}),"\n",(0,i.jsx)(t.h3,{id:"part-2-loading-and-plotting-images-and-image-annotations",children:"Part 2: Loading and Plotting Images and Image Annotations"}),"\n",(0,i.jsxs)(t.p,{children:["Since the file structure and format are straightforward, the code consists of very simple PIL and matplotlib code to show the 3 images (RGB, depth and instance maps) side-by-side:\n",(0,i.jsx)(t.img,{alt:"Image: sample_rgb_depth_instance_images.png",src:n(71295).A+"",width:"2696",height:"882"})]}),"\n",(0,i.jsx)(t.h3,{id:"part-3-projecting-points-into-images",children:"Part 3: Projecting Points into Images"}),"\n",(0,i.jsx)(t.p,{children:"Running the final part of the notebook will load the camera calibration, as well as the pointcloud, trajectory and select a random frame. Then given the device pose from the trajectory, we project the points into the frame."}),"\n",(0,i.jsx)(t.p,{children:"Points that project outside of the valid radius, should not be plotted"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"Image: sample_rgb_depth_instance_images.png",src:n(67091).A+"",width:"928",height:"934"})})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>r});var a=n(96540);const i={},s=a.createContext(i);function o(e){const t=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),a.createElement(s.Provider,{value:t},e.children)}},36778:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/rerun-ase-a51e8d77401c6c66250f11bfec051201.png"},62808:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/scene_visualisation-be66c7f78393be5b4b88951f1f6fc04e.png"},67091:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/projecting_points-2d0baeceecc3530917fbd66d500311e3.png"},71295:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/sample_rgb_depth_instance_images-a53f1903a7bf8f4eb8a2970134211e1c.png"}}]);