"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[3896],{28453:(e,t,a)=>{a.d(t,{R:()=>s,x:()=>o});var i=a(96540);const r={},n=i.createContext(r);function s(e){const t=i.useContext(n);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(n.Provider,{value:t},e.children)}},64688:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"open_datasets/aria_everyday_objects/aria_everyday_objects","title":"Aria Everyday Objects Dataset","description":"Overview","source":"@site/docs/open_datasets/aria_everyday_objects/aria_everyday_objects.mdx","sourceDirName":"open_datasets/aria_everyday_objects","slug":"/open_datasets/aria_everyday_objects/","permalink":"/projectaria_tools/docs/open_datasets/aria_everyday_objects/","draft":false,"unlisted":false,"editUrl":"https://github.com/facebookresearch/projectaria_tools/tree/main/website/docs/open_datasets/aria_everyday_objects/aria_everyday_objects.mdx","tags":[],"version":"current","sidebarPosition":71,"frontMatter":{"sidebar_position":71,"title":"Aria Everyday Objects Dataset"},"sidebar":"tutorialSidebar","previous":{"title":"HOT3D Dataset","permalink":"/projectaria_tools/docs/open_datasets/hot3d"},"next":{"title":"Reading in the Wild dataset","permalink":"/projectaria_tools/docs/open_datasets/ritw"}}');var r=a(74848),n=a(28453);const s={sidebar_position:71,title:"Aria Everyday Objects Dataset"},o="Aria Everyday Objects Dataset",c={},d=[{value:"Overview",id:"overview",level:2},{value:"What is in the dataset?",id:"what-is-in-the-dataset",level:2},{value:"How to download the dataset?",id:"how-to-download-the-dataset",level:2},{value:"BibTeX Citation",id:"bibtex-citation",level:2},{value:"License",id:"license",level:2},{value:"Contributors",id:"contributors",level:2}];function l(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,n.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"aria-everyday-objects-dataset",children:"Aria Everyday Objects Dataset"})}),"\n",(0,r.jsx)(t.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(t.p,{children:"Aria Everyday Objects (AEO) is a small, challenging 3D object detection dataset for egocentric data.\nAEO consists of approximately 45 minutes of egocentric data across 25 sequences captured by non-computer vision experts collected in a diverse set of locations throughout the US.\nOriented 3D bounding boxes have been annotated for each sequence. Annotation is done in 3D, using the camera calibration,\nSLAM trajectory and SLAM semi-dense point cloud to assist with annotation. 1037 3D object bounding box instances across 17 classes: Bed, Chair, Couch, Door, Floor, Lamp, Mirror, Plant, Refrigerator, Screen, Sink, Storage, Table, Wall, WallArt, WasherDryer, and Window. The dataset is designed to accelerate research in egocentric 3D perception."}),"\n",(0,r.jsxs)(t.p,{children:["For more details, please visit the ",(0,r.jsx)(t.a,{href:"https://www.projectaria.com/datasets/aeo/",children:"project page"}),", view the dataset ",(0,r.jsx)(t.a,{href:"https://explorer.projectaria.com/aeo",children:"online"}),",\nexplore the ",(0,r.jsx)(t.a,{href:"https://github.com/facebookresearch/efm3d",children:"github repository"})," and read the ",(0,r.jsx)(t.a,{href:"https://arxiv.org/abs/2406.10224",children:"ECCV 2024 paper"}),"."]}),"\n",(0,r.jsx)(t.h2,{id:"what-is-in-the-dataset",children:"What is in the dataset?"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Aria RGB video at 10 Hz"}),"\n",(0,r.jsx)(t.li,{children:"Aria SLAM x 2 video at 10 Hz"}),"\n",(0,r.jsx)(t.li,{children:"Aria IMU x 2 data"}),"\n",(0,r.jsx)(t.li,{children:"High-quality static 3D bounding boxes of 17 object classes"}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"how-to-download-the-dataset",children:"How to download the dataset?"}),"\n",(0,r.jsxs)(t.p,{children:["Visit the ",(0,r.jsx)(t.a,{href:"https://www.projectaria.com/datasets/aeo/",children:"AEO webpage here"}),". Scroll down, enter your email, then click the button \u201cAccess the Dataset\u201d. Follow the instructions there."]}),"\n",(0,r.jsx)(t.h2,{id:"bibtex-citation",children:"BibTeX Citation"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{children:"@article{straub24efm,\n      title={EFM3D: A Benchmark for Measuring Progress Towards 3D Egocentric Foundation Models},\n      author={Julian Straub and Daniel DeTone and Tianwei Shen and Nan Yang and Chris Sweeney and Richard Newcombe},\n      booktitle={arXiv preprint arXiv:2406.10224},\n      year={2024},\n      url={https://arxiv.org/abs/2406.10224},\n}\n"})}),"\n",(0,r.jsx)(t.h2,{id:"license",children:"License"}),"\n",(0,r.jsxs)(t.p,{children:["AEO dataset is released under a non-commercial license described ",(0,r.jsx)(t.a,{href:"https://www.projectaria.com/datasets/aeo/license/",children:"here"}),"."]}),"\n",(0,r.jsx)(t.h2,{id:"contributors",children:"Contributors"}),"\n",(0,r.jsx)(t.p,{children:"Julian Straub, Daniel DeTone, Tianwei Shen, Nan Yang, Chris Sweeney, Richard Newcombe"})]})}function h(e={}){const{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}}}]);