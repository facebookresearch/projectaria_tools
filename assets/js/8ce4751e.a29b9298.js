"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[429],{28453:(e,t,a)=>{a.d(t,{R:()=>r,x:()=>d});var n=a(96540);const i={},s=n.createContext(i);function r(e){const t=n.useContext(s);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),n.createElement(s.Provider,{value:t},e.children)}},56272:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/camera-comparison-ff5e0ad9c71f40c2a6700d97aa9c129c.png"},57972:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/subset-table-210e91c55dd6be2231beb2e3d3054a86.png"},93405:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/image-grid-8f58f530c4fddace43bacbe5f9a4bdcf.png"},93415:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>r,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"open_datasets/ritw","title":"Reading in the Wild dataset","description":"Reading in the Wild (RitW) is a new benchmark dataset designed to inform models that determine whether or not subjects are reading. The dataset contains 100 hours of egocentric recordings, capturing 1716 sequences of individuals engaged in reading and non-reading activities in unconstrained environments.","source":"@site/docs/open_datasets/ritw.mdx","sourceDirName":"open_datasets","slug":"/open_datasets/ritw","permalink":"/projectaria_tools/docs/open_datasets/ritw","draft":false,"unlisted":false,"editUrl":"https://github.com/facebookresearch/projectaria_tools/tree/main/website/docs/open_datasets/ritw.mdx","tags":[],"version":"current","sidebarPosition":80,"frontMatter":{"sidebar_position":80,"title":"Reading in the Wild dataset"},"sidebar":"tutorialSidebar","previous":{"title":"Aria Everyday Objects Dataset","permalink":"/projectaria_tools/docs/open_datasets/aria_everyday_objects/"},"next":{"title":"Open Models","permalink":"/projectaria_tools/docs/open_models/"}}');var i=a(74848),s=a(28453);const r={sidebar_position:80,title:"Reading in the Wild dataset"},d="Reading in the Wild dataset",o={},l=[{value:"Subsets",id:"subsets",level:2},{value:"Download the data",id:"download-the-data",level:2},{value:"Seattle subset",id:"seattle-subset",level:3},{value:"Columbus subset",id:"columbus-subset",level:3},{value:"Data Explorer",id:"data-explorer",level:2},{value:"GitHub repo",id:"github-repo",level:2},{value:"Additional info",id:"additional-info",level:2}];function c(e){const t={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"reading-in-the-wild-dataset",children:"Reading in the Wild dataset"})}),"\n",(0,i.jsx)(t.p,{children:"Reading in the Wild (RitW) is a new benchmark dataset designed to inform models that determine whether or not subjects are reading. The dataset contains 100 hours of egocentric recordings, capturing 1716 sequences of individuals engaged in reading and non-reading activities in unconstrained environments."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"A grid of captures displaying participants engaged in various activities.",src:a(93405).A+"",width:"400",height:"301"})}),"\n",(0,i.jsx)(t.p,{children:"The dataset contains:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"Video captures from Aria headsets that include data from 2 SLAM cameras, 1 RGB camera, 2 IMUs, 2 eye-tracking cameras (60 Hz), 1 magnetometer, 1 barometer, and audio, captured with Profile 28."}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"Metadata containing information about the reading material and activity categories."}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"/projectaria_tools/docs/data_formats/mps/mps_eye_gaze",children:"Eye Gaze MPS data"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"/projectaria_tools/docs/data_formats/mps/slam/mps_pointcloud",children:"Semi-Dense Point Cloud MPS data"}),"."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"A display of images captured from different kinds of cameras and how they map onto things like gaze and pose estimation.",src:a(56272).A+"",width:"312",height:"400"})}),"\n",(0,i.jsx)(t.h2,{id:"subsets",children:"Subsets"}),"\n",(0,i.jsxs)(t.p,{children:["The Reading in the Wild dataset can be further divided into two subsets that were collected independently of each other: the ",(0,i.jsx)(t.strong,{children:"Seattle"})," dataset and the ",(0,i.jsx)(t.strong,{children:"Columbus"})," dataset."]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Seattle - This subset was collected for training, validation, and testing purposes. It focuses on reading and non-reading activities in diverse scenarios, meaning it covers a wide variety of participants, reading modes, written materials, and more. It contains a mix of normal negative (no text present) and hard negative (text present but not being read) examples, as well as mixed sequences that alternate between reading and not reading. These data were collected in homes, office spaces, libraries, and the outdoors."}),"\n",(0,i.jsx)(t.li,{children:"Columbus - This subset was collected to find cases where models intended to discern whether participants are reading encounter failure points. It contains examples of hard negatives (where text is present but not being read), searching/browsing (which gives confusing gaze patterns), and the reading of non-English texts (where reading direction differs)."}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"A table illustrating the differences between the Seattle and Columbus datasets.",src:a(57972).A+"",width:"1141",height:"215"})}),"\n",(0,i.jsx)(t.h2,{id:"download-the-data",children:"Download the data"}),"\n",(0,i.jsxs)(t.p,{children:["All RitW data is available at ",(0,i.jsx)(t.a,{href:"https://www.projectaria.com/datasets/reading-in-the-wild/",children:"https://www.projectaria.com/datasets/reading-in-the-wild/"}),", but the process differs depending on whether you want to download the Seattle subset or the Columbus subset."]}),"\n",(0,i.jsx)(t.h3,{id:"seattle-subset",children:"Seattle subset"}),"\n",(0,i.jsxs)(t.p,{children:["This dataset is owned and distributed by Meta with a CC-by-NC4 license. You can request and download the dataset ",(0,i.jsx)(t.a,{href:"https://www.projectaria.com/datasets/reading-in-the-wild/#download-dataset",children:"here"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["Alternatively, you can access the dataset through the ",(0,i.jsx)(t.a,{href:"https://explorer.projectaria.com/ritw",children:"Dataset Explorer"}),", which provides a convenient way to visualize the data and selectively download specific sequences."]}),"\n",(0,i.jsx)(t.h3,{id:"columbus-subset",children:"Columbus subset"}),"\n",(0,i.jsxs)(t.p,{children:["This dataset is owned and distributed by The Ohio State University (OSU) with an Apache2 license. Please refer to the ",(0,i.jsx)(t.a,{href:"https://github.com/AIoT-MLSys-Lab/Reading-in-the-Wild-Columbus/",children:"official OSU repository"})," for access and licensing information."]}),"\n",(0,i.jsx)(t.h2,{id:"data-explorer",children:"Data Explorer"}),"\n",(0,i.jsxs)(t.p,{children:["You can explore the Seattle Subset using Data Explorer ",(0,i.jsx)(t.a,{href:"https://explorer.projectaria.com/ritw",children:"here"}),"."]}),"\n",(0,i.jsx)(t.h2,{id:"github-repo",children:"GitHub repo"}),"\n",(0,i.jsxs)(t.p,{children:["You can find the code for the Reading Recognition Model ",(0,i.jsx)(t.a,{href:"https://github.com/facebookresearch/reading_in_the_wild",children:"here"}),"."]}),"\n",(0,i.jsx)(t.h2,{id:"additional-info",children:"Additional info"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://www.projectaria.com/reading-in-the-wild/",children:"The dataset"})," - Learn more about the dataset and how to get access to it."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://arxiv.org/abs/2505.24848",children:"Reading Recognition in the Wild"})," - Read the original research paper that RitW is based on."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://www.projectaria.com/news/introducing-reading-recognition-in-the-wild/",children:"Blog post"})," - Read the blog post that announced Reading in the Wild."]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}}}]);