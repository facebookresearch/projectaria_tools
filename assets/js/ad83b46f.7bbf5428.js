"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[9909],{37753:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/projectaria_tools/docs/intro","label":"Introduction to Project Aria Docs","docId":"intro","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/faq","label":"Project Aria FAQ","docId":"faq","unlisted":false},{"type":"category","label":"Technical Specifications","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/tech_spec/hardware_spec","label":"Hardware Specifications","docId":"tech_spec/hardware_spec","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/tech_spec/recording_profiles","label":"Recording Profiles","docId":"tech_spec/recording_profiles","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/tech_spec/device_calibration","label":"Device Calibration","docId":"tech_spec/device_calibration","unlisted":false}],"href":"/projectaria_tools/docs/tech_spec/"},{"type":"category","label":"Data Formats","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Aria VRS","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/data_formats/aria_vrs/aria_vrs_format","label":"Format","docId":"data_formats/aria_vrs/aria_vrs_format","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_formats/aria_vrs/timestamps_in_aria_vrs","label":"Timestamp Definitions","docId":"data_formats/aria_vrs/timestamps_in_aria_vrs","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_formats/aria_vrs/aria_vrs_command_line","label":"VRS command line tool","docId":"data_formats/aria_vrs/aria_vrs_command_line","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_formats/aria_vrs/aria_vrsplayer","label":"VRSPlayer","docId":"data_formats/aria_vrs/aria_vrsplayer","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_formats/aria_vrs/aria_vrs_tools_installation","label":"VRS Tools installation","docId":"data_formats/aria_vrs/aria_vrs_tools_installation","unlisted":false}],"href":"/projectaria_tools/docs/data_formats/aria_vrs/"},{"type":"category","label":"MPS Outputs","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/data_formats/mps/mps_summary","label":"Basics","docId":"data_formats/mps/mps_summary","unlisted":false},{"type":"category","label":"SLAM","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/data_formats/mps/slam/mps_trajectory","label":"Trajectory","docId":"data_formats/mps/slam/mps_trajectory","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_formats/mps/slam/mps_pointcloud","label":"Semi-Dense Point Cloud","docId":"data_formats/mps/slam/mps_pointcloud","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_formats/mps/slam/mps_calibration","label":"Calibration Data","docId":"data_formats/mps/slam/mps_calibration","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_formats/mps/slam/mps_multi_slam","label":"Multi-SLAM","docId":"data_formats/mps/slam/mps_multi_slam","unlisted":false}],"href":"/projectaria_tools/docs/data_formats/mps/slam/"},{"type":"link","href":"/projectaria_tools/docs/data_formats/mps/mps_eye_gaze","label":"Eye Gaze","docId":"data_formats/mps/mps_eye_gaze","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_formats/mps/hand_tracking/","label":"Hand Tracking","docId":"data_formats/mps/hand_tracking/hand_tracking","unlisted":false}]},{"type":"category","label":"Coordinate Conventions","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/data_formats/coordinate_convention/2d_image_coordinate_system_convention","label":"2D Image Coordinate System Conventions","docId":"data_formats/coordinate_convention/2d_image_coordinate_system_convention","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_formats/coordinate_convention/3d_coordinate_frame_convention","label":"3D Coordinate Frame Conventions","docId":"data_formats/coordinate_convention/3d_coordinate_frame_convention","unlisted":false}]}],"href":"/projectaria_tools/docs/data_formats/"},{"type":"category","label":"Project Aria Tools","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/data_utilities/getting_started","label":"Getting Started","docId":"data_utilities/getting_started","unlisted":false},{"type":"category","label":"Installation Guide","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/data_utilities/installation/download_codebase","label":"Download Codebase","docId":"data_utilities/installation/download_codebase","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/installation/download_mps_sample_data","label":"Download MPS Sample Data","docId":"data_utilities/installation/download_mps_sample_data","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/installation/installation_python","label":"Python Package Installation","docId":"data_utilities/installation/installation_python","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/installation/installation_cpp","label":"C++ Installation","docId":"data_utilities/installation/installation_cpp","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/installation/build_with_cmake","label":"CMake for Your Projects","docId":"data_utilities/installation/build_with_cmake","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/installation/type_hinting","label":"Python Type Annotation","docId":"data_utilities/installation/type_hinting","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/installation/troubleshooting","label":"Troubleshooting","docId":"data_utilities/installation/troubleshooting","unlisted":false}]},{"type":"category","label":"Visualization Guide","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/data_utilities/visualization/visualization_python","label":"Python Visualization","docId":"data_utilities/visualization/visualization_python","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/visualization/visualization_cpp","label":"C++ Visualization","docId":"data_utilities/visualization/visualization_cpp","unlisted":false}],"href":"/projectaria_tools/docs/data_utilities/visualization/"},{"type":"category","label":"Core Code Snippets","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/data_utilities/core_code_snippets/data_provider","label":"Data Provider","docId":"data_utilities/core_code_snippets/data_provider","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/core_code_snippets/image","label":"Image","docId":"data_utilities/core_code_snippets/image","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/core_code_snippets/calibration","label":"Calibration","docId":"data_utilities/core_code_snippets/calibration","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/core_code_snippets/mps","label":"MPS - General","docId":"data_utilities/core_code_snippets/mps","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/core_code_snippets/eye_gaze_code","label":"MPS - Eye Gaze","docId":"data_utilities/core_code_snippets/eye_gaze_code","unlisted":false}]},{"type":"category","label":"Advanced Code Snippets","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/data_utilities/advanced_code_snippets/plotting_sensor_data","label":"Plot Sensor Data (Python)","docId":"data_utilities/advanced_code_snippets/plotting_sensor_data","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/advanced_code_snippets/image_utilities","label":"Image Utilities (Python and C++)","docId":"data_utilities/advanced_code_snippets/image_utilities","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/data_utilities/advanced_code_snippets/vrs_to_mp4","label":"Export VRS to MP4 (Python)","docId":"data_utilities/advanced_code_snippets/vrs_to_mp4","unlisted":false}]}],"href":"/projectaria_tools/docs/data_utilities/"},{"type":"link","href":"/projectaria_tools/docs/collaborative_tools","label":"Collaborative Tools","docId":"collaborative_tools","unlisted":false},{"type":"category","label":"Aria Research Kit","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/ARK/about_ARK","label":"About the Aria Research Kit","docId":"ARK/about_ARK","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/ark_downloads","label":"ARK SW Downloads","docId":"ARK/ark_downloads","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/frame_sizing","label":"Get the Right Size Glasses","docId":"ARK/frame_sizing","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/ARK_quickstart","label":"Aria Glasses Quickstart","docId":"ARK/ARK_quickstart","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/workplacegroup","label":"Workplace Group [Academic Partners Only]","docId":"ARK/workplacegroup","unlisted":false},{"type":"category","label":"Aria Glasses Manual","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/ARK/glasses_manual/glasses_user_manual","label":"Glasses User Manual","docId":"ARK/glasses_manual/glasses_user_manual","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/glasses_manual/fit_and_comfort","label":"Fit and Comfort","docId":"ARK/glasses_manual/fit_and_comfort","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/glasses_manual/cable_clip","label":"Aria Cable Clip","docId":"ARK/glasses_manual/cable_clip","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/glasses_manual/pair_glasses","label":"Pair Additional Glasses & Troubleshooting","docId":"ARK/glasses_manual/pair_glasses","unlisted":false}]},{"type":"link","href":"/projectaria_tools/docs/ARK/mobile_companion_app","label":"Mobile Companion App","docId":"ARK/mobile_companion_app","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/aria_studio","label":"Aria Studio","docId":"ARK/aria_studio","unlisted":false},{"type":"category","label":"Aria Client SDK","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/setup","label":"Setup Guide","docId":"ARK/sdk/setup","unlisted":false},{"type":"category","label":"Code Samples","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/samples/device_connection","label":"Connection","docId":"ARK/sdk/samples/device_connection","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/samples/device_recording","label":"Recording","docId":"ARK/sdk/samples/device_recording","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/samples/streaming_subscribe","label":"Streaming Subscription","docId":"ARK/sdk/samples/streaming_subscribe","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/samples/device_stream","label":"Streaming and Visualizing All Live Sensor Data","docId":"ARK/sdk/samples/device_stream","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/samples/undistort_rgb_image","label":"Streaming Undistorted RGB Image Using Calibration","docId":"ARK/sdk/samples/undistort_rgb_image","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/samples/ticsync_sample","label":"TICSync Time Synchronization","docId":"ARK/sdk/samples/ticsync_sample","unlisted":false}],"href":"/projectaria_tools/docs/ARK/sdk/samples/"},{"type":"category","label":"Core Concepts","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/concepts/streaming_internals","label":"Streaming Internals","docId":"ARK/sdk/concepts/streaming_internals","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/concepts/sdk_sensor_profiles","label":"Access Sensor Profiles","docId":"ARK/sdk/concepts/sdk_sensor_profiles","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/concepts/about_ticsync","label":"About TICSync","docId":"ARK/sdk/concepts/about_ticsync","unlisted":false}]},{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/ticsync","label":"Time Synchronization","docId":"ARK/sdk/ticsync","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/api_reference","label":"API Reference","docId":"ARK/sdk/api_reference","unlisted":false},{"type":"category","label":"Aria CLI","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/cli/api_reference","label":"Command Reference","docId":"ARK/sdk/cli/api_reference","unlisted":false}],"href":"/projectaria_tools/docs/ARK/sdk/cli/"},{"type":"link","href":"/projectaria_tools/docs/ARK/sdk/sdk_troubleshooting","label":"SDK Troubleshooting & Known Issues","docId":"ARK/sdk/sdk_troubleshooting","unlisted":false}],"href":"/projectaria_tools/docs/ARK/sdk/"},{"type":"category","label":"Aria Machine Perception Services (MPS)","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Request MPS","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/ARK/mps/request_mps/mps_cli","label":"MPS CLI","docId":"ARK/mps/request_mps/mps_cli","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/mps/request_mps/mps_cli_getting_started","label":"MPS CLI Getting Started","docId":"ARK/mps/request_mps/mps_cli_getting_started","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/mps/request_mps/mps_cli_guide","label":"MPS CLI Guide","docId":"ARK/mps/request_mps/mps_cli_guide","unlisted":false}],"href":"/projectaria_tools/docs/ARK/mps/request_mps/"},{"type":"link","href":"/projectaria_tools/docs/ARK/mps/eye_gaze_calibration","label":"Eye Gaze Calibration","docId":"ARK/mps/eye_gaze_calibration","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/mps/mps_processing","label":"MPS Data Processing","docId":"ARK/mps/mps_processing","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/mps/mps_versioning","label":"MPS Service Versions","docId":"ARK/mps/mps_versioning","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/mps/mps_troubleshooting","label":"MPS Troubleshooting","docId":"ARK/mps/mps_troubleshooting","unlisted":false}],"href":"/projectaria_tools/docs/ARK/mps/"},{"type":"link","href":"/projectaria_tools/docs/ARK/sw_release_notes","label":"ARK Release Notes","docId":"ARK/sw_release_notes","unlisted":false},{"type":"category","label":"ARK Troubleshooting","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/ARK/troubleshooting/troubleshooting_issues","label":"Troubleshooting & Known Issues","docId":"ARK/troubleshooting/troubleshooting_issues","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/troubleshooting/update_glasses_os","label":"Update Glasses OS","docId":"ARK/troubleshooting/update_glasses_os","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/troubleshooting/reduce_vrs_file_size","label":"Reduce VRS File Size","docId":"ARK/troubleshooting/reduce_vrs_file_size","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/ARK/troubleshooting/linux_usb_driver","label":"Fix USB Driver Issues in Linux","docId":"ARK/troubleshooting/linux_usb_driver","unlisted":false}]}]},{"type":"category","label":"Open Datasets","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/open_datasets/dataset_download","label":"Dataset Download","docId":"open_datasets/dataset_download","unlisted":false},{"type":"category","label":"Aria Dataset Explorer","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/open_datasets/dataset_explorer/dataset_explorer_filters","label":"Dataset Explorer Filters","docId":"open_datasets/dataset_explorer/dataset_explorer_filters","unlisted":false}],"href":"/projectaria_tools/docs/open_datasets/dataset_explorer/"},{"type":"category","label":"Aria Everyday Activities Dataset","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/aea_getting_started","label":"Getting Started","docId":"open_datasets/aria_everyday_activities_dataset/aea_getting_started","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/aea_download_dataset","label":"Dataset Download","docId":"open_datasets/aria_everyday_activities_dataset/aea_download_dataset","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/aea_data_format","label":"Data Format","docId":"open_datasets/aria_everyday_activities_dataset/aea_data_format","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/aea_visualizers","label":"Visualizer","docId":"open_datasets/aria_everyday_activities_dataset/aea_visualizers","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/aea_activities","label":"Activities","docId":"open_datasets/aria_everyday_activities_dataset/aea_activities","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/aea_scripts","label":"Recording Scripts","docId":"open_datasets/aria_everyday_activities_dataset/aea_scripts","unlisted":false}],"href":"/projectaria_tools/docs/open_datasets/aria_everyday_activities_dataset/"},{"type":"category","label":"Aria Digital Twin Dataset","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/getting_started","label":"Getting Started","docId":"open_datasets/aria_digital_twin_dataset/getting_started","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/dataset_download","label":"Dataset Download","docId":"open_datasets/aria_digital_twin_dataset/dataset_download","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/object_models","label":"Object Models","docId":"open_datasets/aria_digital_twin_dataset/object_models","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/data_format","label":"Data Format","docId":"open_datasets/aria_digital_twin_dataset/data_format","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/data_loader","label":"Data Loader","docId":"open_datasets/aria_digital_twin_dataset/data_loader","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/visualizers","label":"Visualizers","docId":"open_datasets/aria_digital_twin_dataset/visualizers","unlisted":false},{"type":"category","label":"Advanced Tutorials","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/advanced_tutorials/depth_maps_to_pointcloud","label":"Creating pointclouds from depth maps & RGB images","docId":"open_datasets/aria_digital_twin_dataset/advanced_tutorials/depth_maps_to_pointcloud","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/advanced_tutorials/multiperson_synchronization","label":"Multi-person Synchronization","docId":"open_datasets/aria_digital_twin_dataset/advanced_tutorials/multiperson_synchronization","unlisted":false}],"href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/advanced_tutorials/"},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/adt_challenges","label":"ADT Challenges","docId":"open_datasets/aria_digital_twin_dataset/adt_challenges","unlisted":false}],"href":"/projectaria_tools/docs/open_datasets/aria_digital_twin_dataset/"},{"type":"category","label":"Aria Synthetic Environments Dataset","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_getting_started","label":"Getting Started","docId":"open_datasets/aria_synthetic_environments_dataset/ase_getting_started","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_download_dataset","label":"Dataset Download","docId":"open_datasets/aria_synthetic_environments_dataset/ase_download_dataset","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_data_format","label":"Data Format","docId":"open_datasets/aria_synthetic_environments_dataset/ase_data_format","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_data_tools","label":"Data Tools and Visualization","docId":"open_datasets/aria_synthetic_environments_dataset/ase_data_tools","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/ase_challenges","label":"ASE Challenges","docId":"open_datasets/aria_synthetic_environments_dataset/ase_challenges","unlisted":false}],"href":"/projectaria_tools/docs/open_datasets/aria_synthetic_environments_dataset/"},{"type":"category","label":"Ego-Exo4D","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/open_datasets/ego-exo4d/ego-exo4d_data_format","label":"Ego-Exo4D Data Format and Loader","docId":"open_datasets/ego-exo4d/ego-exo4d_data_format","unlisted":false}],"href":"/projectaria_tools/docs/open_datasets/ego-exo4d/"},{"type":"category","label":"Digital Twin Catalog","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/open_datasets/digital_twin_catalog/digital_twin_catalog_getting_started","label":"Getting Started","docId":"open_datasets/digital_twin_catalog/digital_twin_catalog_getting_started","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/digital_twin_catalog/digital_twin_catalog_download_dataset","label":"Dataset Download","docId":"open_datasets/digital_twin_catalog/digital_twin_catalog_download_dataset","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/digital_twin_catalog/digital_twin_catalog_object_models","label":"Object Models","docId":"open_datasets/digital_twin_catalog/digital_twin_catalog_object_models","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/digital_twin_catalog/digital_twin_catalog_data_format","label":"DTC Data Format","docId":"open_datasets/digital_twin_catalog/digital_twin_catalog_data_format","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/digital_twin_catalog/digital_twin_catalog_tooling","label":"DTC Tooling","docId":"open_datasets/digital_twin_catalog/digital_twin_catalog_tooling","unlisted":false}],"href":"/projectaria_tools/docs/open_datasets/digital_twin_catalog/"},{"type":"link","href":"/projectaria_tools/docs/open_datasets/object_explorer","label":"DTC Object Explorer","docId":"open_datasets/object_explorer","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/hot3d","label":"HOT3D Dataset","docId":"open_datasets/hot3d","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/aria_everyday_objects/","label":"Aria Everyday Objects Dataset","docId":"open_datasets/aria_everyday_objects/aria_everyday_objects","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_datasets/ritw","label":"Reading in the Wild dataset","docId":"open_datasets/ritw","unlisted":false}],"href":"/projectaria_tools/docs/open_datasets/"},{"type":"category","label":"Open Models","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/open_models/egoblur","label":"EgoBlur","docId":"open_models/egoblur","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_models/evl","label":"Egocentric Voxel Lifting (EVL)","docId":"open_models/evl","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_models/eye_tracking","label":"Eye Tracking","docId":"open_models/eye_tracking","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_models/scenescript","label":"SceneScript","docId":"open_models/scenescript","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/open_models/psr","label":"Photoreal Scene Reconstruction","docId":"open_models/psr","unlisted":false}],"href":"/projectaria_tools/docs/open_models/"},{"type":"category","label":"ATEK","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/ATEK/about_ATEK","label":"About the Aria Training and Evaluation toolkit (ATEK)","docId":"ATEK/about_ATEK","unlisted":false}]},{"type":"category","label":"Tech Insights","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/projectaria_tools/docs/tech_insights/camera_intrinsic_models","label":"Camera Intrinsic Models","docId":"tech_insights/camera_intrinsic_models","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/tech_insights/sensor_measurement_model","label":"Sensor Measurement Model","docId":"tech_insights/sensor_measurement_model","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/tech_insights/camera_photometric_and_noise_model","label":"Camera Photometric and Noise Models","docId":"tech_insights/camera_photometric_and_noise_model","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/tech_insights/imu_noise_model","label":"IMU Noise Model","docId":"tech_insights/imu_noise_model","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/tech_insights/device_timestamping","label":"Device Timestamping","docId":"tech_insights/device_timestamping","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/tech_insights/temporal_alignment_of_sensor_data","label":"Temporal Alignment of Sensor Data","docId":"tech_insights/temporal_alignment_of_sensor_data","unlisted":false}],"href":"/projectaria_tools/docs/tech_insights/"},{"type":"link","href":"/projectaria_tools/docs/attribution_citation/","label":"Attribution and Contributing","docId":"attribution_citation/attribution_citation","unlisted":false},{"type":"link","href":"/projectaria_tools/docs/support","label":"Support","docId":"support","unlisted":false}]},"docs":{"ARK/about_ARK":{"id":"ARK/about_ARK","title":"About the Aria Research Kit","description":"The Aria Research Kit (ARK) provides Project Aria glasses, services and tools to enable researchers to gather and process their own Aria data. Go to Aria Research Kit intro page at projectaria.com to find out more, or to apply to become a research partner.","sidebar":"tutorialSidebar"},"ARK/aria_studio":{"id":"ARK/aria_studio","title":"Aria Studio","description":"Overview","sidebar":"tutorialSidebar"},"ARK/ark_downloads":{"id":"ARK/ark_downloads","title":"ARK SW Downloads","description":"The Aria Research Kit (ARK) provides the Aria Mobile Companion app to researchers who use Project Aria glasses.","sidebar":"tutorialSidebar"},"ARK/ARK_quickstart":{"id":"ARK/ARK_quickstart","title":"Aria Glasses Quickstart","description":"This page provides a quick overview of what to do once you have received your Project Aria glasses. To find out how to get Aria Glasses, go to projectaria.com.","sidebar":"tutorialSidebar"},"ARK/frame_sizing":{"id":"ARK/frame_sizing","title":"Get the Right Size Glasses","description":"If you have been approved to become a Project Aria partner and receive the Aria Research Kit (ARK), you\'ll have the option to order Small or Large Aria glasses.","sidebar":"tutorialSidebar"},"ARK/glasses_manual/cable_clip":{"id":"ARK/glasses_manual/cable_clip","title":"Aria Cable Clip","description":"Overview","sidebar":"tutorialSidebar"},"ARK/glasses_manual/fit_and_comfort":{"id":"ARK/glasses_manual/fit_and_comfort","title":"Fit and Comfort","description":"Overview","sidebar":"tutorialSidebar"},"ARK/glasses_manual/glasses_user_manual":{"id":"ARK/glasses_manual/glasses_user_manual","title":"Glasses User Manual","description":"The Aria Research Kit (ARK) provides Project Aria glasses, services and tools to enable researchers to gather and process their own Aria data. Go to Aria Research Kit intro page to find out more or to apply for the ARK.","sidebar":"tutorialSidebar"},"ARK/glasses_manual/pair_glasses":{"id":"ARK/glasses_manual/pair_glasses","title":"Pair Additional Glasses & Troubleshooting","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mobile_companion_app":{"id":"ARK/mobile_companion_app","title":"Mobile Companion App","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/eye_gaze_calibration":{"id":"ARK/mps/eye_gaze_calibration","title":"Eye Gaze Calibration","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/mps":{"id":"ARK/mps/mps","title":"Machine Perception Services (MPS)","description":"To accelerate research with Project Aria, we provide several Spatial AI machine perception capabilities that help form the foundation for future Contextualized AI applications and analysis of egocentric data. These capabilities are powered by a set of proprietary machine perception algorithms, designed for Project Aria glasses, that provide superior accuracy and robustness on Aria data compared to off-the-shelf open source algorithms.","sidebar":"tutorialSidebar"},"ARK/mps/mps_processing":{"id":"ARK/mps/mps_processing","title":"MPS Data Processing","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/mps_troubleshooting":{"id":"ARK/mps/mps_troubleshooting","title":"MPS Troubleshooting","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/mps_versioning":{"id":"ARK/mps/mps_versioning","title":"MPS Service Versions","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/request_mps/mps_cli":{"id":"ARK/mps/request_mps/mps_cli","title":"MPS CLI","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/request_mps/mps_cli_getting_started":{"id":"ARK/mps/request_mps/mps_cli_getting_started","title":"MPS CLI Getting Started","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/request_mps/mps_cli_guide":{"id":"ARK/mps/request_mps/mps_cli_guide","title":"MPS CLI Guide","description":"Overview","sidebar":"tutorialSidebar"},"ARK/mps/request_mps/request_mps":{"id":"ARK/mps/request_mps/request_mps","title":"Request MPS","description":"Cloud based Machine Perception Services (MPS) are available to Project Aria research partners to generate SLAM, Multi-Slam, Eye Gaze and Hand Tracking derived data outputs. Partner data is only used to serve MPS requests. Partner data is not available to Meta researchers or Meta\u2019s affiliates. Go to MPS Data Processing for more details about how data is processed.","sidebar":"tutorialSidebar"},"ARK/sdk/api_reference":{"id":"ARK/sdk/api_reference","title":"API Reference","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/cli/api_reference":{"id":"ARK/sdk/cli/api_reference","title":"Command Reference","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/cli/cli":{"id":"ARK/sdk/cli/cli","title":"Aria CLI","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/concepts/about_ticsync":{"id":"ARK/sdk/concepts/about_ticsync","title":"About TICSync","description":"What is TICSync","sidebar":"tutorialSidebar"},"ARK/sdk/concepts/sdk_sensor_profiles":{"id":"ARK/sdk/concepts/sdk_sensor_profiles","title":"Access Sensor Profiles","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/concepts/streaming_internals":{"id":"ARK/sdk/concepts/streaming_internals","title":"Streaming Internals","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/samples/device_connection":{"id":"ARK/sdk/samples/device_connection","title":"Connection","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/samples/device_recording":{"id":"ARK/sdk/samples/device_recording","title":"Recording","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/samples/device_stream":{"id":"ARK/sdk/samples/device_stream","title":"Streaming and Visualizing All Live Sensor Data","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/samples/samples":{"id":"ARK/sdk/samples/samples","title":"Code Samples","description":"This section provides code samples and walkthroughs for using the Aria Client SDK to interact with the Project Aria glasses.","sidebar":"tutorialSidebar"},"ARK/sdk/samples/streaming_subscribe":{"id":"ARK/sdk/samples/streaming_subscribe","title":"Streaming Subscription","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/samples/ticsync_sample":{"id":"ARK/sdk/samples/ticsync_sample","title":"TICSync Time Synchronization","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/samples/undistort_rgb_image":{"id":"ARK/sdk/samples/undistort_rgb_image","title":"Streaming Undistorted RGB Image Using Calibration","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/sdk":{"id":"ARK/sdk/sdk","title":"About the SDK","description":"The Project Aria Client SDK provides versatile APIs to help you create your own machine perception Python applications with Project Aria glasses.","sidebar":"tutorialSidebar"},"ARK/sdk/sdk_troubleshooting":{"id":"ARK/sdk/sdk_troubleshooting","title":"SDK Troubleshooting & Known Issues","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/setup":{"id":"ARK/sdk/setup","title":"Setup Guide","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sdk/ticsync":{"id":"ARK/sdk/ticsync","title":"Time Synchronization","description":"Overview","sidebar":"tutorialSidebar"},"ARK/sw_release_notes":{"id":"ARK/sw_release_notes","title":"ARK Release Notes","description":"These SW Release notes are for the Aria Research Kit (ARK), and are for Meta SW that supports Academic Research Partners using Project Aria glasses. To find out how to become a research partner, go to projectaria.com.","sidebar":"tutorialSidebar"},"ARK/troubleshooting/linux_usb_driver":{"id":"ARK/troubleshooting/linux_usb_driver","title":"Fix USB Driver Issues in Linux","description":"Overview","sidebar":"tutorialSidebar"},"ARK/troubleshooting/reduce_vrs_file_size":{"id":"ARK/troubleshooting/reduce_vrs_file_size","title":"Reduce VRS File Size","description":"Overview","sidebar":"tutorialSidebar"},"ARK/troubleshooting/troubleshooting_issues":{"id":"ARK/troubleshooting/troubleshooting_issues","title":"Troubleshooting & Known Issues","description":"Overview","sidebar":"tutorialSidebar"},"ARK/troubleshooting/update_glasses_os":{"id":"ARK/troubleshooting/update_glasses_os","title":"Update Glasses OS","description":"Overview","sidebar":"tutorialSidebar"},"ARK/workplacegroup":{"id":"ARK/workplacegroup","title":"Workplace Group [Academic Partners Only]","description":"Overview","sidebar":"tutorialSidebar"},"ATEK/about_ATEK":{"id":"ATEK/about_ATEK","title":"About the Aria Training and Evaluation toolkit (ATEK)","description":"Aria Training and Evaluation Kit (ATEK) is a toolbox for accelerating the development of Machine Learning tasks using Aria datasets.","sidebar":"tutorialSidebar"},"attribution_citation/attribution_citation":{"id":"attribution_citation/attribution_citation","title":"Attribution and Contributing","description":"Citation","sidebar":"tutorialSidebar"},"collaborative_tools":{"id":"collaborative_tools","title":"Collaborative Tools","description":"Overview","sidebar":"tutorialSidebar"},"data_formats/aria_vrs/aria_vrs":{"id":"data_formats/aria_vrs/aria_vrs","title":"Aria VRS","description":"Overview","sidebar":"tutorialSidebar"},"data_formats/aria_vrs/aria_vrs_command_line":{"id":"data_formats/aria_vrs/aria_vrs_command_line","title":"VRS command line tool","description":"The vrs command line tool is a Swiss army knife utility to manipulate VRS files (operations such as inspection, or copy/filter editing).","sidebar":"tutorialSidebar"},"data_formats/aria_vrs/aria_vrs_format":{"id":"data_formats/aria_vrs/aria_vrs_format","title":"Format","description":"This page provides information about how Aria data streams are identified in VRS, Aria sensor data configuration, followed by useful VRS tools for common use cases.","sidebar":"tutorialSidebar"},"data_formats/aria_vrs/aria_vrs_tools_installation":{"id":"data_formats/aria_vrs/aria_vrs_tools_installation","title":"VRS Tools installation","description":"VRS Tools can easily be installed on your system using our prepackaged versions.","sidebar":"tutorialSidebar"},"data_formats/aria_vrs/aria_vrsplayer":{"id":"data_formats/aria_vrs/aria_vrsplayer","title":"VRSPlayer","description":"The vrsplayer application lets you \\"play\\" a VRS like a multi-stream video, with audio if an audio stream is present.","sidebar":"tutorialSidebar"},"data_formats/aria_vrs/timestamps_in_aria_vrs":{"id":"data_formats/aria_vrs/timestamps_in_aria_vrs","title":"Timestamp Definitions","description":"This page provides information about how Project Aria timestamp data is formatted in VRS.","sidebar":"tutorialSidebar"},"data_formats/coordinate_convention/2d_image_coordinate_system_convention":{"id":"data_formats/coordinate_convention/2d_image_coordinate_system_convention","title":"2D Image Coordinate System Conventions","description":"For any provided camera intrinsic calibration value, we use the convention that the color value of a pixel with integer coordinates $(u,v)$ is the average color of the square spanning from $(u-0.5,v-0.5)$ to $(u+0.5,v+0.5)$ in continuous coordinates.","sidebar":"tutorialSidebar"},"data_formats/coordinate_convention/3d_coordinate_frame_convention":{"id":"data_formats/coordinate_convention/3d_coordinate_frame_convention","title":"3D Coordinate Frame Conventions","description":"This page provides an overview of 3D Coordinate Frame Conventions used for Project Aria glasses, covering:","sidebar":"tutorialSidebar"},"data_formats/data_formats":{"id":"data_formats/data_formats","title":"Data Formats","description":"In this section, we describe:","sidebar":"tutorialSidebar"},"data_formats/mps/hand_tracking/hand_tracking":{"id":"data_formats/mps/hand_tracking/hand_tracking","title":"Hand Tracking","description":"Project Aria\'s Machine Perception Services (MPS) uses Project Aria\'s SLAM (mono scene) camera images to estimate the hand movement of the wearer.","sidebar":"tutorialSidebar"},"data_formats/mps/mps_eye_gaze":{"id":"data_formats/mps/mps_eye_gaze","title":"Eye Gaze","description":"Eye Gaze Data Format","sidebar":"tutorialSidebar"},"data_formats/mps/mps_summary":{"id":"data_formats/mps/mps_summary","title":"Basics","description":"This page provides an overview of how Project Aria Machine Perception Services (MPS) output files are formatted.","sidebar":"tutorialSidebar"},"data_formats/mps/slam/mps_calibration":{"id":"data_formats/mps/slam/mps_calibration","title":"Calibration Data","description":"Online calibration is generated as part of SLAM MPS requests.","sidebar":"tutorialSidebar"},"data_formats/mps/slam/mps_multi_slam":{"id":"data_formats/mps/slam/mps_multi_slam","title":"Multi-SLAM","description":"Multi-SLAM is a Project Aria Machine Perception Service (MPS) that can be requested on two or more recordings. It creates SLAM MPS outputs in a shared co-ordinate frame.","sidebar":"tutorialSidebar"},"data_formats/mps/slam/mps_pointcloud":{"id":"data_formats/mps/slam/mps_pointcloud","title":"Semi-Dense Point Cloud","description":"Semi-Dense Point Cloud is a Project Aria Machine Perception Service (MPS) that is generated as part of SLAM MPS requests.","sidebar":"tutorialSidebar"},"data_formats/mps/slam/mps_trajectory":{"id":"data_formats/mps/slam/mps_trajectory","title":"Trajectory","description":"6DoF trajectory data is generated as part of SLAM Machine Perception Services (MPS) requests:","sidebar":"tutorialSidebar"},"data_formats/mps/slam/slam":{"id":"data_formats/mps/slam/slam","title":"SLAM","description":"Overview","sidebar":"tutorialSidebar"},"data_utilities/advanced_code_snippets/image_utilities":{"id":"data_utilities/advanced_code_snippets/image_utilities","title":"Image Utilities (Python and C++)","description":"Overview","sidebar":"tutorialSidebar"},"data_utilities/advanced_code_snippets/plotting_sensor_data":{"id":"data_utilities/advanced_code_snippets/plotting_sensor_data","title":"Plot Sensor Data (Python)","description":"This tutorial shows how to plot Project Aria sensor data using Python. This example covers how to:","sidebar":"tutorialSidebar"},"data_utilities/advanced_code_snippets/vrs_to_mp4":{"id":"data_utilities/advanced_code_snippets/vrs_to_mp4","title":"Export VRS to MP4 (Python)","description":"The vrstomp4 script enables you to create an MP4 video from a Project Aria VRS recording.","sidebar":"tutorialSidebar"},"data_utilities/core_code_snippets/calibration":{"id":"data_utilities/core_code_snippets/calibration","title":"Calibration","description":"This section covers how to use Project Aria Tools to:","sidebar":"tutorialSidebar"},"data_utilities/core_code_snippets/data_provider":{"id":"data_utilities/core_code_snippets/data_provider","title":"Data Provider","description":"In this section, we introduce the Python/C++ API to access sensor data in Project Aria VRS files (projectariatools/main/core/dataprovider).","sidebar":"tutorialSidebar"},"data_utilities/core_code_snippets/eye_gaze_code":{"id":"data_utilities/core_code_snippets/eye_gaze_code","title":"MPS - Eye Gaze","description":"This page provides a number of Eye Gaze code snippets that can be useful when working with Eye Gaze data provided in Open Datasets or generated by Machine Perception Services.","sidebar":"tutorialSidebar"},"data_utilities/core_code_snippets/image":{"id":"data_utilities/core_code_snippets/image","title":"Image","description":"In this section, we introduce the Python/C++ API to access and manipulate Project Aria images (projectariatools/main/core/image). Raw Aria data is stored in VRS files.","sidebar":"tutorialSidebar"},"data_utilities/core_code_snippets/mps":{"id":"data_utilities/core_code_snippets/mps","title":"MPS - General","description":"Project Aria Machine Perception Services (MPS) enables Aria users with access to the Aria Research Kit to request derived data on Aria VRS files.","sidebar":"tutorialSidebar"},"data_utilities/data_utilities":{"id":"data_utilities/data_utilities","title":"Overview","description":"Overview","sidebar":"tutorialSidebar"},"data_utilities/getting_started":{"id":"data_utilities/getting_started","title":"Getting Started","description":"In this guide, we introduce how to install the projectaria_tools Python package and provide tutorials to go through the APIs to access and visualize Aria data.","sidebar":"tutorialSidebar"},"data_utilities/installation/build_with_cmake":{"id":"data_utilities/installation/build_with_cmake","title":"CMake for Your Projects","description":"To use projectaria_tools for your own projects with CMake, we recommend adding it as a submodule in your project.","sidebar":"tutorialSidebar"},"data_utilities/installation/download_codebase":{"id":"data_utilities/installation/download_codebase","title":"Download Codebase","description":"Supported Platforms","sidebar":"tutorialSidebar"},"data_utilities/installation/download_mps_sample_data":{"id":"data_utilities/installation/download_mps_sample_data","title":"Download MPS Sample Data","description":"This sample (hosted at projectaria.com) contains a raw VRS file and all the corresponding MPS outputs.","sidebar":"tutorialSidebar"},"data_utilities/installation/installation_cpp":{"id":"data_utilities/installation/installation_cpp","title":"C++ Installation","description":"Overview","sidebar":"tutorialSidebar"},"data_utilities/installation/installation_python":{"id":"data_utilities/installation/installation_python","title":"Python Package Installation","description":"This page provides information about how to install the Python utilities using a virtual environment or from source. We recommend that only advanced users install from source.","sidebar":"tutorialSidebar"},"data_utilities/installation/troubleshooting":{"id":"data_utilities/installation/troubleshooting","title":"Troubleshooting","description":"Jupyter Notebook issues","sidebar":"tutorialSidebar"},"data_utilities/installation/type_hinting":{"id":"data_utilities/installation/type_hinting","title":"Python Type Annotation","description":"This page provides information about how to use the Python type hinting from stub files (*.pyi).","sidebar":"tutorialSidebar"},"data_utilities/visualization/visualization":{"id":"data_utilities/visualization/visualization","title":"Visualization Guide","description":"Project Aria Tools offers two kinds of tools for visualizing data: Python tools and C++ tools.","sidebar":"tutorialSidebar"},"data_utilities/visualization/visualization_cpp":{"id":"data_utilities/visualization/visualization_cpp","title":"C++ Visualization","description":"Overview","sidebar":"tutorialSidebar"},"data_utilities/visualization/visualization_python":{"id":"data_utilities/visualization/visualization_python","title":"Python Visualization","description":"Overview","sidebar":"tutorialSidebar"},"faq":{"id":"faq","title":"Project Aria FAQ","description":"This Project Aria FAQ covers:","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Introduction to Project Aria Docs","description":"Project Aria is a research platform developed by Meta Reality Labs Research to enable both internal groups in Meta and external researchers to use egocentric data to push the state of the art in egocentric AI research, including the subfields of computer vision, robotics, and contextual AI, as examples. We believe it will take many of the world\u2019s leading research communities to collectively solve the biggest problems in this deep research domain.","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/adt_challenges":{"id":"open_datasets/aria_digital_twin_dataset/adt_challenges","title":"ADT Challenges","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/advanced_tutorials/advanced_tutorials":{"id":"open_datasets/aria_digital_twin_dataset/advanced_tutorials/advanced_tutorials","title":"Advanced Tutorials","description":"Tutorials","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/advanced_tutorials/depth_maps_to_pointcloud":{"id":"open_datasets/aria_digital_twin_dataset/advanced_tutorials/depth_maps_to_pointcloud","title":"Creating pointclouds from depth maps & RGB images","description":"This tutorial will walk you through how to take the depth maps and RGB images from Aria Digital Twin (ADT) and convert to a colored 3D pointcloud in the Scene coordinate frame.","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/advanced_tutorials/multiperson_synchronization":{"id":"open_datasets/aria_digital_twin_dataset/advanced_tutorials/multiperson_synchronization","title":"Multi-person Synchronization","description":"This tutorial will walk you through the steps to get synchronized ground truth data in a multi-person sequence in the Aria Digital Twin (ADT) dataset.","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/aria_digital_twin_dataset":{"id":"open_datasets/aria_digital_twin_dataset/aria_digital_twin_dataset","title":"Overview","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/data_format":{"id":"open_datasets/aria_digital_twin_dataset/data_format","title":"Data Format","description":"The Aria Digital Twin Dataset (ADT) provides real world and synthetic raw Project Aria data, derived data generated by ADT Ground Truth data processing services as well as derived data generated by Project Aria\'s Machine Perception Services (MPS).","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/data_loader":{"id":"open_datasets/aria_digital_twin_dataset/data_loader","title":"Data Loader","description":"Data loading is broken down into two main loaders: AriaDigitalTwinDataPathsProvider, AriaDigitalTwinDataProvider.","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/dataset_download":{"id":"open_datasets/aria_digital_twin_dataset/dataset_download","title":"Dataset Download","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/getting_started":{"id":"open_datasets/aria_digital_twin_dataset/getting_started","title":"Getting Started","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/object_models":{"id":"open_datasets/aria_digital_twin_dataset/object_models","title":"Object Models","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_digital_twin_dataset/visualizers":{"id":"open_datasets/aria_digital_twin_dataset/visualizers","title":"Visualizers","description":"To help you visualize and debug your algorithms when using the Aria Digital Twin (ADT) dataset, we\u2019ve provided the following visualizers:","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aea_activities":{"id":"open_datasets/aria_everyday_activities_dataset/aea_activities","title":"Activities","description":"When creating recordings for one to two Project Aria glasses wearers for the Aria Everyday Activities (AEA) dataset, we created scripts to represent all day long activities with always on sensing. Each script contained multiple scenarios that told a story about people going through their day. The scripts provided general guidance for an improvised scenario. Actors did not have specific lines to learn, instead they followed prompts and went with what felt most natural to to them.","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aea_data_format":{"id":"open_datasets/aria_everyday_activities_dataset/aea_data_format","title":"Data Format","description":"The Aria Everyday Activities dataset contains multiple activity sequences for one to two Project Aria glasses users. We created recordings using scripts to represent all day activities with always on sensing.","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aea_download_dataset":{"id":"open_datasets/aria_everyday_activities_dataset/aea_download_dataset","title":"Dataset Download","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aea_getting_started":{"id":"open_datasets/aria_everyday_activities_dataset/aea_getting_started","title":"Getting Started","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aea_scripts":{"id":"open_datasets/aria_everyday_activities_dataset/aea_scripts","title":"Recording Scripts","description":"The following scripts were used by actors to collect data for the Aria Everyday Activities (AEA) dataset.","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aea_visualizers":{"id":"open_datasets/aria_everyday_activities_dataset/aea_visualizers","title":"Visualizer","description":"To help you visualize and debug your algorithms when using the Aria Everyday Activities (AEA) dataset, we\u2019ve provided a Python based visualizer that can work with time synchronized data from multiple Project Aria glasses in a shared world location.","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_activities_dataset/aria_everyday_activities_dataset":{"id":"open_datasets/aria_everyday_activities_dataset/aria_everyday_activities_dataset","title":"Aria Everyday Activities Dataset","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_everyday_objects/aria_everyday_objects":{"id":"open_datasets/aria_everyday_objects/aria_everyday_objects","title":"Aria Everyday Objects Dataset","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_synthetic_environments_dataset/aria_synthetic_environments_dataset":{"id":"open_datasets/aria_synthetic_environments_dataset/aria_synthetic_environments_dataset","title":"Aria Synthetic Environments Dataset","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_synthetic_environments_dataset/ase_challenges":{"id":"open_datasets/aria_synthetic_environments_dataset/ase_challenges","title":"ASE Challenges","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/aria_synthetic_environments_dataset/ase_data_format":{"id":"open_datasets/aria_synthetic_environments_dataset/ase_data_format","title":"Data Format","description":"This page provides an overview of Aria Synthetic Environments (ASE) data formats and organization.","sidebar":"tutorialSidebar"},"open_datasets/aria_synthetic_environments_dataset/ase_data_tools":{"id":"open_datasets/aria_synthetic_environments_dataset/ase_data_tools","title":"Data Tools and Visualization","description":"We provide different functions and code snippets in Python to load Aria Synthetic Environments (ASE) data from a sequence and associate/interpret them with each other. The contents of each scene/sequence are detailed in Data Format.","sidebar":"tutorialSidebar"},"open_datasets/aria_synthetic_environments_dataset/ase_download_dataset":{"id":"open_datasets/aria_synthetic_environments_dataset/ase_download_dataset","title":"Dataset Download","description":"By downloading the datasets you agree that you have read and accepted the terms of","sidebar":"tutorialSidebar"},"open_datasets/aria_synthetic_environments_dataset/ase_getting_started":{"id":"open_datasets/aria_synthetic_environments_dataset/ase_getting_started","title":"Getting Started","description":"This section will cover everything you need to know to get up and running using Aria Synthetic Environments (ASE) visualizers and data loaders. ASE tooling contains:","sidebar":"tutorialSidebar"},"open_datasets/dataset_download":{"id":"open_datasets/dataset_download","title":"Dataset Download","description":"Downloading Open Datasets","sidebar":"tutorialSidebar"},"open_datasets/dataset_explorer/dataset_explorer":{"id":"open_datasets/dataset_explorer/dataset_explorer","title":"Aria Dataset Explorer","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/dataset_explorer/dataset_explorer_filters":{"id":"open_datasets/dataset_explorer/dataset_explorer_filters","title":"Dataset Explorer Filters","description":"The following filters can be used with the Aria Dataset Explorer.","sidebar":"tutorialSidebar"},"open_datasets/digital_twin_catalog/digital_twin_catalog":{"id":"open_datasets/digital_twin_catalog/digital_twin_catalog","title":"Digital Twin Catalog Dataset","description":"About the data","sidebar":"tutorialSidebar"},"open_datasets/digital_twin_catalog/digital_twin_catalog_data_format":{"id":"open_datasets/digital_twin_catalog/digital_twin_catalog_data_format","title":"DTC Data Format","description":"The Digital Twin Catalog Dataset (DTC) provides real world raw Project Aria and digital single-lens reflex (DSLR) camera data,","sidebar":"tutorialSidebar"},"open_datasets/digital_twin_catalog/digital_twin_catalog_download_dataset":{"id":"open_datasets/digital_twin_catalog/digital_twin_catalog_download_dataset","title":"Dataset Download","description":"Overview\u200b","sidebar":"tutorialSidebar"},"open_datasets/digital_twin_catalog/digital_twin_catalog_getting_started":{"id":"open_datasets/digital_twin_catalog/digital_twin_catalog_getting_started","title":"Getting Started","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/digital_twin_catalog/digital_twin_catalog_object_models":{"id":"open_datasets/digital_twin_catalog/digital_twin_catalog_object_models","title":"Object Models","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/digital_twin_catalog/digital_twin_catalog_tooling":{"id":"open_datasets/digital_twin_catalog/digital_twin_catalog_tooling","title":"DTC Tooling","description":"To help you quickly ramp up using the Digital Twin Catalog (DTC) dataset, we have provided the following Python tools which are available in the DTC code repo:","sidebar":"tutorialSidebar"},"open_datasets/ego-exo4d/ego-exo4d":{"id":"open_datasets/ego-exo4d/ego-exo4d","title":"Ego-Exo4D Dataset","description":"Ego-Exo4D is a foundational dataset for research on video learning and multimodal perception. The open dataset was released in November 2023 and in March 2024 was updated to include more data, more annotations, and more modalities. Ego-Exo4D comes from years of collaboration between Meta\u2019s FAIR (Fundamental Artificial Intelligence Research), Meta\u2019s Project Aria, and 15 university partners. Ego-Exo4D is unique because of its simultaneous capture of:","sidebar":"tutorialSidebar"},"open_datasets/ego-exo4d/ego-exo4d_data_format":{"id":"open_datasets/ego-exo4d/ego-exo4d_data_format","title":"Ego-Exo4D Data Format and Loader","description":"Ego-Exo4D includes Project Aria\'s SLAM (Trajectory and Semi-Dense Point Cloud), and Eye Gaze MPS outputs. For information about these, go to MPS data formats. This dataset also contains 3D calibration for the multiple static external cameras (GoPros).","sidebar":"tutorialSidebar"},"open_datasets/hot3d":{"id":"open_datasets/hot3d","title":"HOT3D Dataset","description":"HOT3D is a new benchmark dataset for vision-based understanding of 3D hand-object interactions. This dataset contains over 800 minutes of egocentric recordings, with 33 diverse hand-held objects, capturing over one million multi-view frames of hand-object interactions.","sidebar":"tutorialSidebar"},"open_datasets/object_explorer":{"id":"open_datasets/object_explorer","title":"DTC Object Explorer","description":"Overview","sidebar":"tutorialSidebar"},"open_datasets/open_datasets":{"id":"open_datasets/open_datasets","title":"Open Datasets","description":"This section provides information about how to use Project Aria\'s open data.","sidebar":"tutorialSidebar"},"open_datasets/ritw":{"id":"open_datasets/ritw","title":"Reading in the Wild dataset","description":"Reading in the Wild (RitW) is a new benchmark dataset designed to inform models that determine whether or not subjects are reading. The dataset contains 100 hours of egocentric recordings, capturing 1716 sequences of individuals engaged in reading and non-reading activities in unconstrained environments.","sidebar":"tutorialSidebar"},"open_models/egoblur":{"id":"open_models/egoblur","title":"EgoBlur","description":"Overview","sidebar":"tutorialSidebar"},"open_models/evl":{"id":"open_models/evl","title":"Egocentric Voxel Lifting (EVL)","description":"Overview","sidebar":"tutorialSidebar"},"open_models/eye_tracking":{"id":"open_models/eye_tracking","title":"Eye Tracking","description":"Overview","sidebar":"tutorialSidebar"},"open_models/open_models":{"id":"open_models/open_models","title":"Open Models","description":"Project Aria has released several open models, powered by Project Aria data, and with the ability to extend beyond Aria data.","sidebar":"tutorialSidebar"},"open_models/psr":{"id":"open_models/psr","title":"Photoreal Scene Reconstruction","description":"Overview","sidebar":"tutorialSidebar"},"open_models/scenescript":{"id":"open_models/scenescript","title":"SceneScript","description":"Overview","sidebar":"tutorialSidebar"},"support":{"id":"support","title":"Support","description":"Overview","sidebar":"tutorialSidebar"},"tech_insights/camera_intrinsic_models":{"id":"tech_insights/camera_intrinsic_models","title":"Camera Intrinsic Models","description":"This page provides an overview of the intrinsic models used by RGB, Eye Tracking and Mono Scene (aka SLAM) cameras in Project Aria glasses. Go to the Project Aria FAQ for more calibration information and resources.","sidebar":"tutorialSidebar"},"tech_insights/camera_photometric_and_noise_model":{"id":"tech_insights/camera_photometric_and_noise_model","title":"Camera Photometric and Noise Models","description":"This page provides an overview of the Photometric and Noise models used by RGB, Eye Tracking and Mono Scene (aka SLAM) cameras in Project Aria glasses.","sidebar":"tutorialSidebar"},"tech_insights/device_timestamping":{"id":"tech_insights/device_timestamping","title":"Device Timestamping","description":"This page provides an overview of Project Aria devices are configured to create time aligned VRS recordings. Go to Timestamps in Aria VRS for how Aria data is formatted. Go to Temporal Alignment of Aria Sensor Data for Project Aria data is temporally aligned and provides information about how to finely align IMU, barometer and magnetometer data.","sidebar":"tutorialSidebar"},"tech_insights/imu_noise_model":{"id":"tech_insights/imu_noise_model","title":"IMU Noise Model","description":"In our visual-inertial fusion algorithm, we model, as traditionally done, the stochastic part of the IMU error as including three components:","sidebar":"tutorialSidebar"},"tech_insights/sensor_measurement_model":{"id":"tech_insights/sensor_measurement_model","title":"Sensor Measurement Model","description":"This page provides an overview of how Project Aria device sensor measurements are modeled for IMU, magnetometer, barometer and audio. Go to the Project Aria FAQ for more calibration information and resources.","sidebar":"tutorialSidebar"},"tech_insights/tech_insights":{"id":"tech_insights/tech_insights","title":"Tech Insights","description":"Technical deeper dives on domain-specific topics. You don\'t need to read this section to use Project Aria data or glasses, but you may find it interesting to understand how Aria glasses work.","sidebar":"tutorialSidebar"},"tech_insights/temporal_alignment_of_sensor_data":{"id":"tech_insights/temporal_alignment_of_sensor_data","title":"Temporal Alignment of Sensor Data","description":"This page provides an overview of how Project Aria data is temporally aligned and provides information about how to finely align IMU, barometer and magnetometer data.","sidebar":"tutorialSidebar"},"tech_spec/device_calibration":{"id":"tech_spec/device_calibration","title":"Device Calibration","description":"Most sensors in Project Aria glasses are calibrated extrinsically and intrinsically, to rectify from sensor measurements to real quantities in the physical world. Extrinsic calibrations model the 6-DoF pose among the sensors, while intrinsic calibrations model how sensor measurements maps to physical or geometrical quantities in the physical world. We also provide the extrinsic pose for the sensors in the CAD model to indicate where sensors are designed to be.","sidebar":"tutorialSidebar"},"tech_spec/hardware_spec":{"id":"tech_spec/hardware_spec","title":"Hardware Specifications","description":"Project Aria glasses have five cameras (two Mono Scene, one RGB, and two Eye Tracking cameras) as well as non-visual sensors (two IMUs, magnetometer, barometer, GPS, Wi-Fi beacon, Bluetooth beacon and Microphones). Mono Scene Cameras are often used to support SLAM algorithms, but they can have other applications.","sidebar":"tutorialSidebar"},"tech_spec/recording_profiles":{"id":"tech_spec/recording_profiles","title":"Recording Profiles","description":"Overview","sidebar":"tutorialSidebar"},"tech_spec/tech_spec":{"id":"tech_spec/tech_spec","title":"Technical Specifications","description":"The Technical Specifications section provides information about Project Aria glasses hardware, the different configurations Aria glasses can use when recording, and how Aria glasses are calibrated.","sidebar":"tutorialSidebar"}}}}')}}]);