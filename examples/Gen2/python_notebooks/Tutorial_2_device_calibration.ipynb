{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7c2a97",
   "metadata": {},
   "source": [
    "# Tutorial 2: Device calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dae0ba",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Most sensors in Aria glasses are calibrated both extrinsically and intrinsically, allowing you to rectify sensor measurements to real-world quantities. Calibration is performed per device, and the information is stored in the VRS file. This tutorial demonstrates how to work with device calibration in Project Aria using `projectaria_tools`. \n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "- How to obtain each sensor's calibration data  \n",
    "- Camera calibration: projection and unprojection, and how to post-process images according to calibration (distort).\n",
    "- IMU calibration: measurement rectification. \n",
    "- Multi-sensor coordination and sensor poses, and the concept of the \"Device\" frame. \n",
    "\n",
    "**Pre-requisite:**  \n",
    "Familiarity with VRS basics from `Tutorial_1_vrs_Data_provider_basics.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0224ae",
   "metadata": {},
   "source": [
    "### Obtaining Device Calibration Content\n",
    "\n",
    "Each VRS file's device calibration can be accessed as a `DeviceCalibration` instance via the `VrsDataProvider` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86397786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectaria_tools.core import data_provider\n",
    "from projectaria_tools.core import calibration\n",
    "\n",
    "# Load local VRS file\n",
    "vrs_file_path = \"path/to/your/recording.vrs\"\n",
    "vrs_data_provider = data_provider.create_vrs_data_provider(vrs_file_path)\n",
    "\n",
    "# Obtain device calibration\n",
    "device_calib = vrs_data_provider.get_device_calibration()\n",
    "if device_calib is None:\n",
    "    raise RuntimeError(\n",
    "        \"device calibration does not exist! Please use a VRS that contains valid device calibration for this tutorial. \"\n",
    "    )\n",
    "\n",
    "# You can obtain device version (Aria Gen1 vs Gen2), or device subtype (DVT with small/large frame width + short/long temple arms, etc) information from calibration\n",
    "if device_calib is not None:\n",
    "    device_version = device_calib.get_device_version()\n",
    "    device_subtype = device_calib.get_device_subtype()\n",
    "\n",
    "    print(\"Obtained valid calibration: \")\n",
    "    print(f\"Device Version: {calibration.get_name(device_version)}\")\n",
    "    print(f\"Device Subtype: {device_subtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321cc0e",
   "metadata": {},
   "source": [
    "### Accessing Individual Sensor Calibration\n",
    "\n",
    "`DeviceCalibration` provides APIs to query the intrinsics and extrinsics of each calibrated sensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c6941",
   "metadata": {},
   "source": [
    "#### 1. Camera Calibration Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d85d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sensor labels within device calibration\n",
    "all_labels = device_calib.get_all_labels()\n",
    "print(f\"All sensors within device calibration: {all_labels}\")\n",
    "print(f\"Cameras: {device_calib.get_camera_labels()}\")\n",
    "\n",
    "# Query a specific camera's calibration\n",
    "rgb_camera_label = \"camera-rgb\"\n",
    "camera_calib = device_calib.get_camera_calib(rgb_camera_label)\n",
    "\n",
    "if camera_calib is None:\n",
    "    raise RuntimeError(\n",
    "        \"camera-rgb calibration does not exist! Please use a VRS that contains valid RGB camera calibration for this tutorial. \"\n",
    "    )\n",
    "\n",
    "print(f\"-------------- camera calibration for {rgb_camera_label} ----------------\")\n",
    "print(f\"Image Size: {camera_calib.get_image_size()}\")\n",
    "print(f\"Camera Model Type: {camera_calib.get_model_name()}\")\n",
    "print(\n",
    "    f\"Camera Intrinsics Params: {camera_calib.get_projection_params()}, \\n\"\n",
    "    f\"where focal is {camera_calib.get_focal_lengths()}, \"\n",
    "    f\"and principal point is {camera_calib.get_principal_point()}\\n\"\n",
    ")\n",
    "\n",
    "# Get extrinsics (device to camera transformation)\n",
    "T_device_camera = camera_calib.get_transform_device_camera()\n",
    "print(f\"Camera Extrinsics T_Device_Camera:\\n{T_device_camera.to_matrix()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3112df8",
   "metadata": {},
   "source": [
    "#### 2. IMU calibration content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"IMUs: {device_calib.get_imu_labels()}\")\n",
    "\n",
    "# Query a specific IMU's calibration\n",
    "imu_label = \"imu-right\"\n",
    "imu_calib = device_calib.get_imu_calib(imu_label)\n",
    "\n",
    "if imu_calib is None:\n",
    "    raise RuntimeError(\n",
    "        \"imu-right calibration does not exist! Please use a VRS that contains valid IMU calibration for this tutorial. \"\n",
    "    )\n",
    "\n",
    "print(f\"-------------- IMU calibration for {imu_label} ----------------\")\n",
    "\n",
    "# Get IMU intrinsics parameters\n",
    "accel_bias = imu_calib.get_accel_model().get_bias()\n",
    "accel_rectification_matrix = imu_calib.get_accel_model().get_rectification()\n",
    "gyro_bias = imu_calib.get_gyro_model().get_bias()\n",
    "gyro_rectification_matrix = imu_calib.get_gyro_model().get_rectification()\n",
    "\n",
    "print(f\"Accelerometer Intrinsics:\")\n",
    "print(f\"  Bias: {accel_bias}\")\n",
    "print(f\"  Rectification Matrix:\\n{accel_rectification_matrix}\")\n",
    "\n",
    "print(f\"Gyroscope Intrinsics:\")\n",
    "print(f\"  Bias: {gyro_bias}\")\n",
    "print(f\"  Rectification Matrix:\\n{gyro_rectification_matrix}\")\n",
    "\n",
    "# Get extrinsics (device to IMU transformation)\n",
    "T_device_imu = imu_calib.get_transform_device_imu()\n",
    "print(f\"IMU Extrinsics T_Device_IMU:\\n{T_device_imu.to_matrix()}\")\n",
    "\n",
    "print(f\"  \\n ------IMPORTANT----- \\n \"\n",
    "      f\"Please use .raw_to_rectified_[accel,gyro]() and .rectified_to_raw_[accel,gyro]() APIs to apply IMU calibration! \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182932bf",
   "metadata": {},
   "source": [
    "#### 3. Magnetometer, barometer, and microphone calibration content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Magnetometers: {device_calib.get_magnetometer_labels()}\")\n",
    "print(f\"Barometers: {device_calib.get_barometer_labels()}\")\n",
    "print(f\"Microphones: {device_calib.get_microphone_labels()}\")\n",
    "\n",
    "# ----------------\n",
    "# Magnetometer calibration\n",
    "# ----------------\n",
    "magnetometer_label = \"mag0\"\n",
    "magnetometer_calib = device_calib.get_magnetometer_calib(magnetometer_label)\n",
    "\n",
    "if magnetometer_calib is None:\n",
    "    raise RuntimeError(\n",
    "        f\"{magnetometer_label} calibration does not exist! Please use a VRS that contains valid magnetometer calibration for this tutorial.\"\n",
    "    )\n",
    "\n",
    "# Get magnetometer intrinsics parameters\n",
    "mag_bias = magnetometer_calib.get_model().get_bias()\n",
    "mag_rectification_matrix = magnetometer_calib.get_model().get_rectification()\n",
    "\n",
    "print(f\"Magnetometer calibration for {magnetometer_label} only have intrinsics:\")\n",
    "print(f\"  Bias: {mag_bias}\")\n",
    "print(f\"  Rectification Matrix:\\n{mag_rectification_matrix}\")\n",
    "\n",
    "# ----------------\n",
    "# Barometer calibration\n",
    "# ----------------\n",
    "baro_label = \"baro0\"\n",
    "baro_calib = device_calib.get_barometer_calib(baro_label)\n",
    "\n",
    "if baro_calib is None:\n",
    "    raise RuntimeError(\n",
    "        f\"{baro_label} calibration does not exist! Please use a VRS that contains valid barometer calibration for this tutorial.\"\n",
    "    )\n",
    "\n",
    "print(f\"Barometer calibration for {baro_label} only have intrinsics:\")\n",
    "print(f\"  Slope: {baro_calib.get_slope()}\")\n",
    "print(f\"  Offset in Pascal:\\n{baro_calib.get_offset_pa()}\")\n",
    "\n",
    "# ----------------\n",
    "# Microphone calibration\n",
    "# ----------------\n",
    "microphone_labels = device_calib.get_microphone_labels()\n",
    "for mic_label in microphone_labels:\n",
    "    mic_calib = device_calib.get_microphone_calib(mic_label)\n",
    "    if mic_calib is None:\n",
    "        print(f\"Microphone calibration for {mic_label} is not available.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Microphone calibration for {mic_label} only has intrinsics:\")\n",
    "    print(f\"  sensitivity delta: {mic_calib.get_d_sensitivity_1k_dbv()}\")\n",
    "\n",
    "print(f\"  \\n ------IMPORTANT----- \\n \"\n",
    "    f\"Please use .raw_to_rectified() and .rectified_to_raw() APIs to apply magnetometer, barometer, and microphone calibration!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5fe107",
   "metadata": {},
   "source": [
    "### Camera Intrinsics: Project and Unproject\n",
    "\n",
    "A camera intrinsic model maps between a 3D point in the camera coordinate system and its corresponding 2D pixel on the sensor. This supports:\n",
    "\n",
    "- **Projection:** 3D point → 2D pixel\n",
    "- **Unprojection:** 2D pixel → 3D ray\n",
    "\n",
    "For more details, see the Project Aria wiki page on camera intrinsics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0273a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Project 3D point to pixel\n",
    "point_3d = np.array([0.1, 0.05, 1.0])  # Point in camera frame (meters)\n",
    "pixel = camera_calib.project(point_3d)\n",
    "if pixel is not None:\n",
    "    print(f\"3D point {point_3d} projected to -> pixel {pixel}\")\n",
    "else:\n",
    "    print(f\"3D point {point_3d} projected out of camera sensor plane\")\n",
    "\n",
    "# Unproject pixel to 3D ray.\n",
    "test_pixel = np.array([400, 300])\n",
    "ray_3d = camera_calib.unproject(test_pixel)\n",
    "print(f\"Pixel {test_pixel} unprojected to -> 3D ray {ray_3d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdf669d-64bc-4b2b-8846-cef9d31c0c96",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Camera Intrinsics: undistortion\n",
    "\n",
    "Camera calibration enables post-processing of Aria images, such as undistorting images from a fisheye to a linear camera model. Steps:\n",
    "\n",
    "1. Use `vrs_data_provider` to access the camera image and calibration.\n",
    "2. Create a linear camera model using `get_linear_camera_calibration` function.\n",
    "3. Apply `distort_by_calibration` to distort or undistort the image from the actual Fisheye camera model to linear camera model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c487289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with Rerun\n",
    "import rerun as rr\n",
    "\n",
    "rr.init(\"rerun_viz_image_undistortion\")\n",
    "\n",
    "# We already obtained RGB camera calibration as `camera_alib`.\n",
    "# Now, create a linear camera model that is similar to camera_calib\n",
    "linear_camera_model = calibration.get_linear_camera_calibration(\n",
    "    image_width=camera_calib.get_image_size()[0],\n",
    "    image_height=camera_calib.get_image_size()[1],\n",
    "    focal_length=camera_calib.get_focal_lengths()[0],\n",
    "    label=\"test_linear_camera\",\n",
    ")\n",
    "\n",
    "rgb_stream_id = vrs_data_provider.get_stream_id_from_label(\"camera-rgb\")\n",
    "num_samples = vrs_data_provider.get_num_data(rgb_stream_id)\n",
    "\n",
    "# Plot a few frames from RGB camera, and also plot the undistorted images\n",
    "first_few = min(10, num_samples)\n",
    "for i in range(first_few):\n",
    "    # Query RGB images\n",
    "    image_data, image_record = vrs_data_provider.get_image_data_by_index(\n",
    "        rgb_stream_id, i\n",
    "    )\n",
    "    if not image_data.is_valid():\n",
    "        continue\n",
    "\n",
    "    # Plot original RGB image\n",
    "    timestamp_ns = image_record.capture_timestamp_ns\n",
    "    rr.set_time_nanos(\"device_time\", timestamp_ns)\n",
    "    rr.log(\"camera_rgb\", rr.Image(image_data.to_numpy_array()))\n",
    "\n",
    "    # Undistort RGB image to a linear camera model\n",
    "    undistorted_image = calibration.distort_by_calibration(\n",
    "        arraySrc=image_data.to_numpy_array(),\n",
    "        dstCalib=linear_camera_model,\n",
    "        srcCalib=camera_calib,\n",
    "    )\n",
    "    rr.log(\"undistorted_camera_rgb\", rr.Image(undistorted_image))\n",
    "\n",
    "rr.notebook_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5309bd2f",
   "metadata": {},
   "source": [
    "### IMU Intrinsics: Measurement Rectification\n",
    "\n",
    "IMU intrinsics are represented by an affine model. The raw sensor readout (`value_raw`) is compensated to obtain the real acceleration or angular velocity (`value_compensated`):\n",
    "```\n",
    "value_compensated = M^-1 * (value_raw - bias)\n",
    "```\n",
    "- `M` is an upper triangular matrix (no global rotation between IMU body and accelerometer frame).\n",
    "\n",
    "To simulate sensor readout from real values:\n",
    "```\n",
    "value_raw = M * value_compensated + bias\n",
    "```\n",
    "\n",
    "Note that in the following example, the difference between raw reading and compensated IMU signals are pretty close, therefore the plotting may look similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_imu_plot_colors(rerun_plot_label):\n",
    "    \"\"\"\n",
    "    A helper function to set colors for the IMU plots in rerun\n",
    "    \"\"\"\n",
    "    rr.log(\n",
    "        f\"{rerun_plot_label}/accl/x[m/sec2]\",\n",
    "        rr.SeriesLine(color=[230, 25, 75], name=\"accel/x[m/sec2]\"),\n",
    "        static=True,\n",
    "    )  # Red\n",
    "    rr.log(\n",
    "        f\"{rerun_plot_label}/accl/y[m/sec2]\",\n",
    "        rr.SeriesLine(color=[60, 180, 75], name=\"accel/y[m/sec2]\"),\n",
    "        static=True,\n",
    "    )  # Green\n",
    "    rr.log(\n",
    "        f\"{rerun_plot_label}/accl/z[m/sec2]\",\n",
    "        rr.SeriesLine(color=[0, 130, 200], name=\"accel/z[m/sec2]\"),\n",
    "        static=True,\n",
    "    )  # Blue\n",
    "    rr.log(\n",
    "        f\"{rerun_plot_label}/gyro/x[rad/sec2]\",\n",
    "        rr.SeriesLine(color=[245, 130, 48], name=\"gyro/x[rad/sec2]\"),\n",
    "        static=True,\n",
    "    )  # Orange\n",
    "    rr.log(\n",
    "        f\"{rerun_plot_label}/gyro/y[rad/sec2]\",\n",
    "        rr.SeriesLine(color=[145, 30, 180], name=\"gyro/y[rad/sec2]\"),\n",
    "        static=True,\n",
    "    )  # Purple\n",
    "    rr.log(\n",
    "        f\"{rerun_plot_label}/gyro/z[rad/sec2]\",\n",
    "        rr.SeriesLine(color=[70, 240, 240], name=\"gyro/z[rad/sec2]\"),\n",
    "        static=True,\n",
    "    )  # Cyan\n",
    "\n",
    "\n",
    "def _plot_imu_signals(accel_data, gyro_data, rerun_plot_label):\n",
    "    \"\"\"\n",
    "    This is a helper function to plot IMU signals in Rerun 1D plot\n",
    "    \"\"\"\n",
    "    rr.log(\n",
    "        f\"{rerun_plot_label}/accl/x[m/sec2]\",\n",
    "        rr.Scalar(accel_data[0]),\n",
    "    )\n",
    "    rr.log(\n",
    "        f\"{rerun_plot_label}/accl/y[m/sec2]\",\n",
    "        rr.Scalar(accel_data[1]),\n",
    "    )\n",
    "    rr.log(\n",
    "        f\"{rerun_plot_label}/accl/z[m/sec2]\",\n",
    "        rr.Scalar(accel_data[2]),\n",
    "    )\n",
    "    rr.log(\n",
    "        f\"{rerun_plot_label}/gyro/x[rad/sec2]\",\n",
    "        rr.Scalar(gyro_data[0]),\n",
    "    )\n",
    "    rr.log(\n",
    "        f\"{rerun_plot_label}/gyro/y[rad/sec2]\",\n",
    "        rr.Scalar(gyro_data[1]),\n",
    "    )\n",
    "    rr.log(\n",
    "        f\"{rerun_plot_label}/gyro/z[rad/sec2]\",\n",
    "        rr.Scalar(gyro_data[2]),\n",
    "    )\n",
    "\n",
    "\n",
    "rr.init(\"rerun_viz_imu_rectification\")\n",
    "\n",
    "imu_label = \"imu-right\"\n",
    "imu_calib = device_calib.get_imu_calib(imu_label)\n",
    "imu_stream_id = vrs_data_provider.get_stream_id_from_label(imu_label)\n",
    "if imu_calib is None or imu_stream_id is None:\n",
    "    raise RuntimeError(\n",
    "        \"imu-right calibration or stream data does not exist! Please use a VRS that contains valid IMU calibration and data for this tutorial. \"\n",
    "    )\n",
    "\n",
    "num_samples = vrs_data_provider.get_num_data(imu_stream_id)\n",
    "first_few = min(5000, num_samples)\n",
    "\n",
    "# Set same colors for both plots\n",
    "_set_imu_plot_colors(\"imu_right\")\n",
    "_set_imu_plot_colors(\"imu_right_compensated\")\n",
    "\n",
    "for i in range(0, first_few, 50):\n",
    "    # Query IMU data\n",
    "    imu_data = vrs_data_provider.get_imu_data_by_index(imu_stream_id, i)\n",
    "\n",
    "    # Plot raw IMU readings\n",
    "    rr.set_time_nanos(\"device_time\", imu_data.capture_timestamp_ns)\n",
    "\n",
    "    # Get compensated imu data\n",
    "    compensated_accel = imu_calib.raw_to_rectified_accel(imu_data.accel_msec2)\n",
    "    compensated_gyro = imu_calib.raw_to_rectified_gyro(imu_data.gyro_radsec)\n",
    "\n",
    "    # print one sample content\n",
    "    if i == 0:\n",
    "        print(\n",
    "            f\"IMU compensation: raw accel {imu_data.accel_msec2} , compensated accel {compensated_accel}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"IMU compensation: raw gyro {imu_data.gyro_radsec} , compensated gyro {compensated_gyro}\"\n",
    "        )\n",
    "\n",
    "    # Plot raw IMU readings\n",
    "    _plot_imu_signals(imu_data.accel_msec2, imu_data.gyro_radsec, \"imu_right\")\n",
    "\n",
    "    # Plot compensated IMU readings in a separate plot\n",
    "    _plot_imu_signals(compensated_accel, compensated_gyro, \"imu_right_compensated\")\n",
    "\n",
    "rr.notebook_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd8361",
   "metadata": {},
   "source": [
    "### 5\\. Accessing Sensor Extrinsics\n",
    "\n",
    "The core API to query sensor extrinsics is: \n",
    "```\n",
    "get_transform_device_sensor(label = sensor_label, use_cad_calib = False)\n",
    "```\n",
    "This API returns the extrinsics of the sensor, represented as a `Sophus::SE3` (translation \\+ rotation).  in the reference coordinate frame of `Device`. \n",
    "- The `Device` frame is the reference coordinate system for all sensors.  \n",
    "- For Aria-Gen2, the \"Device\" frame is the left front-facing SLAM camera (`slam-front-left`).  \n",
    "- All sensor extrinsics are defined relative to this frame.\n",
    "\n",
    "The optional parameter `use_cad_calib` controls the \"source\" of the sensor extrinsics. \n",
    "- `use_cad_calib=False` (default): this will return the sensor extrinsics from factory calibration, if the sensor's extrinsics is factory-calibrated. This include:\n",
    "    - Cameras\n",
    "    - IMUs\n",
    "- `use_cad_calib=True`: this will return the sensor's extrinsics in their designed location in CAD.  This is useful for sensors without factory-calibrated extrinsics, including:\n",
    "    - Magnetometer  \n",
    "    - Barometer  \n",
    "    - Microphones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c5913c-b618-4bcb-98d7-1dfbfce514af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectaria_tools.utils.rerun_helpers import (\n",
    "    AriaGlassesOutline,\n",
    "    ToTransform3D,\n",
    "    ToBox3D,\n",
    ")\n",
    "\n",
    "rr.init(\"rerun_viz_sensor_extrinsics\")\n",
    "\n",
    "# Obtain a glass outline for visualization. This outline uses factory calibration extrinsics if possible, uses CAD extrinsics if factory calibration is not available.\n",
    "glass_outline = AriaGlassesOutline(device_calib, use_cad_calib=False)\n",
    "rr.log(\"device/glasses_outline\", rr.LineStrips3D([glass_outline]), static=True)\n",
    "\n",
    "# Plot all the sensor locations from either factory calibration (if available) or CAD\n",
    "sensor_labels = device_calib.get_all_labels()\n",
    "camera_labels = device_calib.get_camera_labels()\n",
    "for sensor in sensor_labels:\n",
    "    # Query for sensor extrinsics from factory calibration if possible. Fall back to CAD values if unavailable.\n",
    "    if (\"camera\" in sensor) or (\"imu\" in sensor):\n",
    "        T_device_sensor = device_calib.get_transform_device_sensor(label = sensor, get_cad_value = False)\n",
    "    else:\n",
    "        T_device_sensor = device_calib.get_transform_device_sensor(label = sensor, get_cad_value = True)\n",
    "\n",
    "    # Skip if extrinsics cannot be obtained\n",
    "    if T_device_sensor is None:\n",
    "        print(f\"Warning: sensor {sensor} does not have extrinsics from neither factory calibration nor CAD, skipping the plotting.\")\n",
    "        continue\n",
    "\n",
    "    # Plot sensor labels\n",
    "    rr.log(f\"device/{sensor}\", ToTransform3D(T_device_sensor), static=True)\n",
    "    rr.log(\n",
    "        f\"device/{sensor}/text\",\n",
    "        ToBox3D(sensor, [1e-5, 1e-5, 1e-5]),\n",
    "        static=True,\n",
    "    )\n",
    "\n",
    "    # For cameras, also plot camera frustrum\n",
    "    if sensor in camera_labels:\n",
    "        camera_calibration = device_calib.get_camera_calib(sensor)\n",
    "        rr.log(f\"device/{sensor}_frustum\", ToTransform3D(T_device_sensor), static=True)\n",
    "        rr.log(\n",
    "            f\"device/{sensor}_frustum\",\n",
    "            rr.Pinhole(\n",
    "                resolution=[\n",
    "                    camera_calibration.get_image_size()[0],\n",
    "                    camera_calibration.get_image_size()[1],\n",
    "                ],\n",
    "                focal_length=float(camera_calibration.get_focal_lengths()[0]),\n",
    "            ),\n",
    "            static=True,\n",
    "        )\n",
    "\n",
    "rr.notebook_show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
