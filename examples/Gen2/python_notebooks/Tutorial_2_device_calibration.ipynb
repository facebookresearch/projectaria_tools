{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bd7c2a97",
      "metadata": {},
      "source": [
        "# Tutorial 2: Device calibration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8dae0ba",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "Most sensors in Aria glasses are calibrated both extrinsically and intrinsically, allowing you to rectify sensor measurements to real-world quantities. Calibration is performed per device, and the information is stored in the VRS file. This tutorial demonstrates how to work with device calibration in Project Aria using `projectaria_tools`. \n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "- How to obtain each sensor's calibration data  \n",
        "- Camera calibration: projection and unprojection, and how to post-process images according to calibration (distort).\n",
        "- IMU calibration: measurement rectification. \n",
        "- Multi-sensor coordination and sensor poses, and the concept of the \"Device\" frame. \n",
        "\n",
        "**Pre-requisite:**  \n",
        "- Familiarity with VRS basics from `Tutorial_1_vrs_Data_provider_basics.ipynb`.\n",
        "- Download Aria Gen2 sample data from [link](https://www.projectaria.com/async/sample/download/?bucket=core&filename=aria_gen2_sample_data_1.vrs)\n",
        "\n",
        "**Note on Visualization**\n",
        "If visualization window is not showing up, this is due to `Rerun` lib's caching issue. Just rerun the specific code cell."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c0224ae",
      "metadata": {},
      "source": [
        "### Obtaining Device Calibration Content\n",
        "\n",
        "Each VRS file's device calibration can be accessed as a `DeviceCalibration` instance via the `VrsDataProvider` API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86397786",
      "metadata": {},
      "outputs": [],
      "source": [
        "from projectaria_tools.core import data_provider\n",
        "from projectaria_tools.core import calibration\n",
        "\n",
        "# Load local VRS file\n",
        "vrs_file_path = \"path/to/your/recording.vrs\"\n",
        "vrs_data_provider = data_provider.create_vrs_data_provider(vrs_file_path)\n",
        "\n",
        "# Obtain device calibration\n",
        "device_calib = vrs_data_provider.get_device_calibration()\n",
        "if device_calib is None:\n",
        "    raise RuntimeError(\n",
        "        \"device calibration does not exist! Please use a VRS that contains valid device calibration for this tutorial. \"\n",
        "    )\n",
        "\n",
        "# You can obtain device version (Aria Gen1 vs Gen2), or device subtype (DVT with small/large frame width + short/long temple arms, etc) information from calibration\n",
        "if device_calib is not None:\n",
        "    device_version = device_calib.get_device_version()\n",
        "    device_subtype = device_calib.get_device_subtype()\n",
        "\n",
        "    print(\"Obtained valid calibration: \")\n",
        "    print(f\"Device Version: {calibration.get_name(device_version)}\")\n",
        "    print(f\"Device Subtype: {device_subtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3321cc0e",
      "metadata": {},
      "source": [
        "### Accessing Individual Sensor Calibration\n",
        "\n",
        "`DeviceCalibration` provides APIs to query the intrinsics and extrinsics of each calibrated sensor."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60c6941",
      "metadata": {},
      "source": [
        "#### 1. Camera Calibration Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89d85d9a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get sensor labels within device calibration\n",
        "all_labels = device_calib.get_all_labels()\n",
        "print(f\"All sensors within device calibration: {all_labels}\")\n",
        "print(f\"Cameras: {device_calib.get_camera_labels()}\")\n",
        "\n",
        "# Query a specific camera's calibration\n",
        "rgb_camera_label = \"camera-rgb\"\n",
        "camera_calib = device_calib.get_camera_calib(rgb_camera_label)\n",
        "\n",
        "if camera_calib is None:\n",
        "    raise RuntimeError(\n",
        "        \"camera-rgb calibration does not exist! Please use a VRS that contains valid RGB camera calibration for this tutorial. \"\n",
        "    )\n",
        "\n",
        "print(f\"-------------- camera calibration for {rgb_camera_label} ----------------\")\n",
        "print(f\"Image Size: {camera_calib.get_image_size()}\")\n",
        "print(f\"Camera Model Type: {camera_calib.get_model_name()}\")\n",
        "print(\n",
        "    f\"Camera Intrinsics Params: {camera_calib.get_projection_params()}, \\n\"\n",
        "    f\"where focal is {camera_calib.get_focal_lengths()}, \"\n",
        "    f\"and principal point is {camera_calib.get_principal_point()}\\n\"\n",
        ")\n",
        "\n",
        "# Get extrinsics (device to camera transformation)\n",
        "T_device_camera = camera_calib.get_transform_device_camera()\n",
        "print(f\"Camera Extrinsics T_Device_Camera:\\n{T_device_camera.to_matrix()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3112df8",
      "metadata": {},
      "source": [
        "#### 2. IMU calibration content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c2555a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"IMUs: {device_calib.get_imu_labels()}\")\n",
        "\n",
        "# Query a specific IMU's calibration\n",
        "imu_label = \"imu-right\"\n",
        "imu_calib = device_calib.get_imu_calib(imu_label)\n",
        "\n",
        "if imu_calib is None:\n",
        "    raise RuntimeError(\n",
        "        \"imu-right calibration does not exist! Please use a VRS that contains valid IMU calibration for this tutorial. \"\n",
        "    )\n",
        "\n",
        "print(f\"-------------- IMU calibration for {imu_label} ----------------\")\n",
        "\n",
        "# Get IMU intrinsics parameters\n",
        "accel_bias = imu_calib.get_accel_model().get_bias()\n",
        "accel_rectification_matrix = imu_calib.get_accel_model().get_rectification()\n",
        "gyro_bias = imu_calib.get_gyro_model().get_bias()\n",
        "gyro_rectification_matrix = imu_calib.get_gyro_model().get_rectification()\n",
        "\n",
        "print(f\"Accelerometer Intrinsics:\")\n",
        "print(f\"  Bias: {accel_bias}\")\n",
        "print(f\"  Rectification Matrix:\\n{accel_rectification_matrix}\")\n",
        "\n",
        "print(f\"Gyroscope Intrinsics:\")\n",
        "print(f\"  Bias: {gyro_bias}\")\n",
        "print(f\"  Rectification Matrix:\\n{gyro_rectification_matrix}\")\n",
        "\n",
        "# Get extrinsics (device to IMU transformation)\n",
        "T_device_imu = imu_calib.get_transform_device_imu()\n",
        "print(f\"IMU Extrinsics T_Device_IMU:\\n{T_device_imu.to_matrix()}\")\n",
        "\n",
        "print(f\"  \\n ------IMPORTANT----- \\n \"\n",
        "      f\"Please use .raw_to_rectified_[accel,gyro]() and .rectified_to_raw_[accel,gyro]() APIs to apply IMU calibration! \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "182932bf",
      "metadata": {},
      "source": [
        "#### 3. Magnetometer, barometer, and microphone calibration content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "743a4899",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Magnetometers: {device_calib.get_magnetometer_labels()}\")\n",
        "print(f\"Barometers: {device_calib.get_barometer_labels()}\")\n",
        "print(f\"Microphones: {device_calib.get_microphone_labels()}\")\n",
        "\n",
        "# ----------------\n",
        "# Magnetometer calibration\n",
        "# ----------------\n",
        "magnetometer_label = \"mag0\"\n",
        "magnetometer_calib = device_calib.get_magnetometer_calib(magnetometer_label)\n",
        "\n",
        "if magnetometer_calib is None:\n",
        "    raise RuntimeError(\n",
        "        f\"{magnetometer_label} calibration does not exist! Please use a VRS that contains valid magnetometer calibration for this tutorial.\"\n",
        "    )\n",
        "\n",
        "# Get magnetometer intrinsics parameters\n",
        "mag_bias = magnetometer_calib.get_model().get_bias()\n",
        "mag_rectification_matrix = magnetometer_calib.get_model().get_rectification()\n",
        "\n",
        "print(f\"Magnetometer calibration for {magnetometer_label} only have intrinsics:\")\n",
        "print(f\"  Bias: {mag_bias}\")\n",
        "print(f\"  Rectification Matrix:\\n{mag_rectification_matrix}\")\n",
        "\n",
        "# ----------------\n",
        "# Barometer calibration\n",
        "# ----------------\n",
        "baro_label = \"baro0\"\n",
        "baro_calib = device_calib.get_barometer_calib(baro_label)\n",
        "\n",
        "if baro_calib is None:\n",
        "    raise RuntimeError(\n",
        "        f\"{baro_label} calibration does not exist! Please use a VRS that contains valid barometer calibration for this tutorial.\"\n",
        "    )\n",
        "\n",
        "print(f\"Barometer calibration for {baro_label} only have intrinsics:\")\n",
        "print(f\"  Slope: {baro_calib.get_slope()}\")\n",
        "print(f\"  Offset in Pascal:\\n{baro_calib.get_offset_pa()}\")\n",
        "\n",
        "# ----------------\n",
        "# Microphone calibration, containing both mic and speaker calibrations.\n",
        "# ----------------\n",
        "microphone_labels = device_calib.get_microphone_labels()\n",
        "speaker_labels = device_calib.get_speaker_labels()\n",
        "audio_sensor_labels = device_calib.get_audio_labels()\n",
        "print(f\"Both mic and speakers are calibrated. \\n\"\n",
        "f\"List of mics that are calibrated: {microphone_labels} \\n\"\n",
        "f\"List of speakers that are calibrated: {speaker_labels}\")\n",
        "\n",
        "for audio_label in audio_sensor_labels:\n",
        "    audio_calib = device_calib.get_microphone_calib(audio_label)\n",
        "    if audio_calib is None:\n",
        "        print(f\"Audio sensor calibration for {audio_label} is not available.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Audio sensor calibration for {audio_label} only has intrinsics:\")\n",
        "    print(f\"  sensitivity delta: {audio_calib.get_d_sensitivity_1k_dbv()}\")\n",
        "\n",
        "print(f\"  \\n ------IMPORTANT----- \\n \"\n",
        "    f\"Please use .raw_to_rectified() and .rectified_to_raw() APIs to apply magnetometer, barometer, and microphone calibration!\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc5fe107",
      "metadata": {},
      "source": [
        "### Camera Intrinsics: Project and Unproject\n",
        "\n",
        "A camera intrinsic model maps between a 3D point in the camera coordinate system and its corresponding 2D pixel on the sensor. This supports:\n",
        "\n",
        "- **Projection:** 3D point → 2D pixel\n",
        "- **Unprojection:** 2D pixel → 3D ray\n",
        "\n",
        "For more details, see the Project Aria wiki page on camera intrinsics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a0273a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Project 3D point to pixel\n",
        "point_3d = np.array([0.1, 0.05, 1.0])  # Point in camera frame (meters)\n",
        "pixel = camera_calib.project(point_3d)\n",
        "if pixel is not None:\n",
        "    print(f\"3D point {point_3d} projected to -> pixel {pixel}\")\n",
        "else:\n",
        "    print(f\"3D point {point_3d} projected out of camera sensor plane\")\n",
        "\n",
        "# Unproject pixel to 3D ray.\n",
        "test_pixel = np.array([400, 300])\n",
        "ray_3d = camera_calib.unproject(test_pixel)\n",
        "print(f\"Pixel {test_pixel} unprojected to -> 3D ray {ray_3d}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bdf669d-64bc-4b2b-8846-cef9d31c0c96",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "## Camera Intrinsics: undistortion\n",
        "\n",
        "Camera calibration enables post-processing of Aria images, such as undistorting images from a fisheye to a linear camera model. Steps:\n",
        "\n",
        "1. Use `vrs_data_provider` to access the camera image and calibration.\n",
        "2. Create a linear camera model using `get_linear_camera_calibration` function.\n",
        "3. Apply `distort_by_calibration` to distort or undistort the image from the actual Fisheye camera model to linear camera model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c487289",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize with Rerun\n",
        "import rerun as rr\n",
        "\n",
        "rr.init(\"rerun_viz_image_undistortion\")\n",
        "\n",
        "# We already obtained RGB camera calibration as `camera_alib`.\n",
        "# Now, create a linear camera model that is similar to camera_calib\n",
        "linear_camera_model = calibration.get_linear_camera_calibration(\n",
        "    image_width=camera_calib.get_image_size()[0],\n",
        "    image_height=camera_calib.get_image_size()[1],\n",
        "    focal_length=camera_calib.get_focal_lengths()[0],\n",
        "    label=\"test_linear_camera\",\n",
        ")\n",
        "\n",
        "rgb_stream_id = vrs_data_provider.get_stream_id_from_label(\"camera-rgb\")\n",
        "num_samples = vrs_data_provider.get_num_data(rgb_stream_id)\n",
        "\n",
        "# Plot a few frames from RGB camera, and also plot the undistorted images\n",
        "first_few = min(10, num_samples)\n",
        "for i in range(first_few):\n",
        "    # Query RGB images\n",
        "    image_data, image_record = vrs_data_provider.get_image_data_by_index(\n",
        "        rgb_stream_id, i\n",
        "    )\n",
        "    if not image_data.is_valid():\n",
        "        continue\n",
        "\n",
        "    # Plot original RGB image\n",
        "    timestamp_ns = image_record.capture_timestamp_ns\n",
        "    rr.set_time_nanos(\"device_time\", timestamp_ns)\n",
        "    rr.log(\"camera_rgb\", rr.Image(image_data.to_numpy_array()))\n",
        "\n",
        "    # Undistort RGB image to a linear camera model\n",
        "    undistorted_image = calibration.distort_by_calibration(\n",
        "        arraySrc=image_data.to_numpy_array(),\n",
        "        dstCalib=linear_camera_model,\n",
        "        srcCalib=camera_calib,\n",
        "    )\n",
        "    rr.log(\"undistorted_camera_rgb\", rr.Image(undistorted_image))\n",
        "rr.notebook_show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5309bd2f",
      "metadata": {},
      "source": [
        "### IMU Intrinsics: Measurement Rectification\n",
        "\n",
        "IMU intrinsics are represented by an affine model. The raw sensor readout (`value_raw`) is compensated to obtain the real acceleration or angular velocity (`value_compensated`):\n",
        "```\n",
        "value_compensated = M^-1 * (value_raw - bias)\n",
        "```\n",
        "- `M` is an upper triangular matrix (no global rotation between IMU body and accelerometer frame).\n",
        "\n",
        "To simulate sensor readout from real values:\n",
        "```\n",
        "value_raw = M * value_compensated + bias\n",
        "```\n",
        "\n",
        "Note that in the following example, the difference between raw reading and compensated IMU signals are pretty close, therefore the plotting may look similar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8eb11d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def _set_imu_plot_colors(rerun_plot_label):\n",
        "    \"\"\"\n",
        "    A helper function to set colors for the IMU plots in rerun\n",
        "    \"\"\"\n",
        "    rr.log(\n",
        "        f\"{rerun_plot_label}/accl/x[m/sec2]\",\n",
        "        rr.SeriesLine(color=[230, 25, 75], name=\"accel/x[m/sec2]\"),\n",
        "        static=True,\n",
        "    )  # Red\n",
        "    rr.log(\n",
        "        f\"{rerun_plot_label}/accl/y[m/sec2]\",\n",
        "        rr.SeriesLine(color=[60, 180, 75], name=\"accel/y[m/sec2]\"),\n",
        "        static=True,\n",
        "    )  # Green\n",
        "    rr.log(\n",
        "        f\"{rerun_plot_label}/accl/z[m/sec2]\",\n",
        "        rr.SeriesLine(color=[0, 130, 200], name=\"accel/z[m/sec2]\"),\n",
        "        static=True,\n",
        "    )  # Blue\n",
        "    rr.log(\n",
        "        f\"{rerun_plot_label}/gyro/x[rad/sec2]\",\n",
        "        rr.SeriesLine(color=[245, 130, 48], name=\"gyro/x[rad/sec2]\"),\n",
        "        static=True,\n",
        "    )  # Orange\n",
        "    rr.log(\n",
        "        f\"{rerun_plot_label}/gyro/y[rad/sec2]\",\n",
        "        rr.SeriesLine(color=[145, 30, 180], name=\"gyro/y[rad/sec2]\"),\n",
        "        static=True,\n",
        "    )  # Purple\n",
        "    rr.log(\n",
        "        f\"{rerun_plot_label}/gyro/z[rad/sec2]\",\n",
        "        rr.SeriesLine(color=[70, 240, 240], name=\"gyro/z[rad/sec2]\"),\n",
        "        static=True,\n",
        "    )  # Cyan\n",
        "\n",
        "\n",
        "def _plot_imu_signals(accel_data, gyro_data, rerun_plot_label):\n",
        "    \"\"\"\n",
        "    This is a helper function to plot IMU signals in Rerun 1D plot\n",
        "    \"\"\"\n",
        "    rr.log(\n",
        "        f\"{rerun_plot_label}/accl/x[m/sec2]\",\n",
        "        rr.Scalar(accel_data[0]),\n",
        "    )\n",
        "    rr.log(\n",
        "        f\"{rerun_plot_label}/accl/y[m/sec2]\",\n",
        "        rr.Scalar(accel_data[1]),\n",
        "    )\n",
        "    rr.log(\n",
        "        f\"{rerun_plot_label}/accl/z[m/sec2]\",\n",
        "        rr.Scalar(accel_data[2]),\n",
        "    )\n",
        "    rr.log(\n",
        "        f\"{rerun_plot_label}/gyro/x[rad/sec2]\",\n",
        "        rr.Scalar(gyro_data[0]),\n",
        "    )\n",
        "    rr.log(\n",
        "        f\"{rerun_plot_label}/gyro/y[rad/sec2]\",\n",
        "        rr.Scalar(gyro_data[1]),\n",
        "    )\n",
        "    rr.log(\n",
        "        f\"{rerun_plot_label}/gyro/z[rad/sec2]\",\n",
        "        rr.Scalar(gyro_data[2]),\n",
        "    )\n",
        "\n",
        "\n",
        "rr.init(\"rerun_viz_imu_rectification\")\n",
        "\n",
        "imu_label = \"imu-right\"\n",
        "imu_calib = device_calib.get_imu_calib(imu_label)\n",
        "imu_stream_id = vrs_data_provider.get_stream_id_from_label(imu_label)\n",
        "if imu_calib is None or imu_stream_id is None:\n",
        "    raise RuntimeError(\n",
        "        \"imu-right calibration or stream data does not exist! Please use a VRS that contains valid IMU calibration and data for this tutorial. \"\n",
        "    )\n",
        "\n",
        "num_samples = vrs_data_provider.get_num_data(imu_stream_id)\n",
        "first_few = min(5000, num_samples)\n",
        "\n",
        "# Set same colors for both plots\n",
        "_set_imu_plot_colors(\"imu_right\")\n",
        "_set_imu_plot_colors(\"imu_right_compensated\")\n",
        "\n",
        "for i in range(0, first_few, 50):\n",
        "    # Query IMU data\n",
        "    imu_data = vrs_data_provider.get_imu_data_by_index(imu_stream_id, i)\n",
        "\n",
        "    # Plot raw IMU readings\n",
        "    rr.set_time_nanos(\"device_time\", imu_data.capture_timestamp_ns)\n",
        "\n",
        "    # Get compensated imu data\n",
        "    compensated_accel = imu_calib.raw_to_rectified_accel(imu_data.accel_msec2)\n",
        "    compensated_gyro = imu_calib.raw_to_rectified_gyro(imu_data.gyro_radsec)\n",
        "\n",
        "    # print one sample content\n",
        "    if i == 0:\n",
        "        print(\n",
        "            f\"IMU compensation: raw accel {imu_data.accel_msec2} , compensated accel {compensated_accel}\"\n",
        "        )\n",
        "        print(\n",
        "            f\"IMU compensation: raw gyro {imu_data.gyro_radsec} , compensated gyro {compensated_gyro}\"\n",
        "        )\n",
        "\n",
        "    # Plot raw IMU readings\n",
        "    _plot_imu_signals(imu_data.accel_msec2, imu_data.gyro_radsec, \"imu_right\")\n",
        "\n",
        "    # Plot compensated IMU readings in a separate plot\n",
        "    _plot_imu_signals(compensated_accel, compensated_gyro, \"imu_right_compensated\")\n",
        "\n",
        "rr.notebook_show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abfd8361",
      "metadata": {},
      "source": [
        "### 5\\. Accessing Sensor Extrinsics\n",
        "\n",
        "The core API to query sensor extrinsics is: \n",
        "```\n",
        "get_transform_device_sensor(label = sensor_label, use_cad_calib = False)\n",
        "```\n",
        "This API returns the extrinsics of the sensor, represented as a `Sophus::SE3` (translation \\+ rotation).  in the reference coordinate frame of `Device`. \n",
        "- The `Device` frame is the reference coordinate system for all sensors.  \n",
        "- For Aria-Gen2, the \"Device\" frame is the left front-facing SLAM camera (`slam-front-left`).  \n",
        "- All sensor extrinsics are defined relative to this frame.\n",
        "\n",
        "The optional parameter `use_cad_calib` controls the \"source\" of the sensor extrinsics. \n",
        "- `use_cad_calib=False` (default): this will return the sensor extrinsics from factory calibration, if the sensor's extrinsics is factory-calibrated. This include:\n",
        "    - Cameras\n",
        "    - IMUs\n",
        "- `use_cad_calib=True`: this will return the sensor's extrinsics in their designed location in CAD.  This is useful for sensors without factory-calibrated extrinsics, including:\n",
        "    - Magnetometer  \n",
        "    - Barometer  \n",
        "    - Microphones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84c5913c-b618-4bcb-98d7-1dfbfce514af",
      "metadata": {},
      "outputs": [],
      "source": [
        "from projectaria_tools.utils.rerun_helpers import (\n",
        "    AriaGlassesOutline,\n",
        "    ToTransform3D,\n",
        "    ToBox3D,\n",
        ")\n",
        "\n",
        "rr.init(\"rerun_viz_sensor_extrinsics\")\n",
        "\n",
        "# Obtain a glass outline for visualization. This outline uses factory calibration extrinsics if possible, uses CAD extrinsics if factory calibration is not available.\n",
        "glass_outline = AriaGlassesOutline(device_calib, use_cad_calib=False)\n",
        "rr.log(\"device/glasses_outline\", rr.LineStrips3D([glass_outline]), static=True)\n",
        "\n",
        "# Plot all the sensor locations from either factory calibration (if available) or CAD\n",
        "sensor_labels = device_calib.get_all_labels()\n",
        "camera_labels = device_calib.get_camera_labels()\n",
        "for sensor in sensor_labels:\n",
        "    # Query for sensor extrinsics from factory calibration if possible. Fall back to CAD values if unavailable.\n",
        "    if (\"camera\" in sensor) or (\"imu\" in sensor):\n",
        "        T_device_sensor = device_calib.get_transform_device_sensor(label = sensor, get_cad_value = False)\n",
        "    else:\n",
        "        T_device_sensor = device_calib.get_transform_device_sensor(label = sensor, get_cad_value = True)\n",
        "\n",
        "    # Skip if extrinsics cannot be obtained\n",
        "    if T_device_sensor is None:\n",
        "        print(f\"Warning: sensor {sensor} does not have extrinsics from neither factory calibration nor CAD, skipping the plotting.\")\n",
        "        continue\n",
        "\n",
        "    # Plot sensor labels\n",
        "    rr.log(f\"device/{sensor}\", ToTransform3D(T_device_sensor), static=True)\n",
        "    rr.log(\n",
        "        f\"device/{sensor}/text\",\n",
        "        ToBox3D(sensor, [1e-5, 1e-5, 1e-5]),\n",
        "        static=True,\n",
        "    )\n",
        "\n",
        "    # For cameras, also plot camera frustum\n",
        "    if sensor in camera_labels:\n",
        "        camera_calibration = device_calib.get_camera_calib(sensor)\n",
        "        rr.log(f\"device/{sensor}_frustum\", ToTransform3D(T_device_sensor), static=True)\n",
        "        rr.log(\n",
        "            f\"device/{sensor}_frustum\",\n",
        "            rr.Pinhole(\n",
        "                resolution=[\n",
        "                    camera_calibration.get_image_size()[0],\n",
        "                    camera_calibration.get_image_size()[1],\n",
        "                ],\n",
        "                focal_length=float(camera_calibration.get_focal_lengths()[0]),\n",
        "            ),\n",
        "            static=True,\n",
        "        )\n",
        "\n",
        "rr.notebook_show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
