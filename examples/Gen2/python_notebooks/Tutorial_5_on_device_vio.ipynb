{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4737c1",
   "metadata": {},
   "source": [
    "# Tutorial 5: On-Device VIO data streams\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In Aria-Gen2 glasses, one of the key upgrade from Aria-Gen1 is the capability to run Machine Perception (MP) algorithms on the device during streaming / recording. Currently supported on-device MP algorithms include Eye-tracking, Hand-tracking, and VIO. These algorithm results are stored as separate data streams in the VRS file. \n",
    "\n",
    "**VIO (Visual Inertial Odometry)** combines camera images and IMU (Inertial Measurement Unit) data to estimate device pose and motion in real-time. VIO tracks the device's position, orientation, and velocity by performing visual tracking, IMU integration, sensor fusion, etc, making it the foundation for spatial tracking and understanding. \n",
    "\n",
    "In Aria-Gen2 devices, the VIO algorithm are run on device to produce 2 types of tracking results as part of the VRS file: VIO and VIO High Frequency. \n",
    "This tutorial focuses on demonstration of how to use the **on-device VIO and VIO_high_frequency** results. \n",
    "\n",
    "**What you'll learn:**\n",
    "\n",
    "- How to access on-device VIO and VIO_high_frequency data from VRS files\n",
    "- How to visualize 3D trajectory from on-device VIO data.\n",
    "\n",
    "**Prerequisites**\n",
    "- Complete Tutorial 1 (VrsDataProvider Basics) to understand basic data provider concepts\n",
    "- Complete Tutorial 2 (Device Calibration) to understand how to properly use calibration in Aria data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e2224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectaria_tools.core import data_provider\n",
    "\n",
    "# Load local VRS file\n",
    "vrs_file_path = \"path/to/your/recording.vrs\"\n",
    "vrs_data_provider = data_provider.create_vrs_data_provider(vrs_file_path)\n",
    "\n",
    "# Query VIO data streams\n",
    "vio_label = \"vio\"\n",
    "vio_stream_id = vrs_data_provider.get_stream_id_from_label(vio_label)\n",
    "if vio_stream_id is None:\n",
    "    raise RuntimeError(\n",
    "        f\"{vio_label} data stream does not exist! Please use a VRS that contains valid VIO data for this tutorial.\"\n",
    "    )\n",
    "\n",
    "# Query VIO_high_frequency data streams\n",
    "vio_high_freq_label = \"vio_high_frequency\"\n",
    "vio_high_freq_stream_id = vrs_data_provider.get_stream_id_from_label(vio_high_freq_label)\n",
    "if vio_high_freq_stream_id is None:\n",
    "    raise RuntimeError(\n",
    "        f\"{vio_high_freq_label} data stream does not exist! Please use a VRS that contains valid VIO high frequency data for this tutorial.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4d85a",
   "metadata": {},
   "source": [
    "## On-Device VIO Data Stream\n",
    "### Data Type: `FrontendOutput`\n",
    "This a new data type introduced to store the results from the VIO system, containing the following fields: \n",
    "\n",
    "| Field Name                    | Description                                |\n",
    "| ----------------------------- | ------------------------------------------ |\n",
    "| `frontend_session_uid`        | Session identifier (resets on VIO restart) |\n",
    "| `frame_id`                    | Frame set identifier                       |\n",
    "| `capture_timestamp_ns`        | Center capture time in nanoseconds         |\n",
    "| `unix_timestamp_ns`           | Unix timestamp in nanoseconds              |\n",
    "| `status`                      | VIO status (VALID/INVALID)                 |\n",
    "| `pose_quality`                | Pose quality (GOOD/BAD/UNKNOWN)            |\n",
    "| `visual_tracking_quality`     | Visual-only tracking quality               |\n",
    "| `online_calib`                | Online calibration estimates for SLAM cameras and IMUs  |\n",
    "| `gravity_in_odometry`         | Gravity vector in odometry frame           |\n",
    "| `transform_odometry_bodyimu`  | Body IMU's pose in odometry reference frame         |\n",
    "| `transform_bodyimu_device`    | Transform from body IMU to device frame    |\n",
    "| `linear_velocity_in_odometry` | Linear velocity in odometry frame in m/s         |\n",
    "| `angular_velocity_in_bodyimu` | Angular velocity in body IMU frame in rad/s      |\n",
    "\n",
    "Here, **body IMU** is the IMU that is picked as the reference for motion tracking. For Aria-Gen2' on-device VIO algorithm, this is often `imu-left`. \n",
    "\n",
    "**Important Note**: Always check `status == VioStatus.VALID` and\n",
    "`pose_quality == TrackingQuality.GOOD` for VIO data validity!\n",
    "\n",
    "### Data Access API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectaria_tools.core.sensor_data import VioStatus, TrackingQuality\n",
    "\n",
    "print(\"=== VIO Data Sample ===\")\n",
    "\n",
    "# Find the first valid VIO data sample\n",
    "num_vio_samples = vrs_data_provider.get_num_data(vio_stream_id)\n",
    "first_valid_index = None\n",
    "for idx in range(num_vio_samples):\n",
    "    vio_data = vrs_data_provider.get_vio_data_by_index(vio_stream_id, idx)\n",
    "    if (\n",
    "        vio_data.status == VioStatus.VALID\n",
    "        and vio_data.pose_quality == TrackingQuality.GOOD\n",
    "    ):\n",
    "        first_valid_index = idx\n",
    "        break\n",
    "\n",
    "if first_valid_index is not None:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"First VALID VIO Data Sample (Index: {first_valid_index})\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Session Information\n",
    "    print(f\"Session UID: {vio_data.frontend_session_uid}\")\n",
    "    print(f\"Frame ID: {vio_data.frame_id}\")\n",
    "\n",
    "    # Timestamps\n",
    "    print(f\"Capture Time: {vio_data.capture_timestamp_ns} ns\")\n",
    "    print(f\"Unix Time: {vio_data.unix_timestamp_ns} ns\")\n",
    "\n",
    "    # Quality Status\n",
    "    print(f\"Status: {vio_data.status}\")\n",
    "    print(f\"Pose Quality: {vio_data.pose_quality}\")\n",
    "    print(f\"Visual Quality: {vio_data.visual_tracking_quality}\")\n",
    "\n",
    "    # Transforms\n",
    "    print(f\"Transform Odometry → Body IMU:\\n{vio_data.transform_odometry_bodyimu.to_matrix()}\")\n",
    "    print(f\"Transform Body IMU → Device:\\n{vio_data.transform_bodyimu_device.to_matrix()}\")\n",
    "\n",
    "    # Motion\n",
    "    print(f\"Linear Velocity: {vio_data.linear_velocity_in_odometry}\")\n",
    "    print(f\"Angular Velocity: {vio_data.angular_velocity_in_bodyimu}\")\n",
    "    print(f\"Gravity Vector: {vio_data.gravity_in_odometry}\")\n",
    "else:\n",
    "    print(\"⚠️  No valid VIO sample found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cdac1",
   "metadata": {},
   "source": [
    "## On-Device VIO High Frequency Data Stream\n",
    "\n",
    "**VIO High Frequency** results are generated directly from the on-device VIO results by performing IMU integration between VIO poses, hence provides a much higher data rate at approximately **800Hz**. \n",
    "\n",
    "### Data Type: `OpenLoopTrajectoryPose`\n",
    "The **VioHighFrequency** stream **re-uses** the `OpenLoopTrajectoryPose` data\n",
    "structure [defined in MPS](https://github.com/facebookresearch/projectaria_tools/blob/main/core/mps/Trajectory.h). \n",
    "\n",
    "| Field Name                        | Description                                             |\n",
    "| --------------------------------- | ------------------------------------------------------- |\n",
    "| `tracking_timestamp`              | Timestamp in device time domain, in microseconds        |\n",
    "| `transform_odometry_device`       | Transformation from device to odometry coordinate frame, represented as a SE3 instance. |\n",
    "| `device_linear_velocity_odometry` | Translational velocity of device in odometry frame, in m/s     |\n",
    "| `angular_velocity_device`         | Angular velocity of device in device frame, in rad/s              |\n",
    "| `quality_score`                   | Quality of pose estimation (higher = better)            |\n",
    "| `gravity_odometry`                | Earth gravity vector in odometry frame                  |\n",
    "| `session_uid`                     | Unique identifier for VIO tracking session              |\n",
    "\n",
    "**Important Note**: Due to the high frequency nature of this data (~800Hz), consider\n",
    "subsampling for visualization to maintain performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ba60b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== VIO High-Frequency Data Sample ===\")\n",
    "\n",
    "# Find the first VIO high_frequency data sample with high quality value\n",
    "num_vio_high_freq_samples = vrs_data_provider.get_num_data(vio_high_freq_stream_id)\n",
    "first_valid_index = None\n",
    "for idx in range(num_vio_samples):\n",
    "    vio_high_freq_data = vrs_data_provider.get_vio_high_freq_data_by_index(vio_high_freq_stream_id, idx)\n",
    "    if (\n",
    "        vio_high_freq_data.quality_score > 0.5\n",
    "    ):\n",
    "        first_valid_index = idx\n",
    "        break\n",
    "\n",
    "if first_valid_index is not None:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"First VIO High Freq Data Sample with good quality score (Index: {first_valid_index})\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Timestamps, convert timedelta to nanoseconds\n",
    "    capture_timestamp_ns = int(vio_high_freq_data.tracking_timestamp.total_seconds() * 1e9)\n",
    "\n",
    "    # Session Information\n",
    "    print(f\"Session UID: {vio_high_freq_data.session_uid}\")\n",
    "\n",
    "    # Timestamps\n",
    "    print(f\"Tracking Time: {capture_timestamp_ns} ns\")\n",
    "\n",
    "    # Quality\n",
    "    print(f\"Quality Score: {vio_high_freq_data.quality_score:.3f}\")\n",
    "\n",
    "    # Transform\n",
    "    print(f\"Transform Odometry → Device:\\n{vio_high_freq_data.transform_odometry_device.to_matrix()}\")\n",
    "\n",
    "    # Motion\n",
    "    print(f\"Linear Velocity: {vio_high_freq_data.device_linear_velocity_odometry}\")\n",
    "    print(f\"Angular Velocity: {vio_high_freq_data.angular_velocity_device}\")\n",
    "    print(f\"Gravity Vector: {vio_high_freq_data.gravity_odometry}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d81060",
   "metadata": {},
   "source": [
    "## Visualizing On-Device VIO trajectory\n",
    "\n",
    "The following code snippets demonstrate how to visualize a VIO trajectory, along with glass frame + hand tracking results, in a 3D view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f68ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_hand_3d(\n",
    "    hand_joints_in_device, hand_label\n",
    "):\n",
    "    \"\"\"\n",
    "    A helper function to plot single hand data in 3D view\n",
    "    \"\"\"\n",
    "    marker_color = [255,64,0] if hand_label == \"left\" else [255, 255, 0]\n",
    "\n",
    "    hand_skeleton_3d = create_hand_skeleton_from_landmarks(hand_joints_in_device)\n",
    "    rr.log(\n",
    "        f\"world/device/handtracking/{hand_label}/landmarks\",\n",
    "        rr.Points3D(\n",
    "            positions=hand_joints_in_device,\n",
    "            colors= marker_color,\n",
    "            radii=5e-3,\n",
    "        ),\n",
    "    )\n",
    "    rr.log(\n",
    "        f\"world/device/handtracking/{hand_label}/hand_skeleton\",\n",
    "        rr.LineStrips3D(\n",
    "            hand_skeleton_3d,\n",
    "            colors=[0, 255, 0],\n",
    "            radii=3e-3,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_hand_pose_data_3d(hand_pose_data):\n",
    "    \"\"\"\n",
    "    A helper function to plot hand pose data in 3D world view\n",
    "    \"\"\"\n",
    "    # Clear the canvas (only if hand_tracking_label exists for this device version)\n",
    "    rr.log(\n",
    "        f\"world/device/handtracking\",\n",
    "        rr.Clear.recursive(),\n",
    "    )\n",
    "\n",
    "    # Plot both hands\n",
    "    if hand_pose_data.left_hand is not None:\n",
    "        plot_single_hand_3d(\n",
    "            hand_joints_in_device=hand_pose_data.left_hand.landmark_positions_device,\n",
    "            hand_label=\"left\",\n",
    "        )\n",
    "    if hand_pose_data.right_hand is not None:\n",
    "        plot_single_hand_3d(\n",
    "            hand_joints_in_device=hand_pose_data.right_hand.landmark_positions_device,\n",
    "            hand_label=\"right\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rerun as rr\n",
    "from projectaria_tools.core.sensor_data import SensorDataType, TimeDomain, TimeQueryOptions\n",
    "from projectaria_tools.utils.rerun_helpers import (\n",
    "    create_hand_skeleton_from_landmarks,\n",
    "    AriaGlassesOutline,\n",
    "    ToTransform3D\n",
    ")\n",
    "\n",
    "print(\"\\n=== Visualizing on-device VIO trajectory + HandTracking in 3D view ===\")\n",
    "\n",
    "rr.init(\"rerun_viz_vio_trajectory\")\n",
    "device_calib = vrs_data_provider.get_device_calibration()\n",
    "handtracking_stream_id = vrs_data_provider.get_stream_id_from_label(\"handtracking\")\n",
    "\n",
    "# Set up a data queue\n",
    "deliver_options = vrs_data_provider.get_default_deliver_queued_options()\n",
    "deliver_options.deactivate_stream_all()\n",
    "deliver_options.activate_stream(vio_stream_id)\n",
    "\n",
    "# Play for only 3 seconds\n",
    "total_length_ns = vrs_data_provider.get_last_time_ns_all_streams(TimeDomain.DEVICE_TIME) - vrs_data_provider.get_first_time_ns_all_streams(TimeDomain.DEVICE_TIME)\n",
    "skip_begin_ns = int(15 * 1e9) # Skip 15 seconds\n",
    "duration_ns = int(3 * 1e9) # 3 seconds\n",
    "skip_end_ns = max(total_length_ns - skip_begin_ns - duration_ns, 0)\n",
    "deliver_options.set_truncate_first_device_time_ns(skip_begin_ns)\n",
    "deliver_options.set_truncate_last_device_time_ns(skip_end_ns)\n",
    "\n",
    "# Plot VIO trajectory in 3D view.\n",
    "# Need to keep a cache to store already-loaded trajectory\n",
    "vio_traj_cached_full = []\n",
    "for sensor_data in vrs_data_provider.deliver_queued_sensor_data(deliver_options):\n",
    "    # Convert sensor data to VIO data\n",
    "    vio_data = sensor_data.vio_data()\n",
    "    \n",
    "    # Check VIO data validity, only plot for valid data\n",
    "    if ( vio_data.status != VioStatus.VALID or vio_data.pose_quality != TrackingQuality.GOOD):\n",
    "        print(f\"VIO data is invalid for timestamp {sensor_data.get_time_ns(TimeDomain.DEVICE_TIME)}\")\n",
    "        continue\n",
    "\n",
    "    # Set timestamp\n",
    "    rr.set_time_nanos(\"device_time\", vio_data.capture_timestamp_ns)\n",
    "    \n",
    "    # Set and plot the Device pose for the current timestamp, as a RGB axis\n",
    "    T_World_Device = (\n",
    "        vio_data.transform_odometry_bodyimu @ vio_data.transform_bodyimu_device\n",
    "    )\n",
    "    rr.log(\n",
    "        \"world/device\",\n",
    "        ToTransform3D(\n",
    "            T_World_Device,\n",
    "            axis_length=0.05,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Also plot Aria glass outline for visualization\n",
    "    aria_glasses_point_outline = AriaGlassesOutline(\n",
    "        device_calib, use_cad_calib=True\n",
    "    )\n",
    "    rr.log(\n",
    "        \"world/device/glasses_outline\",\n",
    "        rr.LineStrips3D(\n",
    "            aria_glasses_point_outline,\n",
    "            colors=[200,200,200],\n",
    "            radii=5e-4,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Plot gravity direction vector\n",
    "    rr.log(\n",
    "        \"world/vio_gravity\",\n",
    "        rr.Arrows3D(\n",
    "            origins=[T_World_Device.translation()[0]],\n",
    "            vectors=[\n",
    "                vio_data.gravity_in_odometry * 1e-2\n",
    "            ],  # length converted from 9.8 meter -> 10 cm\n",
    "            colors=[101,67,33],\n",
    "            radii=1.5e-3,\n",
    "        ),\n",
    "        static=False,\n",
    "    )\n",
    "\n",
    "    # Plot VIO trajectory that are cached so far\n",
    "    vio_traj_cached_full.append(T_World_Device.translation()[0])\n",
    "    rr.log(\n",
    "        \"world/vio_trajectory\",\n",
    "        rr.LineStrips3D(\n",
    "            vio_traj_cached_full,\n",
    "            colors=[173, 216, 255],\n",
    "            radii=1.5e-3,\n",
    "        ),\n",
    "        static=False,\n",
    "    )\n",
    "\n",
    "    # For visualization purpose, also plot the hand tracking results\n",
    "    interpolated_hand_pose = vrs_data_provider.get_interpolated_hand_pose_data(handtracking_stream_id, vio_data.capture_timestamp_ns, TimeDomain.DEVICE_TIME)\n",
    "    if interpolated_hand_pose is not None:\n",
    "        plot_hand_pose_data_3d(hand_pose_data = interpolated_hand_pose)\n",
    "\n",
    "\n",
    "rr.notebook_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d149e-3517-4bdd-a67e-dfb38521e44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
