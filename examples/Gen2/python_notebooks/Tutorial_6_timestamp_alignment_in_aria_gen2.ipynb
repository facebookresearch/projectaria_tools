{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "138f03c1-1ccc-468a-8079-ae9f8b88c5ae",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "# Tutorial 6: Device Time Alignment in Aria Gen2\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In Project Aria glasses, one of the key features is that it provides multi-sensor data that are **temporally aligned** to a shared, device-time domain for each single device, and also provide **multi-device Time Alignment** using SubGHz signals (Aria Gen2), TICSync (Aria Gen1), or TimeCode signals (Aria Gen1). In this tutorial, we will demonstrate how to use such temporal aligned data from Aria Gen2 recordings.\n",
        "\n",
        "**What you'll learn:**\n",
        "\n",
        "- How to access temporally aligned sensor data on a single VRS recording.\n",
        "- How to access temporally aligned sensor data across multiple recordings using SubGHz signals.\n",
        "\n",
        "**Prerequisites**\n",
        "- Complete Tutorial 1 (VrsDataProvider Basics) to understand basic data provider concepts\n",
        "- Complete Tutorial 3 (Sequential Access multi-sensor data) to understand how to create a queue of sensor data from VRS file.\n",
        "- Download Aria Gen2 sample data: [host recording](https://www.projectaria.com/async/sample/download/?bucket=core&filename=aria_gen2_sample_data_host_1.vrs) and [client recording](https://www.projectaria.com/async/sample/download/?bucket=core&filename=aria_gen2_sample_data_client_1.vrs)\n",
        "\n",
        "\n",
        "**Note on visualization:**\n",
        "If visualization window is not showing up, this is due to `Rerun` lib's caching issue. Just rerun the specific code cell, or restart the Python kernel. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Environment (Google Colab)\n",
        "\n",
        "If running on Google Colab, install projectaria-tools and download sample data (both host and client recordings).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "google_colab_env = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if google_colab_env:\n",
        "    print(\"Running from Google Colab, installing projectaria_tools and downloading sample data\")\n",
        "\n",
        "    # Install projectaria-tools\n",
        "    !pip install projectaria-tools['all']==2.0.0\n",
        "\n",
        "    # Set up data path\n",
        "    vrs_sample_path = \"./vrs_sample_data\"\n",
        "\n",
        "    # Sample VRS file URLs - host and client recordings\n",
        "    host_vrs_url = \"https://www.projectaria.com/async/sample/download/?bucket=core&filename=aria_gen2_sample_data_host_1.vrs\"\n",
        "    client_vrs_url = \"https://www.projectaria.com/async/sample/download/?bucket=core&filename=aria_gen2_sample_data_client_1.vrs\"\n",
        "\n",
        "    host_vrs_filename = \"aria_gen2_sample_data_host_1.vrs\"\n",
        "    client_vrs_filename = \"aria_gen2_sample_data_client_1.vrs\"\n",
        "\n",
        "    host_recording = os.path.join(vrs_sample_path, host_vrs_filename)\n",
        "    client_recording = os.path.join(vrs_sample_path, client_vrs_filename)\n",
        "\n",
        "    # Download commands\n",
        "    command_list = [\n",
        "        f\"mkdir -p {vrs_sample_path}\",\n",
        "        f'curl -o {host_recording} -C - -O -L \"{host_vrs_url}\"',\n",
        "        f'curl -o {client_recording} -C - -O -L \"{client_vrs_url}\"'\n",
        "    ]\n",
        "\n",
        "    # Execute the commands for downloading dataset\n",
        "    print(f\"Downloading host and client VRS sample data...\")\n",
        "    for command in command_list:\n",
        "        !$command\n",
        "\n",
        "    print(f\"Download complete!\")\n",
        "    print(f\"Host VRS file saved to: {host_recording}\")\n",
        "    print(f\"Client VRS file saved to: {client_recording}\")\n",
        "else:\n",
        "    # For local environment, user needs to specify their own VRS file paths\n",
        "    host_recording = \"path/to/host.vrs\"\n",
        "    client_recording = \"path/to/client.vrs\"\n",
        "    print(f\"Please update host_recording and client_recording to point to your VRS files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2d5525c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from projectaria_tools.core import data_provider\n",
        "\n",
        "# Load VRS file\n",
        "vrs_data_provider = data_provider.create_vrs_data_provider(host_recording)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f31fcc66",
      "metadata": {},
      "source": [
        "## Single-Device Timestamp alignment\n",
        "\n",
        "In `projectaria_tools`, every timestamp is linked to a specific `TimeDomain`, which represents the time reference or clock used to generate that timestamp. Timestamps from different `TimeDomain`s are not directly comparable—only timestamps within the same `TimeDomain` are consistent and can be accurately compared or aligned.\n",
        "\n",
        "### Supported Time Domains\n",
        "\n",
        "> **Important: Use `DEVICE_TIME` for single-device Aria data analysis**\n",
        "\n",
        "The following table shows all supported time domains in `projectaria_tools`. **For single-device Aria data analysis, use `DEVICE_TIME` for accurate temporal alignment between sensors.**\n",
        "\n",
        "| Time Domain | Description | Usage |\n",
        "|-------------|-------------|-------|\n",
        "| **DEVICE_TIME (Recommended)**| Capture time in device's time domain. Accurate and reliable. All sensors on the same Aria device share the same device time domain. | **Use this for single-device Aria data analysis** |\n",
        "| **RECORD_TIME** | Timestamps stored in the index of VRS files. For Aria glasses, these are equal to device timestamp converted to double-precision floating point. | Fast access, but use DEVICE_TIME for accuracy |\n",
        "| **HOST_TIME** | Timestamps when sensor data is saved to the device (not when captured). | Should not be needed for any purpose |\n",
        "| **--- Time Domains for Multi-device time alignment ---** |  | |\n",
        "| SUBGHZ | Multi-device time alignment option for Aria Gen2 | See next part in this tutorial |\n",
        "| UTC | Multi-device time alignment option  | See next part in this tutorial |\n",
        "| TIME_CODE | Multi-device time alignment option for Aria Gen1 | See [Gen1 multi-device tutorial](https://github.com/facebookresearch/projectaria_tools/blob/main/examples/Gen1/python_notebooks/ticsync_tutorial.ipynb) |\n",
        "| TIC_SYNC | Multi-device time alignment option for Aria Gen1 | See [Gen1 multi-device tutorial](https://github.com/facebookresearch/projectaria_tools/blob/main/examples/Gen1/python_notebooks/ticsync_tutorial.ipynb) |\n",
        "\n",
        "\n",
        "\n",
        "### Data API to query by timestamp\n",
        "The VRS data provider offers powerful timestamp-based data access through the `get_$SENSOR_data_by_time_ns()` API family. This is the recommended approach for temporal alignment across sensors and precise timestamp-based data retrieval.\n",
        "\n",
        "For any sensor type, you can query data by timestamp using the `get_$SENSOR_data_by_time_ns()` function, where `$SENSOR` can be replaced by any sensor data type available in Aria VRS. See the [VrsDataProvider.h](https://github.com/facebookresearch/projectaria_tools/blob/main/core/data_provider/VrsDataProvider.h) for a complete list of supported sensor types.\n",
        "\n",
        "**TimeQueryOptions**\n",
        "\n",
        "This `TimeQueryOptions` parameter controls how the system finds data when your query timestamp doesn't exactly match a recorded timestamp:\n",
        "\n",
        "| Option | Behavior | Use Case |\n",
        "|--------|----------|----------|\n",
        "| **BEFORE** | Returns the last valid data with `timestamp ≤ query_time` | **Default and most common** - Get the most recent data before or at the query time |\n",
        "| **AFTER** | Returns the first valid data with `timestamp ≥ query_time` | Get the next available data after or at the query time |\n",
        "| **CLOSEST** | Returns data with smallest `timestamp - query_time` | Get the temporally closest data regardless of direction |\n",
        "\n",
        "### Boundary Behavior\n",
        "\n",
        "The API handles edge cases automatically:\n",
        "\n",
        "| Query Condition | BEFORE | AFTER | CLOSEST |\n",
        "|-----------------|--------|-------|---------|\n",
        "| `query_time < first_timestamp` | Returns invalid data | Returns first data | Returns first data |\n",
        "| `first_timestamp ≤ query_time ≤ last_timestamp` | Returns data with `timestamp ≤ query_time` | Returns data with `timestamp ≥ query_time` | Returns temporally closest data |\n",
        "| `query_time > last_timestamp` | Returns last data | Returns invalid data | Returns last data |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "660abc18",
      "metadata": {},
      "outputs": [],
      "source": [
        "from projectaria_tools.core.sensor_data import SensorDataType, TimeDomain, TimeQueryOptions\n",
        "\n",
        "print(\"=== Single VRS timestamp based query ===\")\n",
        "\n",
        "# Select RGB stream ID\n",
        "rgb_stream_id = vrs_data_provider.get_stream_id_from_label(\"camera-rgb\")\n",
        "\n",
        "# Get a timestamp within the recording (3 seconds after start)\n",
        "start_timestamp_ns = vrs_data_provider.get_first_time_ns(rgb_stream_id, TimeDomain.DEVICE_TIME)\n",
        "selected_timestamp_ns = start_timestamp_ns + int(3e9)\n",
        "\n",
        "# Fetch the RGB frame that is CLOSEST to this selected timestamp_ns\n",
        "closest_rgb_data_and_record = vrs_data_provider.get_image_data_by_time_ns(\n",
        "    stream_id = rgb_stream_id,\n",
        "    time_ns = selected_timestamp_ns,\n",
        "    time_domain = TimeDomain.DEVICE_TIME,\n",
        "    time_query_options = TimeQueryOptions.CLOSEST\n",
        ")\n",
        "closest_timestamp_ns = closest_rgb_data_and_record[1].capture_timestamp_ns\n",
        "closest_frame_number = closest_rgb_data_and_record[1].frame_number\n",
        "print(f\" The closest RGB frame to query timestamp {selected_timestamp_ns} is the {closest_frame_number}-th frame, with capture timestamp of {closest_timestamp_ns}\")\n",
        "\n",
        "# Fetch the frame BEFORE this frame\n",
        "prev_rgb_data_and_record = vrs_data_provider.get_image_data_by_time_ns(\n",
        "    stream_id = rgb_stream_id,\n",
        "    time_ns = closest_timestamp_ns - 1,\n",
        "    time_domain = TimeDomain.DEVICE_TIME,\n",
        "    time_query_options = TimeQueryOptions.BEFORE\n",
        ")\n",
        "prev_timestamp_ns = prev_rgb_data_and_record[1].capture_timestamp_ns\n",
        "prev_frame_number = prev_rgb_data_and_record[1].frame_number\n",
        "print(f\" The previous RGB frame is the {prev_frame_number}-th frame, with capture timestamp of {prev_timestamp_ns}\")\n",
        "\n",
        "# Fetch the frame AFTER this frame\n",
        "next_rgb_data_and_record = vrs_data_provider.get_image_data_by_time_ns(\n",
        "    stream_id = rgb_stream_id,\n",
        "    time_ns = closest_timestamp_ns + 1,\n",
        "    time_domain = TimeDomain.DEVICE_TIME,\n",
        "    time_query_options = TimeQueryOptions.AFTER\n",
        ")\n",
        "next_timestamp_ns = next_rgb_data_and_record[1].capture_timestamp_ns\n",
        "next_frame_number = next_rgb_data_and_record[1].frame_number\n",
        "print(f\" The next RGB frame is the {next_frame_number}-th frame, with capture timestamp of {next_timestamp_ns}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f03b0d3-f091-4771-96f7-83ba68f6482f",
      "metadata": {},
      "source": [
        "In this additional example, we demonstrate how to query and visualize \"groups\" of RGB + SLAM images approximately at the same timestamp. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae0ba680-678a-46ea-a26c-5559cf02e9fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import rerun as rr\n",
        "\n",
        "print(\"=== Single VRS timestamp-based query visualization examples ===\")\n",
        "rr.init(\"rerun_viz_single_vrs_timestamp_based_query\")\n",
        "\n",
        "# Select RGB and SLAM stream IDs to visualize\n",
        "all_labels = vrs_data_provider.get_device_calibration().get_camera_labels()\n",
        "slam_labels = [label for label in all_labels if \"slam\" in label ]\n",
        "slam_stream_ids = [vrs_data_provider.get_stream_id_from_label(label) for label in slam_labels]\n",
        "rgb_stream_id = vrs_data_provider.get_stream_id_from_label(\"camera-rgb\")\n",
        "\n",
        "# Starting from +3 seconds into the recording, and at 5Hz frequency\n",
        "target_period_ns = int(2e8)\n",
        "start_timestamp_ns = vrs_data_provider.get_first_time_ns(rgb_stream_id, TimeDomain.DEVICE_TIME) + int(3e9)\n",
        "\n",
        "# Plot 20 samples\n",
        "current_timestamp_ns = start_timestamp_ns\n",
        "for frame_i in range(20):\n",
        "    # Query and plot RGB image\n",
        "    rgb_image_data, rgb_image_record = vrs_data_provider.get_image_data_by_time_ns(\n",
        "        stream_id = rgb_stream_id,\n",
        "        time_ns = current_timestamp_ns,\n",
        "        time_domain = TimeDomain.DEVICE_TIME,\n",
        "        time_query_options = TimeQueryOptions.CLOSEST)\n",
        "    rr.set_time_nanos(\"device_time\", rgb_image_record.capture_timestamp_ns)\n",
        "    rr.log(\"rgb_image\", rr.Image(rgb_image_data.to_numpy_array()))\n",
        "\n",
        "    # Query and plot SLAM images\n",
        "    for slam_i in range(len(slam_labels)):\n",
        "        single_slam_label = slam_labels[slam_i]\n",
        "        single_slam_stream_id = slam_stream_ids[slam_i]\n",
        "\n",
        "        slam_image_data, slam_image_record = vrs_data_provider.get_image_data_by_time_ns(\n",
        "                stream_id = single_slam_stream_id,\n",
        "                time_ns = current_timestamp_ns,\n",
        "                time_domain = TimeDomain.DEVICE_TIME,\n",
        "                time_query_options = TimeQueryOptions.CLOSEST)\n",
        "        rr.set_time_nanos(\"device_time\", slam_image_record.capture_timestamp_ns)\n",
        "        rr.log(single_slam_label, rr.Image(slam_image_data.to_numpy_array()))\n",
        "\n",
        "    # Increment query timestamp\n",
        "    current_timestamp_ns += target_period_ns\n",
        "\n",
        "rr.notebook_show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c7f181",
      "metadata": {},
      "source": [
        "## Multi-Device Timestamp alignment\n",
        "While recording, multiple Aria-Gen2 glasses can enable a feature that allows their timestamps to be mapped across devices using SubGHz signals. Please refer to the multi-device recording wiki page from ARK (TODO: add link) to learn how to record with this feature. \n",
        "\n",
        "Basically, one pair of glasses acts as the **host** device, that actively broadcasts SubGHz signals to a specified channel; \n",
        "all other glasses act as **client** devices, that receives the SubGHz signals, and record a new `Time Domain Mapping` data streams in their VRS file.  \n",
        "It is essentially a timestamp hash mapping from **host** `DEVICE_TIME` -> **client** `DEVICE_TIME`. \n",
        "Therefore this mapping data stream **only exists in client VRS**, but not **host VRS**. \n",
        "\n",
        "In `projectaria_tools`, we provide 2 types of APIs to easily perform timestamp-based query across multi-device recordings: \n",
        "1. Converter APIs provides direct convert functions that maps timestamps between any 2 `TimeDomain`. \n",
        "2. Query APIs that allows users to specifies `time_domain = TimeDomain.SUBGHZ` in a client VRS, to query \"from timestamp of the host\".\n",
        "\n",
        "The following code shows examples of using each type of API. \n",
        "Note that in the visualization example, the host and client windows will play intermittently. \n",
        "This is expected and correct, because the host and client devices' RGB cameras are NOT trigger aligned by nature. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4d99373",
      "metadata": {},
      "outputs": [],
      "source": [
        "import rerun as rr\n",
        "from projectaria_tools.core.sensor_data import (\n",
        "    SensorData,\n",
        "    ImageData,\n",
        "    TimeDomain,\n",
        "    TimeQueryOptions,\n",
        "    TimeSyncMode,\n",
        ")\n",
        "\n",
        "# Create data providers for both host and client recordings\n",
        "host_data_provider = data_provider.create_vrs_data_provider(host_recording)\n",
        "client_data_provider = data_provider.create_vrs_data_provider(client_recording)\n",
        "\n",
        "print(\"======= Multi-VRS time mapping example: Timestamp converter APIs ======\")\n",
        "\n",
        "# Because host and client recordings may start at different times,\n",
        "# we manually pick a timestamp in the middle of the host recording.\n",
        "# Note that for host, we always use DEVICE_TIME domain.\n",
        "selected_timestamp_host = (host_data_provider.get_first_time_ns_all_streams(time_domain = TimeDomain.DEVICE_TIME) +\n",
        "    host_data_provider.get_last_time_ns_all_streams(time_domain = TimeDomain.DEVICE_TIME)) // 2\n",
        "\n",
        "# Convert from host time to client time\n",
        "selected_timestamp_client = client_data_provider.convert_from_synctime_to_device_time_ns(selected_timestamp_host, TimeSyncMode.SUBGHZ)\n",
        "\n",
        "# Convert from client time back to host time. Note that there could be some small numerical differences compared\n",
        "selected_timestamp_host_roundtrip = client_data_provider.convert_from_device_time_to_synctime_ns(selected_timestamp_client, TimeSyncMode.SUBGHZ)\n",
        "\n",
        "print(f\" Selected host timestamp is {selected_timestamp_host}; \")\n",
        "print(f\" Converted to client timestamp is {selected_timestamp_client}; \")\n",
        "print(f\" Then roundtrip convert back to host:{selected_timestamp_host_roundtrip}, \"\n",
        "     f\" And delta value from original host timestamp is {selected_timestamp_host_roundtrip - selected_timestamp_host}. This is mainly due to numerical errors. \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96ed8a31-ef0c-43bf-ace9-b886a419d191",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"======= Multi-VRS time mapping example: Query APIs ======\")\n",
        "rr.init(\"rerun_viz_multi_vrs_time_mapping\")\n",
        "\n",
        "# Set up sensor queue options in host VRS, only turn on RGB stream\n",
        "host_deliver_options = host_data_provider.get_default_deliver_queued_options()\n",
        "host_deliver_options.deactivate_stream_all()\n",
        "rgb_stream_id = host_data_provider.get_stream_id_from_label(\"camera-rgb\")\n",
        "host_deliver_options.activate_stream(rgb_stream_id)\n",
        "\n",
        "# Select only a segment to plot\n",
        "host_vrs_start_timestamp = host_data_provider.get_first_time_ns_all_streams(time_domain = TimeDomain.DEVICE_TIME)\n",
        "host_segment_start = host_vrs_start_timestamp + int(20e9) # 20 seconds after start\n",
        "host_segment_duration = int(5e9)\n",
        "host_segment_end = host_segment_start + host_segment_duration\n",
        "host_vrs_end_timestamp = host_data_provider.get_last_time_ns_all_streams(time_domain = TimeDomain.DEVICE_TIME)\n",
        "host_deliver_options.set_truncate_first_device_time_ns(host_segment_start - host_vrs_start_timestamp)\n",
        "host_deliver_options.set_truncate_last_device_time_ns(host_vrs_end_timestamp - host_segment_end)\n",
        "\n",
        "# Plot RGB image data from both host and client\n",
        "for sensor_data in host_data_provider.deliver_queued_sensor_data(host_deliver_options):\n",
        "    # ---------\n",
        "    # Plotting in host.\n",
        "    # Everything is done in DEVICE_TIME domain.\n",
        "    # ---------\n",
        "    host_image_data, host_image_record = sensor_data.image_data_and_record()\n",
        "\n",
        "    # Set timestamps directly from host image record\n",
        "    host_timestamp_ns = host_image_record.capture_timestamp_ns\n",
        "    rr.set_time_nanos(\"device_time\", host_timestamp_ns)\n",
        "\n",
        "    rr.log(\"rgb_image_in_host\", rr.Image(host_image_data.to_numpy_array()))\n",
        "\n",
        "    # ---------\n",
        "    # Plotting in client.\n",
        "    # All the query APIs are done in SUBGHZ domain.\n",
        "    # ---------\n",
        "    # Query the closest RGB image from client VRS\n",
        "    client_image_data, client_image_record = client_data_provider.get_image_data_by_time_ns(\n",
        "        stream_id = rgb_stream_id,\n",
        "        time_ns = host_timestamp_ns,\n",
        "        time_domain = TimeDomain.SUBGHZ,\n",
        "        time_query_options = TimeQueryOptions.CLOSEST)\n",
        "\n",
        "    # Still need to convert client's device time back to host's time,\n",
        "    # because we want to log this image data on host's timeline in Rerun\n",
        "    client_timestamp_ns = client_image_record.capture_timestamp_ns\n",
        "    converted_client_timestamp_ns = client_data_provider.convert_from_device_time_to_synctime_ns(client_timestamp_ns, TimeSyncMode.SUBGHZ)\n",
        "    rr.set_time_nanos(\"device_time\", converted_client_timestamp_ns)\n",
        "\n",
        "    # Plot client image\n",
        "    rr.log(\"rgb_image_in_client\", rr.Image(client_image_data.to_numpy_array()))\n",
        "\n",
        "rr.notebook_show()"
      ]
    }
  ],
  "metadata": {
    "fileHeader": "",
    "fileUid": "8e5e180f-1699-47fd-8255-d09a47290dd6",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
