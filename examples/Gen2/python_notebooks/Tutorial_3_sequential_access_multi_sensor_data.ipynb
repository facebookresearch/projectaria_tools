{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3523cb32",
   "metadata": {},
   "source": [
    "# Tutorial 3: Sequential Accessing Multi-sensor Data\n",
    "\n",
    "## Introduction\n",
    "This tutorial shows how to use the unified queued API in `vrs_data_provider` to efficiently **stream** multi-sensor data from Aria VRS files. \n",
    "\n",
    "We will learn how to use the unified SensorData interface, access time-ordered sensor data queues, and customize stream control and time windowing for efficient processing.\n",
    "\n",
    "\n",
    "In this tutorial, we will learn: \n",
    "1. Use the basic queued API to iterate through all sensor data.\n",
    "2. Explore the unified SensorData interface\n",
    "3. Customize stream selection and time windowing in this queued API. \n",
    "4. Apply frame rate subsampling for efficient processing\n",
    "\n",
    "**Prerequisites**\n",
    "- Complete Tutorial 1 (VrsDataProvider Basics) to understand basic data provider concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f404b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectaria_tools.core import data_provider\n",
    "\n",
    "# Load local VRS file\n",
    "vrs_file_path = \"path/to/your/recording.vrs\"\n",
    "vrs_data_provider = data_provider.create_vrs_data_provider(vrs_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1f1872",
   "metadata": {},
   "source": [
    "## Basic Sequential Data Access API\n",
    "\n",
    "The `deliver_queued_sensor_data()` method in `vrs_data_provider` provides a **unified** way to iterate through **all sensor data** in **timestamp order**. This is the primary API for sequential access to multi-sensor data.\n",
    "\n",
    "**Key features of the queued API:**\n",
    "- Returns data from ALL streams in the VRS file\n",
    "- Orders data by device timestamp (chronological order)\n",
    "- Customizable via stream selection, sub-sampling each stream, etc. \n",
    "- The returned data can be further converted to each sensor type via a unified interface. \n",
    "\n",
    "Here is a simple example to query the first K data samples from the VRS, and inspect each data sample's  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2fd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Basic Sequential Data Access ===\")\n",
    "print(\"Processing all sensor data in timestamp order...\")\n",
    "\n",
    "# Variables to store how many data samples has arrived for each sensor stream\n",
    "data_count = 0\n",
    "per_stream_data_counts = {}\n",
    "total_num_samples = 5000\n",
    "\n",
    "# Call deliver queued sensor data API to obtain a \"streamed\" data, in sorted timestamp order\n",
    "# The iterator would return a unified SensorData instance\n",
    "print(f\"Start inspecting the first {total_num_samples} data samples in the VRS\")\n",
    "for sensor_data in vrs_data_provider.deliver_queued_sensor_data():\n",
    "    # Which stream does this sensor data belong to\n",
    "    stream_id = sensor_data.stream_id()\n",
    "    stream_label = vrs_data_provider.get_label_from_stream_id(stream_id)\n",
    "\n",
    "    # Aggregate data count for this stream\n",
    "    data_count += 1\n",
    "    if stream_label not in per_stream_data_counts:\n",
    "        per_stream_data_counts[stream_label] = 0\n",
    "    per_stream_data_counts[stream_label] += 1\n",
    "\n",
    "    # Limit output for demonstration\n",
    "    if data_count >= total_num_samples:\n",
    "        print(\"Stopping after 5000 samples for demonstration...\")\n",
    "        break\n",
    "\n",
    "\n",
    "# Print data counts for each sensor stream\n",
    "print(f\"\\nTotal processed: {data_count} sensor data samples\")\n",
    "print(\"Data count per stream:\")\n",
    "for stream_label, count in per_stream_data_counts.items():\n",
    "    print(f\"\\t{stream_label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51bd708",
   "metadata": {},
   "source": [
    "## Understanding the Unified SensorData Interface\n",
    "\n",
    "The queued API returns data using a unified `SensorData` interface. This allows you to handle different types of sensor data (images, IMU, audio, etc.) in a **consistent way**, regardless of the sensor type.\n",
    "\n",
    "**Each SensorData object provides:**\n",
    "- Stream ID and stream label for identification\n",
    "- Sensor data type (IMAGE, IMU, AUDIO, etc.)\n",
    "- Timestamps in different time domains\n",
    "- Access to the actual sensor data (images, IMU, audio, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc1035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projectaria_tools.core.sensor_data import SensorDataType, TimeDomain, TimeQueryOptions\n",
    "\n",
    "print(\"\\n=== Exploring the SensorData Interface ===\")\n",
    "\n",
    "# Get a few samples to examine their properties\n",
    "data_count = 0\n",
    "for sensor_data in vrs_data_provider.deliver_queued_sensor_data():\n",
    "    if data_count >= 5:\n",
    "        break\n",
    "\n",
    "    # Inspect where this sensor data come from, and what is its data type\n",
    "    stream_id = sensor_data.stream_id()\n",
    "    stream_label = vrs_data_provider.get_label_from_stream_id(stream_id)\n",
    "    data_type = sensor_data.sensor_data_type()\n",
    "\n",
    "    # Inspect the device timestamp of this sensor data\n",
    "    device_time = sensor_data.get_time_ns(TimeDomain.DEVICE_TIME)\n",
    "\n",
    "    print(f\"\\nSample {data_count + 1}:\")\n",
    "    print(f\"  Stream: {stream_label} (Stream ID: {stream_id})\")\n",
    "    print(f\"  Type: {data_type}\")\n",
    "    print(f\"  Device Time: {device_time/1e9:.6f}s\")\n",
    "\n",
    "    # Map sensor data to its specific type, and inspect its actual data content.\n",
    "    # Here we use image and IMU as an example\n",
    "    if data_type == SensorDataType.IMAGE:\n",
    "        image_data = sensor_data.image_data_and_record()[0]\n",
    "        print(f\"  Image size: {image_data.get_width()} x {image_data.get_height()}\")\n",
    "        print(f\"  Pixel format: {image_data.get_pixel_format()}\")\n",
    "\n",
    "    elif data_type == SensorDataType.IMU:\n",
    "        imu_data = sensor_data.imu_data()\n",
    "        accel = imu_data.accel_msec2\n",
    "        gyro = imu_data.gyro_radsec\n",
    "        print(f\"  IMU Accel: [{accel[0]:.3f}, {accel[1]:.3f}, {accel[2]:.3f}] m/sÂ²\")\n",
    "        print(f\"  IMU Gyro: [{gyro[0]:.3f}, {gyro[1]:.3f}, {gyro[2]:.3f}] rad/s\")\n",
    "\n",
    "    data_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71f5d9",
   "metadata": {},
   "source": [
    "## Customizing Data Access with DeliverQueuedOptions\n",
    "\n",
    "The real power of the queued API comes from **customization options**. The `DeliverQueuedOptions` class allows you to:\n",
    "\n",
    "1. **Apply time windowing** - Process only specific time ranges.\n",
    "2. **Select specific streams** - Choose which sensors to include.\n",
    "3. **Subsample data** - Reduce frame rates for specific streams.\n",
    "\n",
    "These all provide flexible ways to control the sensor queue, to focus on specific time periods or sensor modalities, or customize data rates for different analysis needs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rerun as rr\n",
    "\n",
    "print(\"\\n=== Customizing Data Access with DeliverQueuedOptions ===\")\n",
    "\n",
    "customized_deliver_options = vrs_data_provider.get_default_deliver_queued_options()\n",
    "\n",
    "# -----------------\n",
    "# 1. Stream selection feature - only select RGB, 1 SLAM camera, and 1 ET camera data.\n",
    "# -----------------\n",
    "rgb_to_select = vrs_data_provider.get_stream_id_from_label(\"camera-rgb\")\n",
    "slam_to_select = vrs_data_provider.get_stream_id_from_label(\"slam-front-right\")\n",
    "et_to_select = vrs_data_provider.get_stream_id_from_label(\"camera-et-right\")\n",
    "\n",
    "# First deactivate all streams, then just add back selected streams\n",
    "customized_deliver_options.deactivate_stream_all()\n",
    "for selected_stream_id in [rgb_to_select,slam_to_select,et_to_select]:\n",
    "    customized_deliver_options.activate_stream(selected_stream_id)\n",
    "\n",
    "# -----------------\n",
    "# 2. Time windowing feature - Skip first 2 seconds, and play for 3 seconds, if possible\n",
    "# -----------------\n",
    "total_length_ns = vrs_data_provider.get_last_time_ns_all_streams(TimeDomain.DEVICE_TIME) - vrs_data_provider.get_first_time_ns_all_streams(TimeDomain.DEVICE_TIME)\n",
    "skip_begin_ns = int(2 * 1e9) # 2 seconds\n",
    "duration_ns = int(3 * 1e9) # 3 seconds\n",
    "skip_end_ns = max(total_length_ns - skip_begin_ns - duration_ns, 0)\n",
    "customized_deliver_options.set_truncate_first_device_time_ns(skip_begin_ns)\n",
    "customized_deliver_options.set_truncate_last_device_time_ns(skip_end_ns)\n",
    "\n",
    "# -----------------\n",
    "# 3. Per-stream sub-sampling feature - subsample slam camera at rate of 3\n",
    "# -----------------\n",
    "slam_subsample_rate = 3\n",
    "customized_deliver_options.set_subsample_rate(stream_id = slam_to_select, rate = slam_subsample_rate)\n",
    "\n",
    "# -----------------\n",
    "# 4. Deliver customized data queue, and visualize\n",
    "# -----------------\n",
    "print(f\"Start visualizing customized sensor data queue\")\n",
    "\n",
    "rr.init(\"rerun_viz_customized_sensor_data_queue\")\n",
    "\n",
    "for sensor_data in vrs_data_provider.deliver_queued_sensor_data(customized_deliver_options):\n",
    "    stream_id = sensor_data.stream_id()\n",
    "    stream_label = vrs_data_provider.get_label_from_stream_id(stream_id)\n",
    "    device_time_ns = sensor_data.get_time_ns(TimeDomain.DEVICE_TIME)\n",
    "\n",
    "    image_data_and_record = sensor_data.image_data_and_record()\n",
    "\n",
    "    # Visualize\n",
    "    rr.set_time_nanos(\"device_time\", device_time_ns)\n",
    "    rr.log(stream_label, rr.Image(image_data_and_record[0].to_numpy_array()))\n",
    "\n",
    "rr.notebook_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3231006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
