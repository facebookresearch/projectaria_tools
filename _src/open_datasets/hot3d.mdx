---
sidebar_position: 65
title: HOT3D Dataset
---

# HOT3D Dataset

HOT3D is a new benchmark dataset for vision-based understanding of 3D hand-object interactions. This dataset contains over 800 minutes of egocentric recordings, with 33 diverse hand-held objects, capturing over one million multi-view frames of hand-object interactions.

The dataset contains:

* Synchronized multi-view egocentric videos from Project Aria glasses and Quest 3 VR headset
* High-quality 3D pose annotations of hands and objects
* 3D object models with PBR materials
* 2D bounding boxes
* [Eye Gaze MPS data](/data_formats/mps/mps_eye_gaze.mdx) (Aria only)
* [Semi-Dense Point Cloud MPS data](/data_formats/mps/slam/mps_pointcloud.mdx) (Aria only)

HOT3D uses its own specific downloader, available in the HOT3D GitHub repository, enabling you to download Quest3, Aria and object models data.

## Getting Started

* [https://www.projectaria.com/datasets/hot3D/](https://www.projectaria.com/datasets/hot3D/) - find out more about the dataset and get access to it.
* [Introducing HOT3D: An Egocentric Dataset for 3D Hand and Object Tracking](https://arxiv.org/pdf/2406.09598) - research paper.
* [HOT3D GitHub repository](https://github.com/facebookresearch/hot3d) - install HOT3D Python tooling that will enable you to download and visualize HOT3D data.
    * Use the [HOT3D Jupyter notebook tutorial](https://github.com/facebookresearch/hot3d/blob/main/hot3d/HOT3D_Tutorial.ipynb) to get to know the downloader and visualizers.

## HOT3D Research Challenges
HOT3D data is used in the following research challenges:
* [Multiview Egocentric Hand Tracking Challenge](https://github.com/facebookresearch/hand_tracking_toolkit?tab=readme-ov-file#evaluation)
* [BOP: Benchmark for 6D Object Pose Estimation](https://bop.felk.cvut.cz/challenges/bop-challenge-2024/)
