{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b4b9bf40-610d-44ca-b208-fb63868afec9",
      "metadata": {},
      "source": [
        "# ADT Tutorial\n",
        "\n",
        "Note: If this is your first ADT tutorial, we suggest going through the ADT quickstart tutorial first. This tutorial will not explain the basics that are covered in the quickstart.\n",
        "\n",
        "In this tutorial, we will explain how to generate 3D pointclouds from the ADT depth maps. This includes unprojecting points using the camera model to get the 3D ray associated with each pixel, using the depth map to compute each point's 3D coordinates in the camera frame, using the Aria pose and calibration to compute the point coordinates in the Scene frame, and finally using the RGB images to colorize the pointcloud."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8a2785e4-eaf1-499b-9427-a091e668cd81",
      "metadata": {},
      "source": [
        "### Running in Google Colab\n",
        "\n",
        "To run this in google colab, go to [ADT Depth Map to Pointcloud Tutorial](https://colab.research.google.com/github/facebookresearch/projectaria_tools/blob/main/projects/AriaDigitalTwinDatasetTools/examples/adt_depth_maps_to_pointcloud_tutorial.ipynb)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c87038e1-093e-4d16-a3ac-a91181530b45",
      "metadata": {},
      "source": [
        "### Setup notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c5566c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48c5566c",
        "outputId": "cb7cf015-5ccc-43c9-f2b2-99df68207a4f"
      },
      "outputs": [],
      "source": [
        "# Specifics for Google Colab\n",
        "google_colab_env = 'google.colab' in str(get_ipython())\n",
        "if google_colab_env:\n",
        "    print(\"Running from Google Colab, installing projectaria_tools and getting sample data\")\n",
        "    !pip install projectaria-tools\n",
        "    # These versions of numpy and pandas-gbq are compatible with the rest of the colab environment\n",
        "    !pip install numpy>=1.23 pandas-gbq==0.19\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aadaec3a",
      "metadata": {
        "id": "aadaec3a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import plotly.graph_objects as go\n",
        "from math import tan\n",
        "import random\n",
        "\n",
        "from projectaria_tools.core.stream_id import StreamId\n",
        "from projectaria_tools.core import calibration\n",
        "from projectaria_tools.projects.adt import (\n",
        "   AriaDigitalTwinDataProvider,\n",
        "   AriaDigitalTwinSkeletonProvider,\n",
        "   AriaDigitalTwinDataPathsProvider,\n",
        "   bbox3d_to_line_coordinates,\n",
        "   bbox2d_to_image_coordinates,\n",
        "   utils as adt_utils,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "89655959",
      "metadata": {
        "id": "89655959"
      },
      "source": [
        "### Download the example sequence\n",
        "\n",
        "The following code cell will directly download the [ADT sample dataset](https://www.projectaria.com/async/sample/download/?bucket=adt&filename=aria_digital_twin_test_data.zip).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdc1d284",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdc1d284",
        "outputId": "2eab93cb-030a-433f-b197-10624ae547e7"
      },
      "outputs": [],
      "source": [
        "if google_colab_env:\n",
        "    adt_sample_path = \"./adt_sample_data\"\n",
        "else:\n",
        "    adt_sample_path = \"/tmp/adt_sample_data\"\n",
        "\n",
        "data_sequence_url = \"https://www.projectaria.com/async/sample/download/?bucket=adt&filename=aria_digital_twin_test_data_v2.zip\"\n",
        "command_list = [\n",
        "    f\"mkdir -p {adt_sample_path}\",\n",
        "    # Download sample data\n",
        "    f'curl -o {adt_sample_path}/adt_sample_data.zip -C - -O -L \"{data_sequence_url}\"',\n",
        "    # Unzip the sample data\n",
        "    f\"unzip -o {adt_sample_path}/adt_sample_data.zip -d {adt_sample_path}\"\n",
        "]\n",
        "sequence_path = f\"{adt_sample_path}/Apartment_release_golden_skeleton_seq100_10s_sample_M1292\"\n",
        "\n",
        "# Execute the commands for downloading dataset\n",
        "if google_colab_env:\n",
        "    for command in command_list:\n",
        "        !$command\n",
        "else:\n",
        "    for command in command_list:\n",
        "        subprocess.run(command, shell=True, check=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d9bdca4d",
      "metadata": {
        "id": "d9bdca4d"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c3f339",
      "metadata": {
        "id": "61c3f339"
      },
      "outputs": [],
      "source": [
        "paths_provider = AriaDigitalTwinDataPathsProvider(sequence_path)\n",
        "data_paths = paths_provider.get_datapaths()\n",
        "gt_provider = AriaDigitalTwinDataProvider(data_paths)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3a6a506d",
      "metadata": {
        "id": "3a6a506d"
      },
      "source": [
        "## Get calib\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rMapQYBUSch_",
      "metadata": {
        "id": "rMapQYBUSch_"
      },
      "outputs": [],
      "source": [
        "stream_id = StreamId(\"214-1\")\n",
        "camera_calibration = gt_provider.get_aria_camera_calibration(stream_id)\n",
        "T_Device_Cam = camera_calibration.get_transform_device_camera()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "m6z2_MVcVNFH",
      "metadata": {
        "id": "m6z2_MVcVNFH"
      },
      "source": [
        "## Set timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aRk8YfZtVXbQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRk8YfZtVXbQ",
        "outputId": "26f966ef-1090-448b-9751-25951441fa5e"
      },
      "outputs": [],
      "source": [
        "img_timestamps_ns_all = gt_provider.get_aria_device_capture_timestamps_ns(stream_id)\n",
        "ts1 = img_timestamps_ns_all[10]\n",
        "ts2 = img_timestamps_ns_all[len(img_timestamps_ns_all)-10]\n",
        "img_timestamps_ns = [ts1, ts2]\n",
        "print(\"selected timestamps: \")\n",
        "for ts in img_timestamps_ns:\n",
        "  print(ts * 1e-9, \"s\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ziuYkJ80BhZ4",
      "metadata": {
        "id": "ziuYkJ80BhZ4"
      },
      "source": [
        "## Load depth images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HGxe1NyhFqjn",
      "metadata": {
        "id": "HGxe1NyhFqjn"
      },
      "outputs": [],
      "source": [
        "SKIP_N_PIXELS = 10\n",
        "\n",
        "# store a list of points in the scene frame for each image\n",
        "points_in_scene = []\n",
        "\n",
        "# also store a list of rgb colors for each image, where each col corresponds to a point in the pointcloud\n",
        "rgb_cols = []\n",
        "\n",
        "for timestamp in img_timestamps_ns:\n",
        "  if timestamp < gt_provider.get_start_time_ns() or timestamp > gt_provider.get_end_time_ns():\n",
        "    print(f\"WARNING: timestamp outside of GT domain\")\n",
        "    continue\n",
        "\n",
        "  aria_pose_with_dt = gt_provider.get_aria_3d_pose_by_timestamp_ns(timestamp)\n",
        "  if not aria_pose_with_dt.is_valid:\n",
        "    print(f\"WARNING: No Aria poses for timestamp {timestamp}, skipping image\")\n",
        "    continue\n",
        "\n",
        "  T_Scene_Device = aria_pose_with_dt.data().transform_scene_device\n",
        "  T_Scene_Cam = T_Scene_Device @ T_Device_Cam\n",
        "\n",
        "  depth = gt_provider.get_depth_image_by_timestamp_ns(timestamp, stream_id).data().to_numpy_array()\n",
        "  rgb = gt_provider.get_aria_image_by_timestamp_ns(timestamp, stream_id).data().to_numpy_array()\n",
        "  u_max = rgb.shape[1]\n",
        "  v_max = rgb.shape[0]\n",
        "\n",
        "  # iterate through all pixels\n",
        "  counter = 0.0\n",
        "  img_points_in_scene = []\n",
        "  img_cols = []\n",
        "  for u in range(u_max):\n",
        "    for v in range(v_max):\n",
        "      counter = counter + 1.0\n",
        "\n",
        "      # skip every N image pixel to speed things up\n",
        "      if counter % SKIP_N_PIXELS != 0.0:\n",
        "        continue\n",
        "      ray = camera_calibration.unproject([u,v])\n",
        "      if ray is not None:\n",
        "        d = depth[v,u] / 1000 # diving by 1000 to convert from mm to m\n",
        "        p_in_cam = d * ray\n",
        "        p_in_scene = T_Scene_Cam @ p_in_cam\n",
        "        img_points_in_scene.append(p_in_scene)\n",
        "\n",
        "        # Note that our API calls go by foo(u,v) or foo(x,y)\n",
        "        # However, when converting to a numpy array, the array must be indexed by (row, col),\n",
        "        # hence the opposite call here vs unproject\n",
        "        img_cols.append(rgb[v][u])\n",
        "\n",
        "  # convert from lists to ndarrays\n",
        "  points_in_scene.append(np.stack(img_points_in_scene))\n",
        "  rgb_cols.append(np.stack(img_cols))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "GKkUbhN_BmJX",
      "metadata": {
        "id": "GKkUbhN_BmJX"
      },
      "source": [
        "## View Results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ugyvAkyPJGbT",
      "metadata": {
        "id": "ugyvAkyPJGbT"
      },
      "source": [
        "### Setup ReRun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sh0E5hNG0UYn",
      "metadata": {
        "id": "sh0E5hNG0UYn"
      },
      "outputs": [],
      "source": [
        "import rerun as rr\n",
        "rr.init(\n",
        "    \"ADT Pointcloud Viewer\",\n",
        "    recording_id=None,\n",
        "    spawn=True,\n",
        "    default_enabled=True,\n",
        "    strict=False,\n",
        ")\n",
        "rr.log(\"world\", rr.ViewCoordinates.RIGHT_HAND_Y_UP, timeless=True)\n",
        "rec = rr.memory_recording()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "oUnMHSf3I6ik",
      "metadata": {
        "id": "oUnMHSf3I6ik"
      },
      "source": [
        "### View different depth images using different colors to show alignment between the two"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8PQVEVXZ3uah",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "8PQVEVXZ3uah",
        "outputId": "cc827f95-8bd6-40d5-ae4b-702eab20b551"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "for i in range(len(points_in_scene)):\n",
        "  rand_col = [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
        "  rr.log(\n",
        "        \"world/points/\" + str(img_timestamps_ns[i]),\n",
        "        rr.Points3D(points_in_scene[i], colors=[rand_col]),\n",
        "        timeless=True,\n",
        "    )\n",
        "rec"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "_sxsLRJvPmgc",
      "metadata": {
        "id": "_sxsLRJvPmgc"
      },
      "source": [
        "### View depth images with color from the RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cu3mY4AqErbh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "cu3mY4AqErbh",
        "outputId": "d874c786-ee1c-42ff-95a7-420e0a54d6fd"
      },
      "outputs": [],
      "source": [
        "# we can use the colors we extracted from the RGB images above to get a colored pointcloud\n",
        "for i in range(len(points_in_scene)):\n",
        "  rr.log(\n",
        "        \"world/points/\" + str(img_timestamps_ns[i]),\n",
        "        rr.Points3D(points_in_scene[i], colors=rgb_cols[i]),\n",
        "        timeless=True,\n",
        "    )\n",
        "rec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c443e30-5239-40ec-a594-419f4d3afeb1",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "fileHeader": "",
    "fileUid": "e1db56fc-d64b-45f5-85e3-022d93460d90",
    "isAdHoc": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  }
}
